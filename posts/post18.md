### கடைக்கால் மாதிரிகள் !

ஹலோ டெக் ஆர்வலர்களே! இன்று நாம் "கடைக்கால் மாதிரிகள்" (Foundation Models) எனப்படும் சூப்பர் ஹீரோக்களைப் பற்றி பேசப் போகிறோம். இவைதான், நாம் வியந்து பார்க்கும் AI பயன்பாடுகளின் (AI Applications) அடித்தளம்! ஒரு பிரம்மாண்டமான கட்டிடத்தை உருவாக்க, அதன் அடித்தளம் உறுதியாக இருக்க வேண்டும். அதுபோல, இந்த மாதிரிகள் தான் AI உலகின் அடித்தளம் (Foundation of AI).

சரி, இந்த சூப்பர் ஹீரோக்களைப் பயன்படுத்த, அவற்றை எப்படி உருவாக்குவது என்று தெரிந்து கொள்ள வேண்டுமா? யோசித்துப் பாருங்கள், ஒரு சுவையான பிரியாணி சாப்பிட, அரிசியை எப்படி விளைவிப்பது என்று தெரிய வேண்டுமா? இல்லை தானே! ஆனால், அரிசியின் வகைகள், அதை எப்படி சமைப்பது என்று தெரிந்தால், இன்னும் சுவையான பிரியாணி செய்ய முடியும் அல்லவா? அதே போலத்தான் இந்த மாதிரிகளும். இந்த மாதிரிகளை உருவாக்குவது ஒரு பெரிய சவால். இது ஒரு ரகசிய சமையல் குறிப்பு போல! இந்த ரகசியத்தை வைத்திருப்பவர்கள், அதை வெளியில் சொல்வதில்லை. அதனால், நாம் இன்று ChatGPT-க்கு போட்டியாக ஒரு மாதிரியை  எப்படி செய்வது என்று பார்க்கப் போவதில்லை. அதற்கு பதிலாக, இந்த மாதிரிகளின் திறன்களை தீர்மானிக்கும் முக்கியமான விஷயங்களை ஆராய்வோம்.

இப்போதெல்லாம், இந்த மாதிரிகளின் Training Process-ல் வெளிப்படைத்தன்மை குறைந்து வருகிறது. அதனால், இந்த மாதிரிகளின் உள்ளே என்ன நடக்கிறது என்று தெரிந்து கொள்வது கொஞ்சம் கடினம். ஆனால், இந்த மாதிரிகளுக்கு இடையே உள்ள வேறுபாடுகளை, அவை பயிற்சிக்கு பயன்படுத்தப்படும் தரவு (Training Data), மாதிரி கட்டமைப்பு (Model Architecture) மற்றும் அளவு (Size), மேலும் மனித விருப்பங்களுக்கு ஏற்ப அவற்றை எப்படி மேம்படுத்துகிறார்கள் (Post-training) என்பதன் மூலம் புரிந்து கொள்ளலாம்.

### **மாதிரியின்  அறிவு: தரவின் முக்கியத்துவம்**

மாதிரி தரவுகளில் இருந்து கற்றுக்கொள்கிறது. எனவே, நாம் பயன்படுத்தும் பயிற்சி தரவு அதன் வலிமை மற்றும் பலவீனங்களை வெளிப்படுத்துகிறது. உதாரணமாக, ஒரு மாதிரி, நிறைய சமையல் குறிப்புகளைப் படித்திருந்தால், அது உணவுகளைப் பற்றி துல்லியமாக பேசும். அதுவே ஒரு மாதிரி, நிறைய அறிவியல் கட்டுரைகளைப் படித்திருந்தால், அது அறிவியல் விஷயங்களைப் பற்றி துல்லியமாக பேசும். ஒரு மாதிரி  எவ்வளவு புத்திசாலியாக (smart) இருக்கும் என்பது, அது பயிற்சி பெற்ற தரவைப் பொறுத்துதான் இருக்கிறது. இது ஒரு மாணவர் எவ்வளவு நன்றாகப் படிக்கிறார் என்பது, அவர் படிக்கும் புத்தகங்கள்  மற்றும் பாடங்கள் எவ்வளவு தரமானவை என்பதைப் பொறுத்தது போன்றது. மாதிரி  தரவுகளை பயன்படுத்தி, அதன் அறிவை உருவாக்குகிறது. இந்த தரவுகள் எவ்வளவு தரமானவை மற்றும் எவ்வளவு பரவலானவை (**diverse**) என்பதைப் பொறுத்து மாதிரியின்  திறன் (**capability**) மாறுபடும்.

தரவின் தரம் மாதிரியின் செயல்திறனை (**performance**) நேரடியாக பாதிக்கிறது. உயர்தர தரவு (**High-quality data**) மாதிரி  துல்லியமான மற்றும் நம்பகமான (**reliable**) பதில்களை  வழங்க உதவுகிறது. உதாரணமாக, ஒரு மாதிரி  தமிழில் உயர்தர தரவுகளை பயன்படுத்தி பயிற்சி பெற்றால், அது தமிழில் துல்லியமான பதில்களை வழங்கும்.

Diversity of Data-அ, மாதிரி பல்வேறு சூழல்களில் (**various contexts**) செயல்பட உதவுகிறது மற்றும் பல்வேறு விஷயங்களைப் பற்றி கற்றுக்கொள்ளவும் உதவுகிறது. உதாரணமாக, ஒரு மாதிரி  பல்வேறு மொழிகளில் தரவுகளை பயன்படுத்தி பயிற்சி பெற்றால், அது பல்வேறு மொழிகளில் பேசும் திறனைப் பெறும். 

தரவின் அளவு (Quantity of Data) மாதிரியின் அறிவை விரிவுபடுத்த உதவுகிறது. பல்வேறு விஷயங்களைப் பற்றி கற்றுக்கொள்ள அதிக அளவு தரவுகள் (**Large amount of data**) உதவுகிறது. உதாரணமாக, ஒரு மாதிரி  நிறைய பூனை படங்களை (**Cat Images**) பார்த்திருந்தால், அது பூனைகளை (**Cats**) அடையாளம் கண்டுபிடிக்கும் திறனைப் பெறும்.

 சரி, இப்போது நீங்கள் ஒரு மாதிரியை  **"train"** செய்ய வேண்டும் என்று வைத்துக்கொள்வோம். அதற்கு நிறைய **"தரவு "** தேவை. ஆனால், **"தரவு "** சேகரிப்பது (**Data Collection**) அவ்வளவு எளிதான காரியம் இல்லை. அதற்கு நிறைய பணம் செலவாகும். அதனால், **"developers"** எல்லாரும் **"Common Crawl"** போன்ற **"open source data"**-ஐப் பயன்படுத்துகிறார்கள். இந்த Common Crawl-ல் எல்லா வகையான websites-ல் இருந்தும் தரவுகள் இருக்கும். அதில் நல்ல websites மற்றும் கெட்ட websites கலந்து இருக்கும். சில சமயம் fake news கூட இருக்கலாம். ஆனால், வேறு வழி இல்லாததால், "developers" இந்த தரவுகளை பயன்படுத்துகிறார்கள். Common Crawl தரவுகளை பயன்படுத்தி பயிற்சி செய்யப்பட்ட மாதிரி சில சமயம் **"biased"**-ஆக நடந்துகொள்ளலாம். அதாவது, சில விஷயங்களை (**Topics**) ஆதரிக்கலாம், சில விஷயங்களை எதிர்க்கலாம். 

தரவு சார்புகள் (Data Biases) மாதிரியின் செயல்திறனை பாதிக்கின்றன. இந்த சார்புகள் தரவுகள் சேகரிக்கப்படும் முறையில் (**collection methods**) உள்ள குறைபாடுகள் காரணமாக ஏற்படுகின்றன. உதாரணமாக, ஒரு மாதிரி  நிறைய ஆண்களின் படங்களை பார்த்திருந்தால், அது பெண்களின் படங்களை அடையாளம் கண்டுபிடிக்க முடியாது. அதனால், நாம் எந்த பணிக்கு மாதிரியை  பயன்படுத்தப் போகிறோம் என்று முடிவு செய்து, அதற்கு தகுந்த மாதிரி தரவுகளை தேர்ந்தெடுத்து செய்ய வேண்டும்.

நாம் ஏற்கனவே **Foundation Models**-ன் முக்கியத்துவத்தைப் பற்றி பார்த்தோம். இப்போது, இந்த மாதிரிகள் எப்படி உருவாக்கப்படுகின்றன என்பதை மூன்று முக்கிய கட்டங்களாக (**Pre-training, Fine-tuning மற்றும் Post-training**) பிரித்து, ஒவ்வொன்றையும் விரிவாகப் பார்ப்போம். இந்த கட்டங்கள் ஒவ்வொன்றும் ஒரு மாதிரியை  மேலும் மேலும் மேம்படுத்தி, அதை பயனர்களுக்கு பயனுள்ளதாக மாற்ற உதவுகின்றன.

**Pre-training** என்பது மாதிரிக்கு ஒரு அடிப்படை அறிவை (**foundational knowledge**) கொடுக்கும் கட்டம். இந்த கட்டத்தில், மாதிரி நிறைய தரவுகளை பயன்படுத்தி, பல்வேறு விஷயங்களைப் பற்றி கற்றுக்கொள்கிறது. இது ஒரு குழந்தை பள்ளிக்கு செல்லும் முன், அடிப்படை எழுத்து, எண்கள் போன்றவற்றைக் கற்றுக்கொள்வது போன்றது.

**எப்படி இது நடக்கிறது?**  
மாதிரி பல்வேறு தரவுகளை பார்க்கிறது - உரை (**text**), படங்கள் (**images**), ஒலி (**audio**) போன்றவை. இந்த தரவுகளை பயன்படுத்தி, மாதிரி சொற்களுக்கு இடையே உள்ள தொடர்புகளை கற்றுக்கொள்கிறது. உதாரணமாக, **"ராஜா"** என்ற சொல்லுக்கும் **"அரசன்"** என்ற சொல்லுக்கும் உள்ள தொடர்பை புரிந்துகொள்கிறது. நீங்கள் ஒரு மாதிரியை  **Pre-training** செய்ய, அதற்கு நிறைய புத்தகங்கள், கட்டுரைகள் மற்றும் இணைய தரவுகள் கொடுக்கிறீர்கள். இந்த தரவுகளை பயன்படுத்தி, மாதிரி பொதுவான அறிவைப் மட்டுமே பெறுகிறது. இதனால் இக்கட்டத்தில்  மாதிரி சரியான பதிலை (**Accurate Response**) சொல்லுவதற்கு முன்பாக, கொஞ்சம் **"fine-tune"** செய்ய வேண்டிய அவசியம் ஏற்படுகிறது.

**Fine-tuning** என்பது **Pre-training**-க்குப் பிறகு மாதிரியை மேலும் மேம்படுத்தும் ஒரு கட்டம். இந்த கட்டத்தில், மாதிரி குறிப்பிட்ட பணிகளுக்கு தன்னைத் தகவமைத்துக் கொள்கிறது. இது ஒரு குழந்தை பள்ளியில் அடிப்படை கல்வியை முடித்த பிறகு, ஒரு குறிப்பிட்ட பாடத்தில் நிபுணத்துவம் பெறுவது போன்றது.

**எப்படி இது நடக்கிறது?** **Fine-tuning**-ல் மாதிரி குறிப்பிட்ட பணிக்கு (**specific task**) தேவையான தரவுகளை பயன்படுத்தி பயிற்சி பெறுகிறது. உதாரணமாக, மருத்துவத் துறையில் (**medical domain**) **Fine-tuning** செய்ய, மருத்துவக் கட்டுரைகள் (**medical articles**), நோய்களின் விளக்கங்கள் (**disease descriptions**) மற்றும் மருந்துகள் (**drugs**) பற்றிய தரவுகள் பயன்படுத்தப்படுகின்றன.

நீங்கள் ஒரு நோயாளியின் அறிகுறிகளை மாதிரிக்கு விவரிக்கிறீர்கள் என வைத்துக்கொள்வோம். **Pre-trained** மாதிரி பொதுவான (**general**) பதில்களை (**responses**) மட்டுமே வழங்கும். ஆனால், **Fine-tuned** மாதிரி  மருத்துவத் துறையில் (**medical domain**) பயிற்சி பெற்றிருப்பதால், அது நோயாளியின் அறிகுறிகளுக்கு சரியான நோய் மற்றும் சிகிச்சையைப்  பற்றி துல்லியமாக பதில் சொல்லும்.

Pre-training  மற்றும் Fine-tuning-க்குப் பிறகு மாதிரியை  மேலும் மேம்படுத்தும் ஒரு கட்டம் தான் **"Post-training"**. இந்த கட்டத்தில், மாதிரி மனிதர்கள் எதிர்பார்ப்பது போன்ற பதில்களை (**Human-like Responses**) சொல்லும்படி பயிற்சி பெறுகிறது. இது ஒரு குழந்தை பள்ளியில் கற்றுக்கொண்ட பிறகு, உலகத்துடன் எப்படி இணைந்து செயல்பட வேண்டும் என்பதைக் கற்றுக்கொள்வது போன்றது.

**Pre-training** மற்றும் **Fine-tuning**-ல் மாதிரி பொதுவான மற்றும் குறிப்பிட்ட அறிவைப் பெறுகிறது. ஆனால், மனிதர்கள் எதிர்பார்ப்பது போன்ற பதில்களை (**Human-like Responses**) வழங்குவதற்கு, மாதிரி மனிதர்களின் விருப்பங்கள் (**preferences**), நடத்தை (**behavior**) மற்றும் எதிர்பார்ப்புகள் (**expectations**) ஆகியவற்றைப் புரிந்துகொள்ள வேண்டும். இது மாதிரி, மனிதர்களுடன் இணைந்து செயல்பட உதவுகிறது.

உதாரணமாக தர்க்கரீதியான மற்றும் பொருத்தமான பதில்கள் அளித்தால். மனிதர்கள் ஒரு கேள்வியை கேட்டால், அதற்கு ஒரு தர்க்கரீதியான (**logical**) மற்றும் பொருத்தமான (**relevant**) பதிலை (**response**) எதிர்பார்க்கிறார்கள். **Post-training** மூலம், மாதிரி இந்த எதிர்பார்ப்புகளை பூர்த்தி செய்யும் திறனைப் பெறுகிறது. 

Post-training-ல், மாதிரி மனிதர்களின் உரையாடல்களை பயன்படுத்தி பயிற்சி பெறுகிறது. இந்த உரையாடல்கள் மனிதர்களின் விருப்பங்கள் நடத்தை மற்றும் எதிர்பார்ப்புகள் ஆகியவற்றைப் புரிந்துகொள்ள உதவுகின்றன. மாதிரி **human feedback** பயன்படுத்தி பயிற்சி பெறுகிறது. இந்த பின்னூட்டம் மாதிரி எவ்வளவு நன்றாக செயல்படுகிறது என்பதை மதிப்பீடு செய்ய உதவுகிறது.

**Post-training**-க்குப் பிறகு, மாதிரி மனிதர்களின் எதிர்பார்ப்புகளை எவ்வளவு நன்றாக பூர்த்தி செய்கிறது என்பதை மதிப்பீடு செய்யப்படுகிறது. இதற்காக, **validation data** பயன்படுத்தப்படுகிறது.

சரி, இப்போது **"Sampling"** பற்றி பேசலாம். இது கொஞ்சம் கடினமான விஷயம். ஏனென்றால் நமது மாதிரி நிறைய பதில்களை சொல்லத் தெரிந்து வைத்திருக்கும். ஆனால், அதில் எந்த பதில் சரியானது என்று எப்படி முடிவு செய்யும்? அதற்குத்தான் இந்த **"Sampling"** பயன்படுகிறது. இதில் பல நுணுக்கங்கள் உள்ளன. சரியான நுணுக்கங்களைப் பயன்படுத்தினால், மாதிரி துல்லியமானபதிலை சொல்லும். இல்லையென்றால் பொருத்தமற்ற பதில்களைச் சொல்லும்.

**எப்படி இது நடக்கிறது?**  
மாதிரி ஒரு கேள்விக்கு பல பதில்களை உருவாக்குகிறது. இந்த பதில்களில் எது சரியானது என்று முடிவு செய்ய, **"Sampling Techniques"** பயன்படுத்தப்படுகின்றன. உதாரணமாக, **"Top-k Sampling"** அல்லது **"Temperature Sampling"** போன்ற முறைகள் பயன்படுத்தப்படுகின்றன. இந்த முறைகள், மாதிரி எந்த பதிலை தேர்ந்தெடுக்க வேண்டும் என்பதை நிர்ணயிக்கின்றன.

Language Generation மாதிரிகள், ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லையும் தேர்ந்தெடுக்கும். இந்த தேர்வு, சொற்களின் "நிகழ்தகவு" (probability) அடிப்படையில் நடைபெறுகிறது. Temperature அளவுரு, இந்த நிகழ்தகவுகளை எவ்வாறு பயன்படுத்துவது என்பதைக் கட்டுப்படுத்துகிறது.

மாதிரி ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லுக்கும் ஒரு நிகழ்தகவு மதிப்பைக் கணக்கிடுகிறது. உதாரணமாக, வாக்கியம்:
**"தமிழ் மொழி .…"**
இதற்கு மாதிரி பின்வரும் சொற்களைத் தேர்ந்தெடுக்கலாம்:

- **தொன்மையானது** — 50% நிகழ்தகவு
- **பழமையானது** — 30% நிகழ்தகவு
- **சிக்கலானது** — 15% நிகழ்தகவு
- **எளிமையானது** — 5% நிகழ்தகவு

Temperature 0 எனில், மாதிரி எப்போதும் அதிக நிகழ்தகவு உள்ள சொல்லைத் தேர்ந்தெடுக்கும். பதில்கள் மிகவும் துல்லியமாகவும், முன்னரே தீர்மானிக்கப்பட்டவையாகவும் இருக்கும். Temperature 0.5 எனில், மாதிரி அதிக நிகழ்தகவு உள்ள சொற்களை அடிக்கடி தேர்ந்தெடுக்கும், ஆனால் சில சமயங்களில் குறைந்த நிகழ்தகவு உள்ள சொற்களையும் தேர்ந்தெடுக்கலாம். Temperature 1 எனில், மாதிரி அனைத்து சொற்களையும் சமமான வாய்ப்புகளுடன் தேர்ந்தெடுக்கும். இது படைப்பாற்றலை அதிகரிக்கும், ஆனால் சில சமயங்களில் தவறான அல்லது பொருத்தமற்ற சொற்களையும் தேர்ந்தெடுக்கலாம். Temperature அதிகரிக்கும் போது, பதில்கள் படைப்பாற்றலுடன் இருக்கும், ஆனால் துல்லியம் குறையலாம் (hallucination). 

ஆங்கிலம்தான் இன்டர்நெட் உலகத்தில் கோலோச்சுகிறது  என்பது எல்லாருக்கும் தெரியும். **"Common Crawl"** போன்ற தரவுசெட்களை (**Datasets**) பார்த்தால், ஆங்கிலம்தான் அதிகமாக இருக்கிறது. அதற்கு அடுத்த இடத்தில் ரஷ்யன், ஜெர்மன், சீனம் போன்ற மொழிகள் உள்ளன. ஆனால், தமிழ் போன்ற மொழிகள் மிகவும் குறைவாக உள்ளன. இதனால்தான், இவற்றை **"low-resource languages"** என்று அழைக்கிறார்கள்.

இப்படி ஆங்கிலம் கோலோச்சுவதால், **"general-purpose models"** ஆங்கிலத்தில் தான் நன்றாக வேலை செய்கின்றன. தமிழ் போன்ற மொழிகளில் கொஞ்சம் சிரமம் உள்ளது. ஏனென்றால், தமிழில் இருக்கும் தரவு மிகவும் குறைவு. இது மட்டும் இல்லை, தமிழின் இலக்கணம் மற்றும் தொடரமைப்பு  போன்றவை கொஞ்சம் சிடுக்கானது. அதனால், தமிழ் போன்ற மொழிகளில் **LLM (Large Language Models)** உருவாக்குவது மிகவும் சிரமமானது. ஆனால், நமது தமிழிலும் நன்றாக வேலை செய்யும் மாதிரிகள் வரவேண்டும் என்று நிறைய பேர் முயற்சி செய்கிறார்கள். **"AI4Bharat"** போன்ற அமைப்புகள் தமிழில் தரவு சேகரித்து , **"open source"**-ஆக வெளியிடுகின்றன. இவை எல்லாம் தமிழில் **"LLM"** உருவாக்குவதற்கு மிகவும் உதவியாக இருக்கும். 

நாம் ஏற்கனவே பேசியது போல, **"general-purpose models"** பொதுவான விஷயங்களில் நன்றாக வேலை செய்யும். ஆனால், **"domain-specific tasks"**-ல் அவ்வளவு நன்றாக வேலை செய்யாது. ஏனென்றால், இந்த பணிகளுக்கு specific data தேவைப்படுகிறது. இந்த தரவு எல்லாம் நம்மால் எளிதாக சேகரிக்க முடியாது. உதாரணத்திற்கு, மருந்து கண்டுபிடிப்பதற்கு (**drug discovery**), புரோட்டீன் (**protein**), டிஎன்ஏ (**DNA**), ஆர்என்ஏ (**RNA**) போன்ற தரவு (**Data**) தேவைப்படும். அதேபோல், புற்றுநோயைக் கண்டுபிடிப்பதற்கு, எக்ஸ்ரே (**X-ray**), எஃப்எம்ஆர்ஐ ஸ்கேன்கள் (**fMRI scans**) போன்றவை தேவைப்படும். இந்த தரவு எல்லாம் மிகவும் விலை உயர்ந்தது அதோடு பிரைவசி பிரச்சனைகள் (**privacy issues**) காரணமாக எளிதாக கிடைக்காது.

அதனால், இந்த மாதிரி பணிகளுக்கு **"domain-specific models"** தேவைப்படுகின்றன. இந்த மாதிரிகள், அந்த டொமைனில் இருக்கும் தரவுவை பயன்படுத்தி பயிற்சி பெற்றிருக்கும். உதாரணத்திற்கு, **DeepMind**-இன் **AlphaFold** மாதிரி, புரோட்டீன் கட்டமைப்பை (**protein structure**) கண்டுபிடிப்பதிலும்,  **NVIDIA**-இன் **BioNeMo** மாதிரி மருந்து கண்டுபிடிப்பதிலும், **Google**-இன் **Med-PaLM2** மாதிரி, மருத்துவ கேள்விகளுக்கு (**medical questions**) பதில் சொல்வதிலும் சிறந்து விளங்குகின்றன.

இந்த மாதிரி **"domain-specific models"** எல்லா துறைகளிலும் பயனுள்ளதாக இருக்கும். ஆனால், இப்போதைக்கு பயோமெடிசினில் (**biomedicine**) தான் அதிகமாக பயன்படுத்தப்படுகின்றன. எதிர்காலத்தில் எல்லா துறைகளிலும் **"domain-specific models"** பயன்படுத்தப்படும்.

