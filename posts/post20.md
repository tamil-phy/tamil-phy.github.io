### பைடார்ச் அறிமுகம்

##### பைடார்ச் என்றால் என்ன?

பைடார்ச் (PyTorch) என்பது நவீன **Artificial Intelligence (AI)** மற்றும் **Machine Learning (ML)** பயன்பாடுகளுக்காக வடிவமைக்கப்பட்ட ஒரு திறந்த மூல **Deep Learning Framework** ஆகும். இது **Python** நிரலாக்க மொழியில் உருவாக்கப்பட்டுள்ளது மற்றும் **Meta AI** (முன்னர் Facebook AI Research - FAIR) நிறுவனத்தால் உருவாக்கப்பட்டு பராமரிக்கப்படுகிறது.

பைடார்ச் (PyTorch) என்பது நவீன AI மற்றும் மெஷின் லர்னிங் பயன்பாடுகளுக்காக வடிவமைக்கப்பட்ட ஒரு சக்திவாய்ந்த டீப் லர்னிங் ஃப்ரேம்வர்க் ஆகும், இது பைத்தான் மொழியில் உருவாக்கப்பட்டு Meta AI (முன்னர் Facebook AI Research) நிறுவனத்தால் பராமரிக்கப்படுகிறது. 

இதன் முக்கிய அம்சங்களில் **டென்சர்கள் (Tensors)** அடங்கும். இவை **NumPy array**-களைப் போன்றதாகவே செயல்படுகின்றன, அதாவது ஒரு அல்லது பல பரிமாணங்களில் தரவை நிர்வகிக்கக்கூடிய அமைப்பாகும். எனினும், NumPy-யில் இல்லாத சிறப்பம்சமாக, PyTorch டென்சர்கள் **GPU (Graphics Processing Unit)** ஆதரவுடன் செயல்படக்கூடியவையாக இருப்பது குறிப்பிடத்தக்கது. இதனால், பெரும் அளவிலான கணக்கீடுகளை (large-scale computations) மிகவேகமாக மேற்கொள்ள முடிகிறது. குறிப்பாக, deep learning மாடல்களில் training மற்றும் inference போன்று அதிக மதிப்பீடு தேவையுள்ள பணிகளில், டென்சர்கள் முக்கியப் பங்காற்றுகின்றன. மேலும், டென்சர்கள் இடையே நடத்தப்படும் கணிதச் செயல்கள் (matrix multiplication, broadcasting, reshaping) அனைத்தும் GPU-வில் இயக்கப்படுவதால், மென்மையான மற்றும் அதிக செயல்திறன் வாய்ந்த செயலாக்கத்தை வழங்குகின்றன. PyTorch-இல், டென்சர்களை CPU மற்றும் GPU இடையே எளிதாக நகர்த்தவும் (device transfer), அவற்றின் data type-ஐ மாற்றவும் (casting), gradients கணக்கிடவும் கூடுதலான வசதிகள் வழங்கப்படுகின்றன.

மேலும், **ஆட்டோமேடிக் டிஃபரன்ஷியேஷன் (Autograd)** அமைப்பு, PyTorch-இன் மிக முக்கியமான அம்சங்களில் ஒன்றாகும். இது **automatic differentiation engine** ஆக செயல்பட்டு, நியூரல் நெட்வொர்க்குகளில் **Backpropagation** செயல்முறையை தானாகவே கணக்கிடும் வகையில் வடிவமைக்கப்பட்டுள்ளது. பயனர் forward pass-ஐ எழுதும்போது, Autograd அந்த கணிப்புகளின் **computational graph**-ஐ தானாக உருவாக்குகிறது. பின்னர், backward pass இல், இது அனைத்துப் பராமிதிகளுக்கான gradients-ஐ கணக்கிட்டு, **gradient descent** போன்ற optimization algorithm-களுடன் இணைந்து செயல்படுகிறது. இதனால், gradients-ஐ கையால் கணக்கிட வேண்டிய தேவை இல்லாமல், விரைவாகவும் நம்பகமாகவும் deep learning மாடல்களை பயிற்சி செய்ய முடிகிறது.

பைடார்ச், **Hugging Face**, **TorchVision**, **TorchText** போன்ற பிரபலமான நூலகங்களுடன் நேரடியாக ஒருங்கிணைந்து செயல்படுகிறது. Hugging Face மூலம் மொழி மாதிரிகள் (language models), TorchVision மூலம் காட்சி அடிப்படையிலான மாதிரிகள் (vision models), TorchText மூலம் உரை அடிப்படையிலான மாதிரிகள் (text preprocessing, embedding layers) ஆகியவற்றை pre-trained format-ல் தரவிறக்கி, customizing மற்றும் fine-tuning செய்ய முடியும். இந்த ஒருங்கிணைப்பு பயனர்களுக்கு state-of-the-art மாதிரிகளை எளிதாக அணுகும் வாய்ப்பை வழங்குகிறது.

மேலும், பைடார்ச் **Pythonic Interface**-ஐ கொண்டுள்ளது என்பதாவது, Python நிரலாக்க மொழியின் இயல்புகள், விரிவுகள், மற்றும் நுட்பங்களை பின்பற்றும் வகையில் PyTorch வடிவமைக்கப்பட்டுள்ளது. இதனால், Python developers-க்கு PyTorch-இல் deep learning மாதிரிகள் உருவாக்கும் செயல்முறை மிகவும் இயல்பானதாகவும், வாசிக்க எளிமையானதாகவும் இருக்கும். எடுத்துக்காட்டாக, control flow statements (if, loops) மற்றும் native Python debugging tools-ஐ model definition-லேயே பயன்படுத்த முடியும், இது மற்ற framework-களில் சாத்தியமில்லாத ஒரு நன்மையாகும்.

**பைடார்சின் மூன்று முக்கிய கூறுகள்** — **டென்சர்கள் (Tensors)**, **ஆட்டோகிரேட் (Autograd)** மற்றும் **நியூரல் நெட்வொர்க் மாடியூல்கள் (torch.nn)** — இவை அனைத்தும் சேர்ந்து PyTorch-ஐ ஒரு சக்திவாய்ந்த மற்றும் வலுவான deep learning framework-ஆக மாற்றுகின்றன.

**டென்சர்கள்** என்பது பல பரிமாண தரவுகளைக் (multi-dimensional data) கையாளும் data structure ஆகும். இவை NumPy array-களைப் போலவே செயல்படுகின்றன ஆனால் கூடுதல் திறன்களுடன், குறிப்பாக **GPU acceleration** மூலம் அதிக வேகத்தில் கணக்கீடுகளைச் செய்ய முடியும். மேலும், டென்சர்களுக்கிடையேயான செயல்பாடுகள் (matrix multiplication, reshaping, broadcasting) அனைத்தும் NumPy API போலவே செயல்படுவதால், NumPy பயனர்களுக்கு கற்றுக்கொள்ள எளிதாக இருக்கிறது. PyTorch-இல் from_numpy() மற்றும் to_numpy() போன்ற functions மூலம் நேரடி மாற்றம் செய்யலாம். மேலும், .cuda() மற்றும் .to(device) போன்ற உத்திகள் மூலம் டென்சர்களை CPU ↔ GPU இடையே மாற்ற முடியும்.

**ஆட்டோகிரேட் (Autograd)** என்பது PyTorch-இல் **automatic differentiation**-ஐ செயல்படுத்தும் ஒரு கருப்பொருள். இது பயன்படுத்தப்படும் ஒவ்வொரு செயற்கை நரம்பியல் பராமிதி (learnable parameter) மீது கணித கணக்குகளைச் செய்யும் போது, அதன் derivative-ஐ தானாகவே கண்காணிக்கிறது. இது requires_grad=True என்ற flag மூலம் செயல்படுத்தப்படுகிறது. பின்னர் .backward() என்ற single command மூலம் network-இன் அனைத்து gradients-ஐ தானாக கணக்கிட முடிகிறது. இது model training-ஐ மிக எளிமையாகவும், code-ஐ தொகுப்பதற்காக நேர்த்தியாகவும் வைத்திருப்பதற்கு உதவுகிறது.

**torch.nn** என்பது PyTorch-இன் neural network மாடியூல் ஆகும். இதில் உள்ள உயர் மட்ட API-கள் (high-level APIs) வழியாக, பயனர்கள் எளிதாக custom neural networks-ஐ உருவாக்க முடியும். எடுத்துக்காட்டாக, nn.Linear, nn.Conv2d, nn.LSTM போன்றவை உடனடி பயன்பாட்டிற்குத் தயாராக உள்ளன. nn.Module என்பது அனைத்து user-defined networks-க்கான base class ஆக இருக்கிறது. இதன் மூலம் மிகச் சீரான மற்றும் maintain செய்யக்கூடிய architecture-களை உருவாக்க முடிகிறது.

மேலும், **loss functions** (nn.CrossEntropyLoss, nn.MSELoss) மற்றும் **optimizers** (torch.optim.SGD, torch.optim.Adam) ஆகியவையும் model training இல் முக்கிய பங்கு வகிக்கின்றன. இதனுடன், torchvision.models, transformers (Hugging Face), torchaudio போன்ற library-களின் மூலம் **pre-trained models**-ஐ import செய்து, **fine-tuning** செய்யும் வசதியும் உண்டு.

இவ்வாறான அனைத்து அம்சங்களும் சேர்ந்து PyTorch-ஐ **AI/ML ஆராய்ச்சி**, **prototype development**, மற்றும் **real-time production deployment** ஆகியவற்றுக்கான ஒரு சிறந்த தேர்வாக மாற்றுகின்றன. அதனாலேயே, பல நிறுவனங்களும் ஆராய்ச்சி நிறுவனங்களும் PyTorch-ஐ தங்கள் முக்கிய deep learning platform-ஆக தேர்ந்தெடுத்துள்ளன.

### டென்சர்கள் 

#### 1. டென்சர்களின் அடிப்படைக் கருத்து

##### 1.1 டென்சர் என்றால் என்ன?

டென்சர்கள் என்பது பல பரிமாணங்களில் தரவுகளை சேமிக்கும் கணித மற்றும் கம்ப்யூட்டேஷனல் கட்டமைப்புகள். இவை நவீன AI மற்றும் டீப் லர்னிங் அல்காரிதம்களின் அடிப்படைத் தரவு கட்டமைப்பாகும்.

**உதாரணமாக:**
- ஒரு பிக்சல் மதிப்பு → ஸ்கேலர் (0D டென்சர்)
- ஒரு வரிசை பிக்சல் மதிப்புகள் → வெக்டர் (1D டென்சர்)
- ஒரு கிரே ஸ்கேல் படம் → மெட்ரிக்ஸ் (2D டென்சர்)
- ஒரு RGB படம் → 3D டென்சர் (உயரம் × அகலம் × 3 வண்ண சேனல்கள்)
- ஒரு வீடியோ → 4D டென்சர் (நேரம் × உயரம் × அகலம் × சேனல்கள்)

##### 1.2 டென்சர் பண்புகள்

ஒவ்வொரு டென்சரும் பின்வரும் முக்கிய பண்புகளைக் கொண்டுள்ளது:

1. **ரேங்க் (Rank)**: டென்சரின் பரிமாணங்களின் எண்ணிக்கை
2. **ஷேப் (Shape)**: ஒவ்வொரு பரிமாணத்தின் அளவு
3. **டேட்டா டைப் (Data Type)**: தரவு வகை (float32, int64 போன்றவை)
4. **டிவைஸ் (Device)**: டென்சர் CPU அல்லது GPU-யில் உள்ளதா என்பது

#### 2. டென்சர் உருவாக்கம் மற்றும் மாற்றங்கள்

##### 2.1 அடிப்படை டென்சர் உருவாக்கம்

```python
import torch

# வெவ்வேறு ரேங்க் கொண்ட டென்சர்கள்
scalar = torch.tensor(5)                    # ஸ்கேலர் (ரேங்க் 0)
vector = torch.tensor([1, 2, 3])            # வெக்டர் (ரேங்க் 1)
matrix = torch.tensor([[1, 2], [3, 4]])     # மெட்ரிக்ஸ் (ரேங்க் 2)
tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # 3D டென்சர்

print(f"ஸ்கேலர்: {scalar}, ரேங்க்: {scalar.ndim}")
print(f"வெக்டர்: {vector}, ரேங்க்: {vector.ndim}")
print(f"மெட்ரிக்ஸ்:\n{matrix}, ரேங்க்: {matrix.ndim}")
print(f"3D டென்சர்:\n{tensor_3d}, ரேங்க்: {tensor_3d.ndim}")
```

##### 2.2 ஸ்பெஷல் டென்சர்கள்

பைடார்ச் பல்வேறு வகையான ஸ்பெஷல் டென்சர்களை உருவாக்க உதவுகிறது:

```python
# சுழியங்களால் நிரப்பப்பட்ட டென்சர்
zeros = torch.zeros(2, 3, dtype=torch.float32)
print("சுழியங்களின் டென்சர்:\n", zeros)

# ஒன்றுகளால் நிரப்பப்பட்ட டென்சர்
ones = torch.ones(2, 3, dtype=torch.float32)
print("\nஒன்றுகளின் டென்சர்:\n", ones)

# ரேண்டம் மதிப்புகளுடன் டென்சர் (0 மற்றும் 1 இடையே)
rand_tensor = torch.rand(2, 3)
print("\nரேண்டம் டென்சர் (0-1):\n", rand_tensor)

# இயல்பான பரவலில் ரேண்டம் டென்சர்
randn_tensor = torch.randn(2, 3)
print("\nஇயல்பான பரவல் டென்சர்:\n", randn_tensor)

# ஐடென்டிட்டி மெட்ரிக்ஸ்
identity = torch.eye(3)
print("\nஐடென்டிட்டி மெட்ரிக்ஸ்:\n", identity)

# அரேஞ்ச் டென்சர்
arange_tensor = torch.arange(0, 10, 2)  # 0 முதல் 10 வரை 2 இடைவெளியில்
print("\nஅரேஞ்ச் டென்சர்:", arange_tensor)

# லின்ஸ்பேஸ் டென்சர்
linspace_tensor = torch.linspace(0, 1, 5)  # 0 முதல் 1 வரை 5 சம புள்ளிகள்
print("\nலின்ஸ்பேஸ் டென்சர்:", linspace_tensor)
```

##### 3. டென்சர் பண்புகள் மற்றும் அட்ரிபியூட்டுகள்

ஒரு டென்சரின் பண்புகளை பின்வரும் முறைகளில் அணுகலாம்:

```python
tensor = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)

print("டென்சர் ஷேப்:", tensor.shape)      # torch.Size([2, 2])
print("டேட்டா டைப்:", tensor.dtype)       # torch.float32
print("டென்சர் ரேங்க்:", tensor.ndim)     # 2
print("உறுப்புகளின் எண்ணிக்கை:", tensor.numel())  # 4
print("டிவைஸ்:", tensor.device)           # cpu
```

#### 4. டென்சர் ஆபரேஷன்கள் - விரிவான விளக்கம்

##### 4.1 அடிப்படை கணித செயல்பாடுகள்

```python
a = torch.tensor([1, 2, 3], dtype=torch.float32)
b = torch.tensor([4, 5, 6], dtype=torch.float32)

# கூட்டல் (எலிமென்ட்-வைஸ்)
print("கூட்டல்:", a + b)  # tensor([5., 7., 9.])

# கழித்தல் (எலிமென்ட்-வைஸ்)
print("கழித்தல்:", a - b)  # tensor([-3., -3., -3.])

# பெருக்கல் (எலிமென்ட்-வைஸ்)
print("எலிமென்ட் வைஸ் பெருக்கல்:", a * b)  # tensor([ 4., 10., 18.])

# வகுத்தல் (எலிமென்ட்-வைஸ்)
print("வகுத்தல்:", b / a)  # tensor([4.0000, 2.5000, 2.0000])

# டாட் ப்ராடக்ட் (உள் பெருக்கல்)
print("டாட் ப்ராடக்ட்:", torch.dot(a, b))  # tensor(32.)

# எக்ஸ்போனென்ஷியேஷன்
print("எக்ஸ்போனென்ஷியேஷன்:", a ** 2)  # tensor([1., 4., 9.])
```

##### 4.2 மெட்ரிக்ஸ் ஆபரேஷன்கள்

```python
A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)
B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)

# மெட்ரிக்ஸ் பெருக்கல்
print("மெட்ரிக்ஸ் பெருக்கல்:\n", torch.matmul(A, B))
# tensor([[19., 22.],
#         [43., 50.]])

# @ ஆபரேட்டரைப் பயன்படுத்தி மெட்ரிக்ஸ் பெருக்கல்
print("@ ஆபரேட்டர்:\n", A @ B)

# டிரான்ஸ்போஸ்
print("டிரான்ஸ்போஸ்:\n", A.T)
# tensor([[1., 3.],
#         [2., 4.]])

# டெர்மினண்ட்
print("டெர்மினண்ட்:", torch.det(A))  # tensor(-2.)

# இன்வர்ஸ்
print("இன்வர்ஸ்:\n", torch.inverse(A))
# tensor([[-2.0000,  1.0000],
#         [ 1.5000, -0.5000]])

# டயகனல்
print("டயகனல்:", torch.diag(A))  # tensor([1., 4.])
```

##### 4.3 ரீஷேப்பிங் மற்றும் வியூ ஆபரேஷன்கள்

```python
tensor = torch.arange(1, 7)  # tensor([1, 2, 3, 4, 5, 6])

# ரீஷேப் செய்தல்
reshaped = tensor.reshape(2, 3)
print("ரீஷேப் செய்யப்பட்டது:\n", reshaped)
# tensor([[1, 2, 3],
#         [4, 5, 6]])

# வியூ மெத்தட்
viewed = tensor.view(3, 2)
print("வியூ மெத்தட்:\n", viewed)
# tensor([[1, 2],
#         [3, 4],
#         [5, 6]])

# ஸ்குவீஸ் மற்றும் அன்ஸ்குவீஸ்
tensor_3d = torch.randn(1, 3, 1, 4)
print("அசல் ஷேப்:", tensor_3d.shape)  # torch.Size([1, 3, 1, 4])

squeezed = tensor_3d.squeeze()  # அளவு 1 உள்ள பரிமாணங்களை நீக்குகிறது
print("ஸ்குவீஸ்டு ஷேப்:", squeezed.shape)  # torch.Size([3, 4])

unsqueezed = squeezed.unsqueeze(0)  # புதிய பரிமாணத்தை சேர்க்கிறது
print("அன்ஸ்குவீஸ்டு ஷேப்:", unsqueezed.shape)  # torch.Size([1, 3, 4])
```

#### 5. டென்சர் டைப் மாற்றங்கள் மற்றும் GPU-க்கு மாற்றுதல்

##### 5.1 டேட்டா டைப் மாற்றங்கள்

```python
# இன்டீஜர் டென்சர்
int_tensor = torch.tensor([1, 2, 3])
print("இன்டீஜர் டென்சர்:", int_tensor.dtype)  # torch.int64

# ஃப்ளோட் டென்சராக மாற்றுதல்
float_tensor = int_tensor.float()
print("ஃப்ளோட் டென்சர்:", float_tensor.dtype)  # torch.float32

# டைப்பை நேரடியாக குறிப்பிடுதல்
double_tensor = torch.tensor([1, 2, 3], dtype=torch.double)
print("டபுள் டென்சர்:", double_tensor.dtype)  # torch.float64

# டைப் மாற்றம் using .to()
bool_tensor = int_tensor.to(torch.bool)
print("பூலியன் டென்சர்:", bool_tensor)  # tensor([True, True, True])
```

##### 5.2 GPU-க்கு மாற்றுதல்

```python
# GPU கிடைக்கிறதா என சரிபார்த்தல்
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("பயன்படுத்தப்படும் சாதனம்:", device)

# டென்சரை GPU-க்கு மாற்றுதல்
tensor = torch.tensor([[1, 2], [3, 4]])
tensor_gpu = tensor.to(device)
print("GPU டென்சர்:", tensor_gpu.device)

# GPU-இல் நேரடியாக டென்சர் உருவாக்கம்
if torch.cuda.is_available():
    gpu_tensor = torch.rand(2, 3, device='cuda')
    print("GPU-இல் உருவாக்கப்பட்ட டென்சர்:", gpu_tensor.device)
```

##### 6. டென்சர் இன்டெக்ஸிங் மற்றும் ஸ்லைசிங்

NumPy-யைப் போலவே, பைடார்ச் டென்சர்களுக்கு இன்டெக்ஸிங் மற்றும் ஸ்லைசிங் ஆபரேஷன்கள் உள்ளன:

```python
tensor = torch.arange(1, 10).reshape(3, 3)
print("அசல் டென்சர்:\n", tensor)
# tensor([[1, 2, 3],
#         [4, 5, 6],
#         [7, 8, 9]])

# ஒரு எலிமென்டை அணுகுதல்
print("முதல் வரிசை, முதல் நெடுவரிசை:", tensor[0, 0])  # tensor(1)

# ஒரு வரிசையை அணுகுதல்
print("முதல் வரிசை:", tensor[0, :])  # tensor([1, 2, 3])

# ஒரு நெடுவரிசையை அணுகுதல்
print("முதல் நெடுவரிசை:", tensor[:, 0])  # tensor([1, 4, 7])

# ஸ்லைசிங்
print("முதல் இரண்டு வரிசைகள்:\n", tensor[:2, :])
# tensor([[1, 2, 3],
#         [4, 5, 6]])

# அட்வான்ஸ்டு இன்டெக்ஸிங்
indices = torch.tensor([0, 2])
print("செலக்டட் வரிசைகள்:\n", tensor[indices, :])
# tensor([[1, 2, 3],
#         [7, 8, 9]])

# பூலியன் மாஸ்கிங்
mask = tensor > 5
print("பூலியன் மாஸ்க்:\n", mask)
# tensor([[False, False, False],
#         [False, False,  True],
#         [ True,  True,  True]])
print("மாஸ்க்டு மதிப்புகள்:", tensor[mask])  # tensor([6, 7, 8, 9])
```

##### 7. ப்ராட்காஸ்டிங் (Broadcasting)

ப்ராட்காஸ்டிங் என்பது வெவ்வேறு ஷேப்புகள் கொண்ட டென்சர்களுக்கு இடையே செயல்பாடுகளைச் செய்ய அனுமதிக்கும் ஒரு சக்திவாய்ந்த மெக்கானிசம்:

```python
# ஸ்கேலருடன் பெருக்கல் (ப்ராட்காஸ்ட்)
tensor = torch.ones(2, 3)
result = tensor * 5
print("ஸ்கேலருடன் பெருக்கல்:\n", result)
# tensor([[5., 5., 5.],
#         [5., 5., 5.]])

# வெக்டருடன் கூட்டல் (ப்ராட்காஸ்ட்)
vector = torch.tensor([1, 2, 3])
result = tensor + vector
print("வெக்டருடன் கூட்டல்:\n", result)
# tensor([[2., 3., 4.],
#         [2., 3., 4.]])

# மெட்ரிக்ஸுடன் கூட்டல் (ப்ராட்காஸ்ட்)
matrix = torch.tensor([[1], [2]])
result = tensor + matrix
print("மெட்ரிக்ஸுடன் கூட்டல்:\n", result)
# tensor([[2., 2., 2.],
#         [3., 3., 3.]])
```

#### 8. நிஜ உலக பயன்பாடுகள்

##### 8.1 பட செயலாக்கம்

```python
# 3D டென்சர் (உயரம் × அகலம் × RGB சேனல்கள்)
image = torch.randn(256, 256, 3)  # 256x256 RGB படம்

# படத்தை 4D டென்சராக மாற்றுதல் (பேட்ச் × சேனல்கள் × உயரம் × அகலம்)
batch_images = image.permute(2, 0, 1).unsqueeze(0)
print("பேட்ச்டு பட டென்சர் ஷேப்:", batch_images.shape)  # torch.Size([1, 3, 256, 256])
```

##### 8.2 NLP பயன்பாடுகள்

```python
# வார்த்தை உட்புகுத்துதல்கள் (Word Embeddings)
vocab_size = 10000
embedding_dim = 300
word_embeddings = torch.randn(vocab_size, embedding_dim)

# ஒரு வாக்கியத்திற்கான உட்புகுத்துதல்கள்
sentence = torch.tensor([42, 7, 1023, 56])  # வார்த்தை ஐடிகள்
embeddings = word_embeddings[sentence]
print("வாக்கிய உட்புகுத்துதல்கள் ஷேப்:", embeddings.shape)  # torch.Size([4, 300])
```

##### 8.3 வீடியோ ப்ராசெஸிங்

```python
# 4D டென்சர் (பேட்ச் × சேனல்கள் × நேரம் × உயரம் × அகலம்)
video = torch.randn(1, 3, 32, 256, 256)  # 1 பேட்ச், 3 சேனல்கள், 32 ஃப்ரேம்கள், 256x256
print("வீடியோ டென்சர் ஷேப்:", video.shape)
```

#### 9. முக்கியமான குறிப்புகள் மற்றும் சிறந்த நடைமுறைகள்

1. **மெமரி மேனேஜ்மென்ட்**:
   - `view()` vs `reshape()`: `view()` மூல டென்சரின் மெமரியைப் பகிர்ந்து கொள்கிறது, `reshape()` புதிய மெமரியை ஒதுக்கலாம்
   - `clone()`: டென்சரின் உண்மையான நகலை உருவாக்குகிறது

2. **GPU பயன்பாடு**:
   - பெரிய டேட்டாசெட்டுகளுக்கு GPU பயன்பாடு கணிசமான வேக அதிகரிப்பைத் தரும்
   - `.to(device)` முறையைப் பயன்படுத்தி CPU/GPU-க்கு இடையே மாற்றவும்

3. **ஆட்டோகிரேட்**:
   - `requires_grad=True` அமைப்பதன் மூலம் கிரேடியண்ட்களை தானாக கணக்கிடலாம்
   ```python
   x = torch.tensor(2.0, requires_grad=True)
   y = x**2
   y.backward()
   print(x.grad)  # dy/dx = 2x → 4.0
   ```

4. **டென்சர் டைப்கள்**:
   - float32 பொதுவாக டீப் லர்னிங்கிற்கு போதுமானது
   - int64 இன்டெக்ஸிங்கிற்கு பயன்படுகிறது

5. **டென்சர் ஆபரேஷன்களின் செயல்திறன்**:
   - பெரிய டென்சர்களில் இன்பிளேஸ் ஆபரேஷன்களைத் தவிர்க்கவும்
   - `torch.no_grad()` கான்டெக்ஸ்டைப் பயன்படுத்தி கிரேடியண்ட் கணக்கீடுகளைத் தவிர்க்கவும்

#### 10. மேம்பட்ட டென்சர் ஆபரேஷன்கள்

##### 10.1 கான்காடினேஷன் (Concatenation)

```python
a = torch.tensor([[1, 2], [3, 4]])
b = torch.tensor([[5, 6]])

# வரிசைகளில் இணைத்தல் (dim=0)
print("வரிசைகளில் இணைத்தல்:\n", torch.cat((a, b), dim=0))
# tensor([[1, 2],
#         [3, 4],
#         [5, 6]])

# நெடுவரிசைகளில் இணைத்தல் (dim=1)
b_vert = torch.tensor([[5], [6]])
print("நெடுவரிசைகளில் இணைத்தல்:\n", torch.cat((a, b_vert), dim=1))
# tensor([[1, 2, 5],
#         [3, 4, 6]])
```

##### 10.2 ஸ்டேக்கிங் (Stacking)

```python
a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])

# ஸ்டேக்கிங் (புதிய பரிமாணத்தை உருவாக்குகிறது)
print("ஸ்டேக் செய்யப்பட்டது:\n", torch.stack((a, b)))
# tensor([[1, 2, 3],
#         [4, 5, 6]])
print("ஸ்டேக் செய்யப்பட்ட டென்சர் ஷேப்:", torch.stack((a, b)).shape)  # torch.Size([2, 3])
```

##### 10.3 ஸ்ப்லிடிங் (Splitting)

```python
tensor = torch.arange(10).reshape(2, 5)
print("அசல் டென்சர்:\n", tensor)

# ஸ்ப்லிட் செய்தல்
chunks = torch.split(tensor, 2, dim=1)
print("ஸ்ப்லிட் செய்யப்பட்ட பகுதிகள்:")
for i, chunk in enumerate(chunks):
    print(f"பகுதி {i+1}:\n", chunk)
```

#### 11. டென்சர்களின் முக்கியத்துவம் AI/ML-இல்

1. **நியூரல் நெட்வொர்க்குகளுக்கான தரவு கட்டமைப்பு**:
   - அனைத்து டீப் லர்னிங் மாடல்களும் உள்ளீடு மற்றும் வெளியீடு டென்சர்களை எதிர்பார்க்கின்றன

2. **GPU துரிதப்படுத்தல்**:
   - டென்சர்கள் GPU-களில் திறம்பட செயல்படுத்தப்படுகின்றன

3. **ஆட்டோமேடிக் டிஃபரன்ஷியேஷன்**:
   - பைடார்சின் `autograd` அமைப்பு டென்சர்களுடன் நேரடியாக வேலை செய்கிறது

4. **டிஸ்ட்ரிப்யூடட் கம்ப்யூட்டிங்**:
   - டென்சர்கள் பல GPU-கள் மற்றும் மெஷின்களில் விநியோகிக்கப்படலாம்

டென்சர்கள் பைடார்ச் ஃப்ரேம்வர்க்கின் அடிப்படைக் கட்டுமானத் தொகுதிகள். இவற்றை நன்கு புரிந்துகொள்வது:

- திறம்பட்ட AI/ML மாடல்களை உருவாக்க உதவுகிறது
- டேட்டா ப்ராசெஸிங் மற்றும் மாற்றங்களை எளிதாக்குகிறது
- GPU-களின் முழு சக்தியைப் பயன்படுத்த அனுமதிக்கிறது
- சிக்கலான நியூரல் நெட்வொர்க் ஆர்கிடெக்சர்களை செயல்படுத்த உதவுகிறது

டென்சர்களின் கருத்துக்கள் மற்றும் பைடார்சில் அவற்றின் செயலாக்கத்தை நன்கு புரிந்துகொள்வது எந்தவொரு AI/ML இன்ஜினியர் அல்லது ஆராய்ச்சியாளருக்கும் அத்தியாவசியமான திறமையாகும்.