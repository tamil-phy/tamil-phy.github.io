[toc]



#### 1. இயல் மொழி தெளிதல் - Natural Language Processing (NLP)  

NLP என்பது கணினிகள் மனித மொழியைப் புரிந்து கொள்ளவும், செயல்படவும் உதவும் ஒரு தொழில்நுட்பம்.  மனித மொழி மிகவும் சிக்கலானது. இது வார்த்தைகள், இலக்கண விதிகள், மற்றும் சூழல் அடிப்படையிலான அர்த்தங்களைக் கொண்டுள்ளது. கணினிகள் இந்த மொழியைப் புரிந்து கொள்ள, பல  படிநிலைகளைப் பயன்படுத்துகின்றன:  

NLP-இன் வளர்ச்சி பல தசாப்தங்களாக நீண்டு வந்துள்ளது. மொழியியல் விதிகளை (Rule-Based Systems 1950s - 1980s) அடிப்படையாகக் கொண்டு, கணினிகள் உரையைப் புரிந்து கொள்ள முயற்சித்தன. உதாரணமாக,  ELIZA (1966) முதல் சாட்பாட்.   புள்ளியியல் முறைகள் (Statistical NLP 1990s - 2000s) மூலம், கணினிகள் உரையைப் பகுப்பாய்வு செய்யத் தொடங்கின. Hidden Markov Models (HMMs), Machine Translation.  Machine Learning (2010s) அல்காரிதம்கள் (எ.கா., SVM, Random Forest) NLP பணிகளுக்குப் பயன்படுத்தப்பட்டன.  எடுத்துக்காட்டாக Sentiment Analysis, Text Classification. Deep Learning மற்றும் Transformer (2017 - தற்போது) மாதிரிகள் (எ.கா., BERT, GPT) NLP-இல் புரட்சியை ஏற்படுத்தியுள்ளன.  இந்த கட்டுரையில், NLP-இன் முக்கிய கருத்துக்களைப் பற்றி மிகவும் விரிவாகப் பார்ப்போம் மற்றும் Python-ஐப் பயன்படுத்தி ஒவ்வொரு கருத்தையும் நடைமுறையில் செய்து பார்ப்போம். 

##### 1.1. Tokenization  

Tokenization என்பது உரையை சிறிய பகுதிகளாக (வார்த்தைகள், வாக்கியங்கள், அல்லது எழுத்துகள்) பிரிக்கும் செயல்முறை. இது NLP-இன் முதல் படியாகும். Tokenization உரையை கணினிகள் புரிந்து கொள்ளும் வகையில் எளிதாக்குகிறது.  

1. **Word Tokenization:** உரையை வார்த்தைகளாக பிரிக்கிறது.  
   - உரை: "I love NLP."  
   - Tokenization: ["I", "love", "NLP", "."]  

2. **Sentence Tokenization:** உரையை வாக்கியங்களாக பிரிக்கிறது.  
   - உரை: "Hello! How are you? I hope you are doing well."  
   - Tokenization: ["Hello!", "How are you?", "I hope you are doing well."]  

உரையை சிறிய பகுதிகளாக பிரிப்பது, கணினிகள் உரையை பகுப்பாய்வு செய்ய உதவுகிறது. இது உரை தரவுகளை எளிதாக்குகிறது மற்றும் பிற NLP பணிகளுக்கு அடிப்படையாகும்.   

```python
from nltk.tokenize import word_tokenize, sent_tokenize

# உரை (Text)
text = "Hello! How are you? I hope you are doing well."

# வார்த்தைகளாக துண்டாக்கம் (Word Tokenization)
words = word_tokenize(text)
print("Words:", words)

# வாக்கியங்களாக துண்டாக்கம் (Sentence Tokenization)
sentences = sent_tokenize(text)
print("Sentences:", sentences)
```

**Output:**  
```
Words: ['Hello', '!', 'How', 'are', 'you', '?', 'I', 'hope', 'you', 'are', 'doing', 'well', '.']
Sentences: ['Hello!', 'How are you?', 'I hope you are doing well.']
```

---

##### 1.2. Stop Words Removal
Stop Words என்பது மொழியில் அடிக்கடி வரும் ஆனால் முக்கியமில்லாத சொற்கள். எடுத்துக்காட்டாக, "the", "is", "in", "and" போன்றவை. இவை உரையின் பொருளை பாதிக்காது, ஆனால் NLP மாதிரிகளின் செயல்திறனை குறைக்கும்.  

**எடுத்துக்காட்டு:**  
- உரை: "This is a simple example."  
- Stop Words Removal: ["This", "simple", "example", "."]  

தரவு செயலாக்கத்தை வேகமாக்குகிறது. மாதிரிகளின் துல்லியத்தை மேம்படுத்துகிறது.  

```python
from nltk.corpus import stopwords

# உரை (Text)
text = "This is a simple example of removing stop words."

# Stop words-ஐப் பெறுதல்
stop_words = set(stopwords.words('english'))

# Tokenization
words = word_tokenize(text)

# Stop words-ஐ நீக்குதல்
filtered_words = [word for word in words if word.lower() not in stop_words]
print("Filtered Words:", filtered_words)
```

**Output:**  
```
Filtered Words: ['This', 'simple', 'example', 'removing', 'stop', 'words', '.']
```

---

##### 1.3. Stemming (வேர்ச்சொல் பிரித்தல்)  
Stemming என்பது வார்த்தையின் மூல வடிவத்தைப் பிரிக்கும் செயல்முறை. இது சொல்லின் பொருளை மாற்றாமல், அதன் அடிப்படை வடிவத்தைக் கொடுக்கும்.  

**எடுத்துக்காட்டு:**  
- "running" -> "run"  
- "jumps" -> "jump"  

உரையில் உள்ள வார்த்தைகளை ஒரே மாதிரியாக மாற்றுகிறது. தரவு செயலாக்கத்தை எளிதாக்குகிறது.  

```python
from nltk.stem import PorterStemmer

# உரை (Text)
words = ["running", "jumps", "easily", "fairly"]

# Stemmer
stemmer = PorterStemmer()

# Stemming
stemmed_words = [stemmer.stem(word) for word in words]
print("Stemmed Words:", stemmed_words)
```

**Output:**  
```
Stemmed Words: ['run', 'jump', 'easili', 'fairli']
```

---

##### 1.4. Lemmatization   
Lemmatization என்பது Stemming-ஐப் போலவே, ஆனால் சொல்லின் சரியான வடிவத்தைப் பிரிக்கும். இது சொல்லின் பொருளை மாற்றாமல், அதன் அகராதி வடிவத்தைக் கொடுக்கும்.  

**எடுத்துக்காட்டு:**  

- "running" -> "run"   

  Stemming-ஐ விட துல்லியமானது. சொல்லின் பொருளை பாதுகாக்கிறது.  

```python
from nltk.stem import WordNetLemmatizer

# உரை (Text)
words = ["running", "jumps", "easily", "better"]

# Lemmatizer
lemmatizer = WordNetLemmatizer()

# Lemmatization
lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
print("Lemmatized Words:", lemmatized_words)
```

**Output:**  
```
Lemmatized Words: ['running', 'jump', 'easily', 'better']
```

---

##### 1.5. Part-of-Speech Tagging   
POS Tagging என்பது வார்த்தைகளின் வகையை (பெயர்ச்சொல், வினைச்சொல், உரிச்சொல்) கண்டறியும் செயல்முறை.  

**எடுத்துக்காட்டு:**  

- "I love NLP."  
- POS Tags: [('I', 'PRP'), ('love', 'VBP'), ('NLP', 'NNP'), ('.', '.')]  

உரையின் கட்டமைப்பை புரிந்து கொள்ள உதவுகிறது.  பிற NLP பணிகளுக்கு பயனுள்ளது.   

```python
from nltk import pos_tag

# உரை (Text)
text = "I love learning NLP."

# Tokenization
words = word_tokenize(text)

# POS Tagging
pos_tags = pos_tag(words)
print("POS Tags:", pos_tags)
```

**Output:**  
```
POS Tags: [('I', 'PRP'), ('love', 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP'), ('.', '.')]
```

---

##### 1.6. Named Entity Recognition (NER) 
NER என்பது உரையில் உள்ள முக்கியமான பெயர்களை (நபர்கள், இடங்கள், நிறுவனங்கள்) அங்கீகரிக்கும் செயல்முறை.  

**எடுத்துக்காட்டு:**  
- உரை: "Apple is located in Cupertino."  
- NER: Apple (ORG), Cupertino (LOC)  

உரையில் உள்ள முக்கிய தகவல்களை பிரித்தெடுக்க உதவுகிறது. இது தரவு பகுப்பாய்வுக்கு பயனுள்ளது.  

```python
import spacy

# spaCy மாதிரியை ஏற்றுதல்
nlp = spacy.load("en_core_web_sm")

# உரை (Text)
text = "Apple is located in Cupertino."

# NER
doc = nlp(text)
for ent in doc.ents:
    print(ent.text, ent.label_)
```

**Output:**  

```
Apple ORG
Cupertino GPE
```

---

##### 1.7. Sentiment Analysis 
Sentiment Analysis என்பது உரையில் உள்ள உணர்ச்சிகளைப் பகுப்பாய்வு செய்யும் செயல்முறை. இது பொதுவாக நேர்மறை, எதிர்மறை, அல்லது நடுநிலை என வகைப்படுத்தப்படுகிறது.  

**எடுத்துக்காட்டு:**  
- உரை: "I love this product!"  
- Sentiment: Positive  

Why Use Sentiment Analysis?  

- வாடிக்கையாளர் கருத்துகளை பகுப்பாய்வு செய்ய உதவுகிறது.  
- சமூக ஊடக தரவுகளை புரிந்து கொள்ள உதவுகிறது.  

Python Example  

```python
from textblob import TextBlob

# உரை (Text)
text = "I love this product!"

# Sentiment Analysis
blob = TextBlob(text)
sentiment = blob.sentiment
print("Sentiment:", sentiment)
```

**Output:**  

```
Sentiment: Sentiment(polarity=0.625, subjectivity=0.6)
```

அதாவது, **Polarity** என்பது உரையின் உணர்வை (Positive/Negative/Neutral) அளவிடும் ஒரு மதிப்பு ஆகும்.

Polarity மதிப்பு **-1 முதல் +1** வரை இருக்கும்.

**+1:** Highly Positive

**0**: Neutral

**-1:** Highly Negative

இங்கு, **Polarity = 0.625** என்பதால், இந்த உரை Positive உணர்வைக் காட்டுகிறது.

**Subjectivity** என்பது உரையில் உள்ள தனிப்பட்ட (Personal) கருத்துகள் மற்றும் உணர்வுகளின் அளவை காண்பிக்கும் ஒரு மதிப்பு ஆகும்.

Subjectivity மதிப்பு **0 முதல் 1** வரை இருக்கும்:

**0:** Completely Objective

**1:** Completely Subjective

இங்கு, **Subjectivity = 0.6** என்பதால், இந்த உரை Subjective கருத்துகளுடன் அதிகமாக இருக்கிறது. இது உரை எழுதுபவரின் தனிப்பட்ட சிந்தனை மற்றும் உணர்ச்சியை அதிகமாக பிரதிபலிக்கிறது.

Code: [Colab Notebook](https://colab.research.google.com/drive/1kjYcGSH0bqGhV7jPeZ5wx2oaXu4sCUQB?usp=sharing)

#### 2. இயல் மொழி தெளிதல் : எளிய சாட்பாட்(Chatbot) உருவாக்குதல்  

இந்த பயிற்சியில், Python-ஐப் பயன்படுத்தி ஒரு எளிய சாட்பாட்டை உருவாக்குவோம். இந்த சாட்பாட் பயனரின் உரையைப் புரிந்து கொண்டு, பொருத்தமான பதில்களை வழங்கும். இது **Rule-Based Chatbot** என்று அழைக்கப்படுகிறது, ஏனெனில் இது முன்-வரையறுக்கப்பட்ட விதிகளைப் பயன்படுத்தி பதில்களை வழங்குகிறது.  

---

##### 2.1. சாட்பாட் என்றால் என்ன?  

சாட்பாட் என்பது ஒரு மென்பொருள் பயன்பாடு ஆகும், இது மனிதர்களுடன் உரையாடுவதற்காக வடிவமைக்கப்பட்டுள்ளது. இது பயனரின் உரையைப் புரிந்து கொண்டு, பொருத்தமான பதில்களை வழங்குகிறது. சாட்பாட்கள் பொதுவாக **Rule-Based** அல்லது **AI-Based** (Machine Learning/Deep Learning) ஆக இருக்கலாம்.  

**Rule-Based சாட்பாட்கள்** என்பவை முன்னரே வரையறுக்கப்பட்ட விதிகள் மற்றும் வடிவங்களின் அடிப்படையில் செயல்படுகின்றன. இவை எளிய மற்றும் குறிப்பிட்ட பணிகளுக்கு ஏற்றவையாக உள்ளன, ஆனால் சிக்கலான அல்லது மாறுபட்ட உரையாடல்களில் திறன்பெறுவது கடினம்.  

**AI-Based சாட்பாட்கள்** என்பவை இயற்கை மொழி செயலாக்கம் (NLP - Natural Language Processing), இயந்திரக் கற்றல் (Machine Learning), மற்றும் ஆழ்ந்த கற்றல் (Deep Learning) போன்ற முறைகளைப் பயன்படுத்தி உரையைப் புரிந்து கொண்டு, மனிதர்களைப் போன்று பதிலளிக்கும் திறனைக் கொண்டுள்ளன. இவை மிகவும் மேம்பட்டவை மற்றும் சிக்கலான உரையாடல்களைக் கையாளும் திறன் கொண்டவை.  

சாட்பாட்கள் பல்வேறு துறைகளில் பயன்படுத்தப்படுகின்றன, உதாரணமாக, வாடிக்கையாளர் சேவை, உதவி மையங்கள், மருத்துவ ஆலோசனை, கல்வி, மற்றும் தனிப்பயனாக்கப்பட்ட பரிந்துரைகள் போன்றவை. இவை மனிதர்களின் பணியை எளிதாக்கவும், நேரத்தை மிச்சப்படுத்தவும், மற்றும் பயனர் அனுபவத்தை மேம்படுத்தவும் உதவுகின்றன.  

மேலும், சாட்பாட்கள் தொடர்ந்து மேம்படுத்தப்பட்டு வருகின்றன, மேலும் அவை மனிதர்களுடன் மிகவும் இயல்பான மற்றும் புரிந்துணரும் வகையில் உரையாடும் திறனைப் பெறுவதற்காக தொடர்ந்து மேம்படுத்தப்படுகின்றன.

**இந்த பயிற்சியில், நாம் Rule-Based Chatbot-ஐ உருவாக்குவோம்.**  

##### 2.2. தேவையான நூலகங்களை நிறுவுதல்  

நாம் `nltk` (Natural Language Toolkit) நூலகத்தைப் பயன்படுத்துவோம். இது NLP பணிகளுக்கு பயனுள்ளதாக இருக்கும்.  

```bash
pip install nltk
```

**Import Libraries**  

```python
import nltk
from nltk.chat.util import Chat, reflections
```

##### 2.3. விதிகளை வரையறுத்தல்  

Rule-Based Chatbot-இல், நாம் பயனரின் உரையைப் பொறுத்து பதில்களை வழங்கும் விதிகளை வரையறுக்க வேண்டும். இந்த விதிகள் **Regular Expressions (Regex)** மூலம் உரையைப் பொருத்தி, பொருத்தமான பதில்களைத் தேர்ந்தெடுக்கும்.  

```python
pairs = [
    [
        r"hi|hello|hey",
        ["Hello! How can I help you?", "Hi there! What can I do for you?"]
    ],
    [
        r"how are you",
        ["I'm good, thank you! How about you?", "I'm doing well. How can I assist you?"]
    ],
    [
        r"what is your name",
        ["I'm a simple chatbot. You can call me ChatBot!", "I don't have a name, but you can call me ChatBot."]
    ],
    [
        r"bye|goodbye",
        ["Goodbye! Have a great day!", "Bye! Take care!"]
    ],
    [
        r"thank you|thanks",
        ["You're welcome!", "No problem!"]
    ],
    [
        r"(.*) your name (.*)",
        ["I'm just a chatbot. I don't have a name!", "You can call me ChatBot."]
    ],
    [
        r"(.*) help (.*)",
        ["Sure, I can help you. What do you need?", "How can I assist you?"]
    ],
    [
        r"(.*) (age|old) (.*)",
        ["I'm just a program, so I don't have an age!", "I'm ageless!"]
    ],
    [
        r"i am good|i'm good",
        ["That's great to hear!", "Good to know you're doing well!"]
    ],
    [
        r"(.*)",  # Fallback rule
        ["I'm not sure how to respond to that.", "Can you please rephrase?"]
    ]
]

```

---

##### 2.4. சாட்பாட்டை உருவாக்குதல்  

இப்போது, நாம் வரையறுத்த விதிகளைப் பயன்படுத்தி சாட்பாட்டை உருவாக்கலாம்.  

```python
# சாட்பாட்டை உருவாக்குதல்
chatbot = Chat(pairs, reflections)

# சாட்பாட்டை இயக்குதல்
def start_chat():
    print("Hello! I'm a simple chatbot. Type 'quit' to exit.")
    while True:
        user_input = input("You: ")  # பயனரின் உரை
        if user_input.lower() == "quit":
            print("ChatBot: Goodbye!")
            break
        response = chatbot.respond(user_input)  # சாட்பாட்டின் பதில்
        print("ChatBot:", response)


```

**சாட்பாட்டை இயக்குதல்**  

```python
# சாட்பாட்டைத் தொடங்குதல்
start_chat()
```

இந்த குறியீட்டை இயக்கினால், சாட்பாட் பயனருடன் உரையாடத் தொடங்கும்.  

**உரையாடல் எடுத்துக்காட்டு:**  

```
You: Hi  
ChatBot: Hello! How can I help you?  

You: What is your name?  
ChatBot: I'm a simple chatbot. You can call me ChatBot!  

You: How are you?  
ChatBot: I'm good, thank you! How about you?  

You: Bye  
ChatBot: Goodbye! Have a great day!  
```

இந்த சாட்பாட் **Rule-Based** ஆக இருப்பதால், இதற்கு சில வரம்புகள் உள்ளன.

இந்த சாட்பாட் முன்-வரையறுக்கப்பட்ட விதிகளை மட்டுமே புரிந்து கொள்ளும். புதிய உரைகளைப் புரிந்து கொள்ள இயலாது.  இது உரையின் சூழலைப் புரிந்து கொள்ளாது. எடுத்துக்காட்டாக, "How old are you?" மற்றும் "What is your age?" இரண்டும் ஒரே கேள்வியாக இருந்தாலும், இது இரண்டிற்கும் தனித்தனியாக விதிகளை வரையறுக்க வேண்டும்.  

இந்த சாட்பாட் உணர்ச்சிகளைப் புரிந்து கொள்ளாது. எடுத்துக்காட்டாக, "I'm feeling sad" என்ற உரைக்கு பொருத்தமான பதிலை வழங்க இயலாது.  சாட்பாட்க்கு  புதிய தரவுகளைக் கற்றுக்கொள்ளும் திறன் இல்லை. இது முன்-வரையறுக்கப்பட்ட விதிகளை மட்டுமே பின்பற்றும்.   

#### 3. செய்யறிவின் வரலாறு  

மனிதர்கள் பல நூற்றாண்டுகளாக எவ்வாறு நுண்ணறிவை வடிவமைக்கலாம் என்பதை ஆய்வு செய்து வந்தாலும்,  செய்யறிவின் (Artificial Intelligence) வளர்ச்சி கடந்த 70 ஆண்டுகளில் தான் ஒரு சீரிய பயணத்தை மேற்கொண்டது. இந்த வளர்ச்சி தொடர்ந்தும் மாற்றங்களை சந்தித்தது, பல நேரங்களில் முன்னேற்றமும், பின்னடைவும் காணப்பட்டது. பலருக்கும் **AI Winter** எனப்படும் பின்னடைவு காலங்கள் தெரிந்திருக்கலாம், ஆனால் **AI-யின் முழுமையான வரலாற்று பயணம்**, அதன் உருவாக்கம், முன்னோடிகள், மற்றும் ஏன் பல முயற்சிகள் தோல்வியடைந்தன என்பதற்கான புரிதல் இன்னும் தேவைப்படுகிறது. அதைப் புரிந்துகொள்வதற்கு, **AI எப்போது ஆரம்பித்தது? அதன் முன்னோடிகள் யார்? முன்னேற்றங்களை எந்த நுண்ணறிவு கோட்பாடுகள் வழிநடத்தின? மற்றும் எந்த இடங்களில் சிக்கல்கள் ஏற்பட்டன?** என்பவற்றை ஆராய்வது அவசியம்.

##### 1956 – Dartmouth Conference: AI-யின் பிறப்பு

1956-ஆம் ஆண்டு, அமெரிக்காவின் **Dartmouth College**-ல் ஒரு வரலாற்றுச் சிறப்புமிக்க மாநாடு நடைபெற்றது. இதை **Dartmouth Conference** என்று அழைக்கிறோம். இம்மாநாட்டை **John McCarthy, Marvin Minsky, Nathaniel Rochester, Claude Shannon** போன்ற முக்கிய AI விஞ்ஞானிகள் ஏற்பாடு செய்தனர். இதில் அவர்கள் முன்வைத்த ஒரு முக்கியமான கருத்து:

   **“மனிதர்களைப் போல சிந்திக்கக் கூடிய கணினிகளை உருவாக்க முடியுமா?”**

இந்த கேள்வி புதியதல்ல, ஏனெனில் 1940களில் **Alan Turing** என்பவர் **Turing Test** என்ற கோட்பாட்டை முன்வைத்திருந்தார். இது, ஒரு கணினி மனிதர்களைப் போல செயல்படுகிறதா என்று பரிசோதிக்க வேண்டிய முறை.

Dartmouth மாநாட்டில் **“Artificial Intelligence”** என்ற சொல் முதன்முறையாக உபயோகிக்கப்பட்டது. இது **மனிதர்கள் மேற்கொள்கின்ற சிந்தனை, தீர்வுகள், மற்றும் முடிவெடுக்கும் செயல்முறைகளை கணினிகள் செய்யக்கூடியதாக உருவாக்கும் புதிய விஞ்ஞானத் துறையாக அறிவிக்கப்பட்டது.**

அந்த மாநாட்டின் முக்கிய நோக்கங்கள்:

* கணினிகள் தன்னிச்சையாக முடிவெடுக்க வேண்டும்.
* கணினிகள் சிக்கல்களை புரிந்து கொண்டு, அதற்கான தீர்வுகளை கண்டறிந்து, திறமையாக தீர்க்க வேண்டும்.
* கணினிகள் மனித மொழியை புரிந்து கொள்ள வேண்டும்.
* கணினிகள் தனிநபர்களைப் போல அறிவாற்றலை வெளிப்படுத்த வேண்டும்.

இந்த மாநாட்டின் முடிவில், **AI-ஆய்வு புதிய பரிமாணத்தை அடைந்தது**. விஞ்ஞானிகள் இதை **சாத்தியமான ஒன்றாக** நம்பினார்கள். ஆனால், மேலும் பல முன்னேற்றங்கள் தேவையென்பதும் தெளிவாக இருந்தது.

##### 1960களில் AI-யின் தொடக்கக்கட்டம் – Rule-Based Systems

Dartmouth மாநாட்டின் பின்னணியில், 1960களில் விஞ்ஞானிகள் AI ஆராய்ச்சியை மேலும் விரிவுபடுத்தினர். AI-யின் ஆரம்பக் கட்டத்தில் உருவாக்கப்பட்ட முறை **Rule-Based Systems** ஆகும். Rule-Based Systems என்பது **மனித நிபுணத்துவத்தை கணினியில் கோட்பாட்டாக எழுத** முயற்சி செய்த AI முறை. இதன் அடிப்படையில்:

* **மனிதர்கள் எப்படி முடிவெடுக்கிறார்கள்?**
* **அந்த முடிவுகளுக்கான தர்க்கரீதியான காரணங்கள் என்ன?**
* **கணினி முறையாக முடிவெடுக்க எந்த விதிகளை (Rules) பயன்படுத்தலாம்?**

என்பவற்றை கணினியில் நிரலாக மாற்ற முயற்சி செய்யப்பட்டது.

##### General Problem Solver (GPS) – Allen Newell & Herbert A. Simon

GPS என்பது Rule-Based Problem Solving System ஆகும். இது பிரச்சனைகளை தீர்ப்பதற்கான பொதுவான செயல்முறையை (General Approach) முன்மொழிகிறது.

இந்த முறை மனிதர்கள் சிக்கல்களை எவ்வாறு தீர்க்கிறார்கள்? என்ற கோட்பாட்டை அடிப்படையாகக் கொண்டு உருவாக்கப்பட்டது. இதன் முக்கிய செயல்முறை, “ஒரு சிக்கலை தர்க்க ரீதியாக பகுக்க வேண்டும், தீர்வுக்கான வழிகளை கண்டுபிடிக்க வேண்டும், பின்னர் சிறந்த தீர்வை தேர்வு செய்ய வேண்டும்” என்பதாகும்.

ஆனால், இந்த முறை முழுமையாக வெற்றியடையவில்லை. இயற்கையின் சிக்கலான தன்மை காரணமாக, எல்லா பிரச்சனைகளுக்கும் ஒரு பொதுவான தீர்வு இருக்க முடியாது என்பதே பின்னர் உணரப்பட்டது.

##### ELIZA – Joseph Weizenbaum (1966)

ELIZA என்பது **மனிதர்களுடன் உரையாடக்கூடிய ஒரு தானியங்கி உரையாடல் (Chatbot)** ஆகும். இது **Natural Language Processing (NLP)** முறைகளைப் பயன்படுத்தி **மனிதர்களைப் போல பதிலளிக்க** முயற்சி செய்தது. ELIZA-வின் தனிச்சிறப்பு என்னவெனில், **மனிதர்களுடன் உரையாடல்களை நகலாக உருவாக்கி, உண்மையான பதில்களைக் கொடுப்பது போல தோற்றமளித்தது**.

**ஆனால், இதில் ஒரு முக்கியமான குறைபாடு இருந்தது.** ELIZA உண்மையாக ஒரு உரையாடலை புரிந்து கொள்ளவில்லை; அது வெறும் **predefined keywords** மற்றும் **pattern-matching** முறைகளை மட்டுமே பயன்படுத்தியது. இதனால், உரையாடல் தோற்றத்திற்கேற்ப இயல்பாக நடந்தாலும், உண்மையில் AI எந்த அர்த்தத்தையும் புரிந்து கொள்ளவில்லை. மேலும், **மனித உணர்வுகளையும், சூழ்நிலையையும் அடையாளம் கண்டு பதிலளிக்க முடியாமல்** இருந்தது.**AI உண்மையாக ஒரு machine intelligence ஆக வேண்டுமெனில், இது சூழ்நிலையைப் புரிந்து கொள்ளும் திறனை வளர்த்துக்கொள்ள வேண்டும்**.

1970களில் AI-யின் முக்கியமான சிக்கலாக **Combinatorial Explosion** கண்டறியப்பட்டது. AI-யில் ஒரு சிக்கலுக்கு தீர்வு காணும்போது, அதன் அனைத்து சாத்தியமான நிலைகளும் கணக்கிடப்படும். ஆனால், ஒரு பிரச்சனை வளர்ச்சியடைந்து பெரியதாக செல்லும் போது, அதன் முடிவுகளின் எண்ணிக்கை கணிக்க முடியாத அளவுக்கு அதிகரிக்கிறது. இதுவே **Combinatorial Explosion** எனப்படும் பிரச்சனை. எடுத்துக்காட்டாக, ஒரு **10x10 pixel** கொண்ட படத்தை எடுத்துக்கொண்டால், ஒவ்வொரு pixel-க்கும் **0 முதல் 256 வரை values** இருக்கலாம். இதனால், அந்த படத்திற்கான அனைத்து சாத்தியமான combination possibilities = **$256^{100}$** ஆகும், இது **பிரபஞ்சத்தில் உள்ள அணுக்களின் எண்ணிக்கையைவிட அதிகம்!** 

இதன் விளைவாக, AI கணிப்பொறிகள் (Computers) மிகப்பெரிய **computational resources** தேவையாகிறது. அதனால், Rule-Based AI முறைகள் **மிகப் பெரிய மற்றும் சிக்கலான பிரச்சனைகளை தீர்க்க முடியாது** என்பதை விஞ்ஞானிகள் உணர்ந்தனர். 

1970களின் இறுதியில், AI-யின் வளர்ச்சி ஒரு பெரிய சிக்கலின் முன் நின்று கொண்டிருந்தது. **Rule-Based Systems** மற்றும் **Expert Systems** பல முன்னேற்றங்களை ஏற்படுத்தியிருந்தாலும், அவை சிறிய அளவிலேயே பயனுள்ளதாக இருந்தன. **Combinatorial Explosion** பிரச்சனையால், மிகப் பெரிய பிரச்சனைகளை தீர்க்க முடியாத நிலை ஏற்பட்டது. இதனால், **Rule-Based AI-க்கு மாற்றாக புதிய வழிகள் தேவைப்படும்** என்று ஆராய்ச்சியாளர்கள் எண்ணத் தொடங்கினர். இதன் விளைவாக, **Machine Learning மற்றும் Deep Learning** போன்ற புதிய அணுகுமுறைகள் உருவாக ஆரம்பித்தன, மேலும் AI ஒரு புதிய பரிணாமத்துக்குள் நுழைந்தது.

இந்நிலையில், **Geoff Hinton** ஒரு புரட்சிகரமான சிந்தனையை முன்வைத்தார்: **Backpropagation of Errors**. இதற்கு முன்பு, AI விஞ்ஞானிகள் மனித மூளையின் செயல்பாட்டை ஒத்திருக்கும் கணினி அமைப்புகளை உருவாக்க முயன்றனர். ஆனால், **Hinton முற்றிலும் மாறுபட்ட அணுகுமுறையை தேர்ந்தெடுத்தார்** – கணினி சரியான முடிவுகளை உடனடியாக கணிக்க வேண்டிய அவசியமில்லை; மாறாக, **தவறுகளை செய்ய அனுமதித்து, அவற்றிலிருந்து திருத்தம் செய்துகொண்டு படிப்படியாக கற்றுக்கொள்ள வேண்டும்**.

நாம் குழந்தையாக இருக்கும்போது, **கல்லாங்காலி (Hopscotch)** விளையாடும் போது, முதல் முயற்சியிலேயே முழுமையாக சரியாக விளையாட முடியாது. கல்லை எங்கே எறிய வேண்டும், எந்த காலால் எங்கு நிற்க வேண்டும் என்பதில் முதல் சில முயற்சிகளில் தவறுகள் செய்வோம். ஆனால், **அந்த தவறுகளை நாம் நம் அனுபவத்தின் மூலம் திருத்திக் கொண்டு மெல்ல மெல்ல சரியான முறையில் விளையாட கற்றுக்கொள்கிறோம்**. ஒவ்வொரு தவறும் **ஒரு புது பாடமாக** அமைந்து, அடுத்த முறையில் அதை திருத்தி மேலும் திறமையாக விளையாட உதவுகிறது.

அதேபோல், Backpropagation முறையிலும், ஒரு Neural Network முதலில் ஒரு கணிப்பு (Prediction) செய்யும். அது தவறாக இருந்தால், அந்த தவறை அடையாளம் கண்டு திருத்தும் வழியை தானாகவே கற்றுக்கொள்ளும். மறுபடியும் கணிப்பு செய்து, மெல்ல மெல்ல சரியான முடிவை அடைய இது iteration முறையில் மேம்படுத்தப்படும்.

**எப்படி ஒரு குழந்தை கல்லாங்காலி (Hopscotch) விளையாடும்போது தவறுகளைச் செய்யும் இடையே அவற்றில் இருந்து பயில்கிறதோ, அதேபோல் Neural Networks-க்கும் தவறுகள் ஒரு முக்கியமான பங்காக உள்ளன.** குழந்தை தொடக்கத்தில் எந்த இடத்தில் குதிக்க வேண்டும், எங்கே கல்லை எறிய வேண்டும் என்று தெரியாமல் தவறாகச் செய்யலாம். ஆனால், **ஒவ்வொரு தவறும் அதை திருத்திக் கொள்ளும் வாய்ப்பாக மாறி, மெல்ல மெல்ல சரியான முறையில் விளையாட கற்றுக்கொள்ள உதவுகிறது.**

**அதேபோல், AI முறைகளும் ஒரு பிரச்சனைக்கு முதல் முயற்சியில் சரியான தீர்வை வழங்காது.** ஆனால், **தவறுகளை அடையாளம் கண்டு திருத்திக்கொண்டு, முன் செய்த பிழைகளை அடிப்படையாகக் கொண்டு, சிறிது சிறிதாக முன்னேறி, முற்றிலும் கற்றுக்கொள்ளும் திறன் பெற்றுவிடும்.** இதுவே **Backpropagation** முறையின் முக்கியத்துவம் – **முந்தைய தவறுகளை திருத்தி, மெல்ல மெல்ல சரியான முடிவை அடைய செய்யும் ஒரு கற்றல் செயல்முறை.**

இந்த புதிய அணுகுமுறை AI-யின் வளர்ச்சியில் ஒரு **முக்கிய திருப்புமுனையாக** அமைந்தது. **David Rumelhart, Geoff Hinton, James McClelland** மற்றும் **Ronald Williams** ஆகியோரால் 1986-ஆம் ஆண்டு மேலும் மேம்படுத்தப்பட்ட **Backpropagation Algorithm** இன்று **Neural Networks-ஐ பயிற்றுவிப்பதற்கான அடிப்படை நுட்பமாக** பார்க்கப்படுகிறது. இதுவே **Deep Learning**-க்கு ஆதாரமாக அமைந்தது. இதன் விளைவாக, **Neural Networks**-ஐ பயிற்றுவிக்க மிகவும் எளிதாகியது, மேலும் பெரிய அளவிலான **Big Data**-வை கையாள AI முன்னேறியது.

1980களின் இறுதியில் **Neural Networks** பற்றிய ஆராய்ச்சி முன்னேறியிருந்தாலும், கணிப்பொறிகள் (Computers) தேவையான கணக்கீடுகளை செய்யும் அளவிற்கு வலிமையாக இருக்கவில்லை. **Parallel Computing** பெரிதாக வளராத நிலையில், மிகப்பெரிய அளவிலான தரவை (Big Data) செயலாக்க முடியாத நிலை இருந்தது. இதனால், AI விஞ்ஞானிகள் **Statistics மற்றும் Probability** சார்ந்த முறைகளை ஆராயத் தொடங்கினர். இதிலிருந்து **Machine Learning** எனும் புதிய துறை உருவாகியது, இது கணினிகளை விதிகளின் அடிப்படையில் அல்ல, முறைமுறையாக தரவிலிருந்து கற்றுக்கொள்ளும் முறையாக உருவாக்க முயற்சித்தது.

1990களில், **Machine Learning** முறைகள் உருவாகி, **Rule-Based AI-யிலிருந்து Statistical AI-க்கான பெரிய மாற்றத்தை கொண்டு வந்தன**. விஞ்ஞானிகள் **Decision Trees, Support Vector Machines (SVM), Bayesian Networks** போன்ற கோட்பாடுகளை உருவாக்கினர். இவை, AI-யை முன்பு இருந்த **நிபுணர் அமைப்புகள் (Expert Systems) அல்லது Rule-Based Systems** போன்று செயல்படுத்தாமல், **தரவின் அடிப்படையில் தானாக முடிவெடுக்கக் கூடிய திறனை கொண்டதாக** வடிவமைக்க முயன்றன. இதன் மூலம் AI சிறிய பிரச்சனைகளுக்கு மட்டுமல்லாமல், **முடிவெடுக்கும் முறைகள், தரவின் மாதிரிகள் (Patterns), மற்றும் சிக்கலான செயல்பாடுகளை** புரிந்து கொள்ளக்கூடியதாக மாறியது.

இந்த காலக்கட்டத்தில், **AI-யின் பயன்பாடுகள்** கணிசமாக அதிகரிக்கத் தொடங்கின. **Natural Language Processing (NLP)** முறைகள் வேகமாக முன்னேறியதால், மொழிபெயர்ப்பு, உரையாடல் அமைப்புகள் மற்றும் உரை பகுப்பாய்வு போன்ற துறைகள் வளர்ச்சியடைந்தன. **IBM Watson** போன்ற மேம்பட்ட **AI Systems** உருவாக்கப்பட்டன, குறிப்பாக தகவல்களை பகுப்பாய்வு செய்து, வினாக்களுக்கு பயனுள்ளதாக பதிலளிக்கக்கூடிய திறன் பெற்றன.

அதே நேரத்தில், **Fraud Detection, Recommendation Systems, மற்றும் Web Search Engines** போன்ற **Data-Driven AI Models** வணிக உலகில் பரவலாகப் பயன்படுத்தப்படத் தொடங்கின. **Computer Vision** மற்றும் **Robotics** துறைகளும் புதிய கட்டத்திற்குச் சென்றன, குறிப்பாக தொழிற்சாலைகள், மருத்துவம், மற்றும் தன்னியக்க வாகனங்கள் (Autonomous Vehicles) போன்ற துறைகளில் AI முக்கிய பங்கு வகிக்கத் தொடங்கியது. இதனால், AI ஆனது ஆய்வகங்களில் மட்டும் அல்லாது **உண்மையான தொழில்துறைகளில் நுழைந்து**, கணிசமான மாற்றங்களை உருவாக்கத் தொடங்கியது.

2000களில் கணிப்பொறிகள் பல மடங்கு வலுவடைந்தன. **Parallel Computing, Cloud Computing, GPUs (Graphics Processing Units)** போன்ற தொழில்நுட்பங்கள் வளர்ந்ததை தொடர்ந்து, **பெரிய அளவிலான தரவை (Big Data) கையாள இயலும் சூழ்நிலை உருவாகியது**. இதனால், 1980களில் தேக்கமடைந்திருந்த **Neural Networks** மீண்டும் முக்கியத்துவம் பெற தொடங்கின. கணினிகள் அதிகம் பயன்படுத்தக்கூடியதாக மாறியதால், விஞ்ஞானிகள் **Machine Learning** மற்றும் **Deep Learning** சார்ந்த ஆய்வுகளை மேலும் தீவிரப்படுத்தினர்.

**Deep Learning** என்ற புதுமையான துறை உருவாக்கப்பட்டதால், **Multi-Layered Neural Networks** மூலம் AI மிகவும் வலிமையானதாக மாறியது. இது, கணினிகளை **தானாக தரவிலிருந்து கற்றுக்கொண்டு முடிவெடுக்கக்கூடியதாக மாற்றியது**, மேலும் AI-யின் பயன்பாடுகளை வெகுவாக அதிகரித்தது. குறிப்பாக, **Speech Recognition (Google Voice, Siri, Alexa), Image Recognition (Face Detection, Self-driving Cars), Natural Language Processing (Chatbots, Machine Translation), மற்றும் Medical AI (Cancer Detection, Drug Discovery)** போன்ற துறைகள் பெரிய வளர்ச்சி கண்டன. AI முன்னேறுவதற்கு மிகப்பெரிய அடித்தளமாக **Deep Learning** துறையின் வளர்ச்சி அமைந்தது, மேலும் இது **புதிய தீர்வுகளை கண்டுபிடிக்கவும், எளிதாக பிரச்சனைகளை தீர்க்கவும் கணினிகளை மிகவும் திறமையாக மாற்றியது**.

2010களின் பிறகு, **AI-யின் வளர்ச்சி ஒரு புதிய உச்சத்தை அடைந்தது**. Deep Learning முறைகள் தரவின் **ஆழமான தன்மைகளை புரிந்துகொள்ளும் திறனை** அதிகரித்தன. முன்னதாக இருந்த **Convolutional Neural Networks (CNNs) மற்றும் Recurrent Neural Networks (RNNs)** போன்ற முறைகள் சில குறிப்பிட்ட பிரச்சனைகளுக்கு மட்டுமே பயன்பட்டன. ஆனால், **AI-யின் வளர்ச்சியில் மிகப் பெரிய மாற்றத்தை கொண்டு வந்தது – Transformers Architecture**.

2017-ஆம் ஆண்டு **Google Brain Team** வெளியிட்ட **“Attention Is All You Need”** ஆய்வு கட்டுரை, **Transformers** எனும் புதிய Deep Learning மாடலை உலகுக்கு அறிமுகப்படுத்தியது. இதன் முக்கியத்துவம் என்னவென்றால், இது **மொத்த தகவல் தொகுப்பிலிருந்தும் (Context) முக்கியமான தரவுகளை கவனத்துடன் அணுகி செயலாக்கும் திறனை கொண்டது**. இதன் மூலம், **நீண்ட உரைகளை புரிந்து கொள்ளுதல், மொழிபெயர்ப்பு, உரையாடல் (Chatbots) போன்ற செயல்பாடுகளில் பெரும் முன்னேற்றம் ஏற்பட்டது**.

Transformers-ல் அடிப்படையாக உருவான **GPT (Generative Pre-trained Transformers), BERT (Bidirectional Encoder Representations from Transformers), மற்றும் T5, Llama, Mistral, Gemini போன்ற LLMs (Large Language Models)** உள்ளிட்ட மாடல்கள் உருவாக்கப்பட்டன. இவை **மனிதர்களை ஒத்த உரையாடல், மொழிபெயர்ப்பு மற்றும் தகவல் உருவாக்கம்** போன்ற செயல்களை மிகச்சரியான முறையில் செய்யக்கூடியதாக உருவாகின.

அதே நேரத்தில், **Generative AI** வளர்ச்சி அடைந்து, AI **படங்கள், வீடியோக்கள், பாடல்கள், மற்றும் மொழிபெயர்ப்பு** போன்றவற்றை உருவாக்கும் திறன் பெற்றது. **DALL-E, MidJourney, Stable Diffusion** போன்ற தொழில்நுட்பங்கள் **கணினியால் உருவாக்கப்படும் படங்களை** மனிதர்களுக்கே அடையாளம் காண முடியாத அளவிற்கு உணர்வுப்பூர்வமாக மாற்றின. ChatGPT, Claude, Gemini போன்ற **உரையாடல் மாடல்கள்** தகவலை புரிந்து கொண்டு, **மனிதர்களைப் போல பதிலளிக்க** தொடங்கின.

**AI இப்போது எங்கு உள்ளது? எதிர்காலம் எப்படி இருக்கும்?**

இன்றைய AI, பல முக்கிய துறைகளில் **மிகவும் வலுவாக** முன்னேறி வருகிறது:

1. **மருத்துவ துறை (Medical AI)** – நோய்களை கண்டறிவது, மருத்துவ பரிசோதனைகளை துல்லியமாக செய்ய AI உதவுகிறது. **Cancer Detection, Drug Discovery** போன்ற முக்கியமான புலங்களில் AI பாரிய மாற்றங்களை உருவாக்கியுள்ளது.
2. **தன்னியக்க வாகனங்கள் (Autonomous Vehicles)** – **Self-Driving Cars, Drones** போன்ற துறைகள் மிக வேகமாக வளர்ந்து வருகின்றன. **Tesla, Waymo, Cruise** போன்ற நிறுவனங்கள் முழுமையாக AI மூலம் இயக்கப்படும் வாகனங்களை உருவாக்கும் முயற்சியில் உள்ளன.
3. **Generative AI** – **ChatGPT, MidJourney, DALL-E** போன்ற AI அமைப்புகள் **உரைகள், படங்கள், வீடியோக்கள், மற்றும் 3D மாதிரிகள்** போன்றவற்றை மனிதர்கள் போல் உருவாக்கி, **உருவாக்க சிந்தனை (Creative Thinking)** பரிமாணத்திலும் AI-யை முன்னேற்றியுள்ளன.
4. **Quantum AI** – **Quantum Computing**-இன் வளர்ச்சி மூலம் மிகப் பெரிய மற்றும் சிக்கலான கணக்கீடுகளை செய்யும் AI உருவாகியுள்ளது. **Google, IBM, Microsoft** போன்ற நிறுவனங்கள் **Quantum AI**-ஐ முழுமையாக வளர்த்துவருகின்றன. இது **வலைவிரித்த கணக்கீடுகள், மருந்தியல் ஆராய்ச்சி, மற்றும் சுற்றுச்சூழல் மண்டல ஆய்வுகள்** போன்ற பல பிரச்சனைகளை தீர்க்க உதவுகின்றது.
5. **மனித அறிவிற்கு இணையான செயற்கை நுண்ணறிவு (Artificial General Intelligence - AGI)** – AI இப்போது **நிபுணத்துவம் (Narrow AI) கொண்ட செயல்களை மட்டுமே செய்கிறது**. ஆனால், எதிர்காலத்தில் **மனிதர்களைப் போல பல்துறை அறிவாற்றல் கொண்ட AGI** உருவாகலாம் என்ற எதிர்பார்ப்பு உள்ளது. இது **மனிதர்களைப் போல சிந்தித்து, தன்னிச்சையாக முடிவெடுக்கும் AI-ஐ உருவாக்கும் முயற்சியில் உள்ள விஞ்ஞானிகளுக்கு மிகப்பெரிய இலக்காக உள்ளது**.

AI-யின் வளர்ச்சி தொடர்ந்து மிக வேகமாக நடைபெற்று வருகிறது. **Generative AI, Robotics, Computational Creativity, AGI** போன்ற தொழில்நுட்பங்கள் முன்னேறி வரும் நிலையில், **AI மனித வாழ்க்கையை மாற்றும் மிகப்பெரிய கண்டுபிடிப்பாக** மாறியுள்ளது.

கணிப்பொறிகள் உருவாகி 80 ஆண்டுகள் ஆகின்றன, ஆனால் AI-யின் வளர்ச்சி கடந்த 20 ஆண்டுகளில் நிகழ்ந்த மிகப் பெரிய புரட்சி. **இன்னும் பத்து ஆண்டுகளில், AI எவ்வாறு மாறும்? அது மனிதர்களுடன் இணைந்து செயல்படுமா? அல்லது, AI-யால் மனித அறிவைத் தாண்டி செல்லக்கூடிய புதிய நுண்ணறிவு உருவாகுமா?**

இது நிச்சயமாக எதிர்காலத்தில் பெரும் ஆராய்ச்சிக்கும், விவாதத்திற்கும் உரிய விஷயமாக இருக்கும்! 

இனி வரும் காலங்களில், **AI-யின் எல்லைகள் மேலும் விரிவடையும்** – அதுவே **மனிதர்களுடன் ஒருங்கிணைந்து செயல்படும் அறிவாற்றல் அமைப்பாக மாறுமா? அல்லது மனித அறிவை மிஞ்சும் நிலையை அடையுமா?** என்பதை எதிர்காலமே தீர்மானிக்க வேண்டும்! 

<div style="page-break-after: always;"></div>

####  4. செய்யறிவு என்றால் என்ன?

செய்யறிவு (Artificial Intelligence) கடந்த பத்தாண்டுகளில் எதிர்பாராத அளவிற்கு நுட்பமான செயல்களைப் புரிந்து வருகிறது. படத்தைப் பார்த்து அதில் இருப்பவற்றைக் கண்டறிவது தொடங்கி மொழிபெயர்ப்பு வரை பலதரப்பட்ட சிக்கலான வேலைகளைச் செம்மையுறச் செய்து காட்டியுள்ளது. அதனைப் பற்றி விரிவாக இக்கட்டுரையில் காண்போம்.

தன்னிச்சையாக செயல்படும் கணினிகளை உருவாக்கும் முயற்சியே Artificial Intelligence (AI) என்று அழைக்கலாம். AI என்பது கணினிகள் மனிதர்களைப் போல அறிவார்ந்த முடிவுகளை எடுக்க மற்றும் புதிதாக கற்றுக்கொள்ள உதவுகின்ற ஒரு முறை. 

**Artificial Intelligence - AI நிறுவுநர்களில் ஒருவரான ஜான் மெக்கார்த்தி (**John McCarthy**), AI-ஐப் பற்றி இப்படி வரையறுக்கிறார் :**

> **“[Artificial intelligence is] the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable.”**

**இந்த வரையறை எதை குறிக்கிறது?**

இந்த **AI** வரையறை மூன்று முக்கியமான அம்சங்களை கொண்டிருக்கிறது:

1️⃣ **Science and Engineering of Making Intelligent Machines**

- இதன் பொருள் **AI என்பது நமக்கு தேவையான தகவல்களை கற்றுக்கொண்டு**, **முடிவுகளை எடுத்து**, **பிரச்சினைகளை தீர்க்க** பயன்படுகிறது.

2️⃣ **Using Computers to Understand Human Intelligence**

- AI என்பது **மனிதர்கள் எப்படி சிந்திக்கிறார்கள், முடிவெடுக்கிறார்கள்** என்பதை புரிந்து கொண்டு அதனை கணினியில் மாதிரி (model) செய்வது.

3️⃣ **AI Does Not Have to Follow Biologically Observable Methods**

- AI மனிதர்களை மாத்திரம் பின்பற்றவேண்டும் என்று இல்லை; இது கணினிகளுக்கே ஏற்ற **algorithm-based intelligence** ஆக இருக்கலாம்.

##### எதை AI என்று அழைக்கலாம்?

இன்று நாம் AI என்பதை Self-driving Cars, Chatbots, Speech Recognition, Medical Diagnosis AI போன்ற செயல்பாடுகளில் காணலாம். ஆனால், AI என்றால் கண்டிப்பாக ஒரு சுயசிந்தனை உடையது மட்டுமே ஆக வேண்டியதில்லை. இது ஒரு நிலையான if-else விதிகளால் கட்டுப்பட்டாலும் கூட, கணினி மனிதர்களின் சிந்தனையை ஒத்த மாதிரி செயல்படும் என்றால், அது AI ஆகக் கொள்ளலாம்.

இதனை புரிந்துக்கொள்ள நாம் ஒளிக்காட்சி விளையாட்டில் (Video Games) வரும் **கதாப்பாத்திரங்கள்** எப்படி செயல்படுகின்றன என்பதை உதாரணமாக கொண்டு AI அணுகுவோம்.

**ஒளிக்காட்சி விளையாட்டில் வரும் NPCs (Non-Playable Characters) AI ஆகிறதா?**

**Video Games** விளையாடும் போது, நீங்கள் எதிர்கொள்ளும் **Non-Playable Characters (NPCs)**, அதாவது **computer-controlled characters** பல முறை **AI** போல தோன்றலாம். ஆனால் அவை உண்மையான **AI அல்ல**.

உதாரணத்திற்கு, ஒரு NPC (வில்லன்) நம்மை பார்க்கும்போது **தாக்கும்**, இல்லையெனில் **நடந்து கொண்டே இருக்கும்**. இது உண்மையான **AI** ஆகாது, இது ஒரு **rule-based system -** simple if-else logic ஆகும். NPC தனது சூழ்நிலையை (context) **புரிந்துகொண்டு சுயமாக முடிவெடுக்காது**.

**NPCs எப்படி முடிவெடுக்கின்றன?**

**If-Else** என்பது ஒரு **decision-making (முடிவெடுக்கும்)** statement ஆகும். இவை **Non-Playable Character (NPC)** எப்போது **தாக்க வேண்டும்? எப்போது நடந்து கொண்டிருக்க வேண்டும்?** என்ற முடிவுகளை எடுக்க இது பயன்படும். **NPC உண்மையான AI அல்ல** - இது வெறும் **if-else** statement கொண்ட ஒரு **rule-based system** மட்டுமே! இவை **Pre-programmed logic** மட்டுமே பயன்படுத்தும்.

**Rule-Based Systems** (If-Else Statements) என்பது **முன்கூட்டியே நிரலாக்கப்பட்ட விதிகளை** பின்பற்றி செயல்படும். ஆனால், **AI** என்பது சூழ்நிலையை புரிந்து கொண்டு **தன்னிச்சையாக முடிவெடுக்க** வேண்டும்.

இவை எவ்வாறு செயல்படும் என்பதை எளிய முறையில் புரிந்துகொள்வோம்.

**காட்சி 1: If-Else Logic கொண்ட rule-based NPC**

நீங்கள் **ஷூட்டர் கேம்** விளையாடுவதாக கற்பனை செய்துக்கொள்ளுங்கள் 🎮 . நீங்கள் ஒரு **NPC வில்லனை** (enemy AI) எதிர்கொள்கிறீர்கள். NPC உங்களை பார்க்கும்போது **தாக்கும்**, இல்லையெனில் **உலாவி கொண்டிருக்கும்**.

```
if player_distance < 10:
    attack()
else:
    patrol()
```

**என்ன நடக்கிறது?**

- நீங்கள் 10 மீட்டருக்கு (meters) உள்ளே வந்தால் NPC வில்லன் உங்களை தாக்கும்.
- நீங்கள் 10 மீட்டருக்கு வெளியே இருந்தால், அது பாதுகாப்பாகச் சுற்றி வரும்.
- சூழ்நிலை எதுவானாலும் இவை கடைசிவரை **இதே விதியை மட்டுமே பின்பற்றும்**.

ஆனால் இன்று **Machine Learning மற்றும் Reinforcement Learning** கொண்டு **AI NPCகள்** உருவாக்கப்பட்டுள்ளன.

**அது எப்படி AI NPCகள் If-Else Statements ஐ தாண்டி செயல்படுகிறது?**

**காட்சி 2: AI-யை கொண்டு முடிவெடுக்கும் NPC**

வீரர் தன்னை தாக்கினால் – NPC பல சூழ்நிலையை ஆராய்ந்து முடிவெடுக்கும். அதாவது வீரரின் ஆரோக்கியம் (Player Health) அதிகமாக இருந்தால் எதிர் தாக்கும். இல்லையெனில் ஒளிந்து கொள்ளும். முன்பு வீரர் நடந்து சென்ற வழியை கற்றுக்கொண்டு அந்த வழியில் மறைத்து தாக்கும். அதுவே NPC-க்கு குறைந்த ஆரோக்கியம் இருந்தால் உங்களிடம் இருந்து தப்பித்து ஓடி ஒளிந்து கொள்ளும். வீரர் அடிக்கடி கவரேஜ் (cover) தேடி இருக்கிறாரா? NPC அதை கவனித்து, சுற்றி தாக்கலாம்.

AI NPC **சூழ்நிலையை ஆராய்ந்து முடிவெடுக்கிறது**. அதாவது, **வீரரின் ஆரோக்கியம்(player health), தன்னுடைய ஆரோக்கியம் (NPC health) மற்றும் எதிரியின் எத்தனை நேரம் தாக்காமல் இருக்கிறார் என்பதைப் பொறுத்து முடிவெடுக்கும்.**

**AI NPC** ஒரு **புதிய சூழ்நிலை உருவான பிறகு** அதற்கேற்ப **கற்றுக்கொண்டு செயல்படும்**. 

**எடுத்துக்கட்டாக ஒரு திருடன் (NPC) - காவலரை (Player) பார்த்து எப்பொழுது ஓட வேண்டும் எனப்பார்ப்போம்?**

| **திருடனின் நிலை (NPC State)**  | **காவலர் அருகில் உள்ளாரா?** | **திருடன் என்ன செய்ய வேண்டும்?** |
| ------------------------------ | ------------------------ | --------------------------- |
| அதிகபட்ச சக்தி உள்ளது (Healthy)   | இல்லை                     | அங்கேயே இருக்கும்              |
| குறைந்த சக்தி உள்ளது (Low Health) | இல்லை                     | ஒளிந்து கொள்ளும்               |
| குறைந்த சக்தி உள்ளது              | ஆம்                       | ஓடிவிடும் 🏃‍♂️                 |
| முழு சக்தி உள்ளது                | ஆம்                       | காவலரை தாக்கலாம்!             |

**AI NPC** **மனிதர்கள் போல் முடிவெடுப்பது எப்படி?**

உதாரணமாக 

1️⃣ **Player ஒரு இடத்தில் ஒளிந்து கொள்ள அதிக நேரம் செலவழிக்கிறார் என்றால்?**

NPC அதை கவனித்து, முன்கூட்டியே எதிர்பார்த்து அந்த இடத்தில் தாக்கலாம்.

2️⃣ **Player எப்போதும் ஒரு குறிப்பிட்ட வழியில் ஓடுகிறாரா?**

AI NPC அந்த வழியை மறித்து விளையாடலாம்.

**Rule-Based AI vs Learning AI (மனிதர்கள் போல் முடிவெடுக்கும் AI)**

| **ஒப்பீடு**                  | **Rule-Based NPC (If-Else Logic)**         | **AI NPC (Machine Learning)**                                |
| -------------------------- | ------------------------------------------ | ------------------------------------------------------------ |
| **முடிவெடுக்கும் விதம்**      | நிரந்தர விதிகள் (Fixed Rules)                | சூழ்நிலைக்கு ஏற்ப கற்றுக்கொண்டு முடிவெடுக்கும் (Dynamic Learning)    |
| **சூழ்நிலைக்கு ஏற்ப மாறுமா?** | முடிவெடுக்க முடியாது (Cannot Learn)         | வீரரின் செயல்பாடுகளிலிருந்து கற்றுக்கொண்டு மாறும் (Learns from Player Actions) |
| **உண்மையான உணர்வு தருமா?**   | எதிர்பார்க்கக்கூடிய செயல்பாடு (Predictable)     | மனிதர்களைப் போன்ற அனுபவம் தரும் (Feels more human-like)           |
| **உதாரண விளையாட்டுகள்**      | **Super Mario**, **Classic Shooter Games** | **Red Dead Redemption, GTA V, Open-World Games**             |

AI என்பது வெறும் விளையாட்டு NPCகளுக்கு மட்டும் அல்ல, நம் சுற்றியுள்ள அனைத்திற்கும் பயன்படுத்தப்படும் ஒரு நுண்ணறிவு முறை. ஆரம்பத்தில், if-else logic மூலம் NPCகள் நிரலாக்கப்பட்ட விதிகளை மட்டும் பின்பற்றி செயல்பட்டன, ஆனால் இன்று Machine Learning & Reinforcement Learning போன்ற நவீன AI முறைகள் சூழ்நிலைகளை புரிந்து கொண்டு தன்னிச்சையாக முடிவெடுக்கும் திறனை பெற்றுவிட்டன. AI  விளையாட்டுகளுக்கு மட்டுமல்ல, தோழமையாக பேசும் voice assistants (Siri, Alexa), சுயமாக செல்லும் Self-Driving Cars, Netflix, YouTube, Amazon போன்ற நிறுவனங்கள் AI-ஐ பயன்படுத்தி, உங்களுக்கு மிகவும் பிடிக்கக்கூடிய உள்ளடக்கங்களை பரிந்துரைக்கிறது, Chatbots மருத்துவத்தில் நோய்களை கண்டறிய, மருத்துவ பரிந்துரைகள் வழங்க மற்றும் மருந்துகளின் கண்டுபிடிப்பை விரைவுபடுத்த AI பயன்படுத்தப்படுகிறது.

**AI மனிதர்களைப் போல செயல்பட வேண்டும் என்பதல்ல அவை மனிதர்களுக்கு பயன்படும் வகையில், தரவினைப் புரிந்து கொண்டு, சூழ்நிலைக்கு ஏற்ப முடிவுகளை எடுக்க, மற்றும் செயல்திறனை மேம்படுத்த மனிதர்கள் உருவாக்கி கொண்டிருக்கிற தொழில்நுட்பம். இது விளையாட்டு முதல் மருத்துவம் வரை பல்வேறு துறைகளில் நம்மை சுற்றியுள்ள தரவை பயனுள்ளதாக மாற்றி செயல்படக்கூடியதாகவும் உருவாகி வருகிறது.**

<div style="page-break-after: always;"></div>

#### 5. Large Language Models (LLMs) என்றால் என்ன?

மனிதர்கள் ஒரு உரையாடலில் ஈடுபடும் போது, அவர்கள் முன்பு பேசிய விஷயங்களை நினைவில் வைத்துக்கொள்கிறார்கள். உதாரணமாக, நீங்கள் ஒரு உணவகத்தில் உணவு ஆர்டர் செய்யும் போது, முதலில் **“இந்த உணவகத்தில் 100 ரூபாய்க்குள் என்ன உணவு கிடைக்கும்?”** என்று கேட்டால், உணவக ஊழியர் அதற்கேற்ப ஒரு பதில் கூறுவார். 

பின்னர் நீங்கள் **“அதில் எதாவது காரமான உணவுகள் உள்ளதா?”** என்று கேட்டால், அவர் உங்கள் முதல் கேள்வியையும் கருத்தில் கொண்டு, **100 ரூபாய்க்குள் காரமான உணவுகள்** என்னென்ன இருக்கின்றன என்பதைச் சொல்வார். 

அதாவது, **மனிதர்கள் உரையாடலில் ஒரு தொடர்ச்சியை வைத்திருக்கிறார்கள்**. ஒரு உரையாடலில் நாம் முன்பு கூறிய விஷயங்களை நினைவில் வைத்துக்கொள்கிறோம், மேலும் அதைப் பொறுத்து அடுத்த பதிலை வழங்குகிறோம். 

நவீன மென்பொருட்கள் மற்றும் **Natural Language Processing, NLP** முன்னேறிய பிறகு, **மனிதர்களைப் போல பதிலளிக்க** தொழில்நுட்பம் வளர்ந்துள்ளது. **Large Language Models (LLMs)** என்பது இதன் ஒரு முக்கிய கூறாகும். 

இவை **புத்தகங்கள், ஆராய்ச்சி கட்டுரைகள், இணையதளங்கள், மற்றும் பல பெரிய தரவுத்தொகுப்புகள்** கொண்டு பயிற்சி பெற்றுள்ளன. **LLMs-ன் வேலை என்ன?**

1. **மொழியை புரிந்துகொள்ளுதல்** – பயனர் என்ன கேட்கிறார்கள் என்பதைப் புரிந்துகொள்வது. 
2. **பதில்களை உருவாக்குதல்** – தரவுத்தொகுப்புகளை அடிப்படையாகக் கொண்டு உகந்த பதிலை உருவாக்குதல். 
3. **Context (சூழ்நிலை) அடிப்படையில் முடிவெடுக்குதல்** – பேச்சின் தொடர்ச்சியைப் பேணுதல். 

> **உதாரணம்:**
> **மாணவர்கள்:** “AI, எனக்கு Differential Equations குறித்த தகவல் வேண்டும்.”
> **மென்பொருள்:** “Differential Equations என்பது calculus-இன் ஒரு பகுதி… நீங்கள் எந்தப் பிரிவில் உதவியை எதிர்பார்க்கிறீர்கள்?”

**LLM-களில் நினைவாற்றல் (Memory) எப்படி வேறுபடுகிறது?**

மனிதர்கள் பேசும்போது, அவர்கள் முன்பு பேசிய தகவல்களை நினைவில் வைத்துக்கொள்கிறார்கள். ஒரு உணவகத்தில் உணவு ஆர்டர் செய்யும் போது, ஊழியர் உங்கள் முந்தைய கேள்விகளை கருத்தில் கொண்டு பதிலளிப்பார். ஆனால் **LLMs-க்கு இயல்பாக நினைவாற்றல் இல்லை**. 

**மனித நினைவாற்றல் vs LLM-களின் நினைவாற்றல்**

| **மனிதன்**                                             | **LLM**                                            |
| ----------------------------------------------------- | -------------------------------------------------- |
| முன்னதாக பேசிய உரையாடலை நினைவில் வைத்துக்கொள்கிறான்         | ஒவ்வொரு கேள்வியையும் தனிப்பட்டதாக பார்க்கிறது             |
| பேசும் போது முன்பு கேட்ட தகவல்களை இணைத்து பதிலளிக்க முடியும் | முந்தைய உரையாடலை தனியாக வழங்காவிட்டால் நினைவில் கொள்ளாது |

**உரையாடல்களை தொடர்ந்தும் வைத்திருப்பது எப்படி?**

மனிதர்களைப் போல் **மென்பொருள்களும் ஒரே conversation-ஐ தொடர** உதவ, நாம் முந்தைய உரையாடல்களை **message list-ல் சேமித்து**, ஒவ்வொரு முறையும் அந்த **முழு உரையாடலை அனுப்ப வேண்டும்**. 

> **எளிய மொழியில்:** இந்த மாடல்களை ஒரு புதிய நண்பராக கற்பனை செய்யலாம். நீங்கள் ஒரு பழைய நிகழ்வை அவரிடம் சொன்னால், அவர் அதனை மறந்து விடுவார். ஆனால், நீங்கள் ஒவ்வொரு முறையும் அதைப் பற்றி நினைவூட்டினால், அவர் அதை மீண்டும் கவனத்தில் கொள்வார். 

> **இயற்கையாக நினைவாற்றல் இல்லாத மென்பொருட்களில், முந்தைய உரையாடலை செயற்கையாக சேர்த்து வழங்க வேண்டும்.**

##### LLM-களின் பயன்பாடுகள்

 **Chatbots உருவாக்கல்** – வாடிக்கையாளர்களுடன் உரையாட மென்பொருள்களை அமைத்தல்,
**மனித மொழியை Data Query-களாக மாற்றுதல்** – Data retrieval-க்கு மென்பொருள்களை பயன்படுத்துதல்,
**புதிய கட்டுரைகள், தகவல்கள் உருவாக்குதல்** – Automatic content generation,
**Text Summarization** – நீளமான உரையை சுருக்கமாக மாற்றுதல் 

> **உதாரணம்:** ஒரு வாடிக்கையாளர் ஒரு chatbot-ஐ கேட்டால்: “இன்று 100 ரூபாய்க்குள் என்ன உணவு கிடைக்கும்?” மென்பொருள் **உணவுப்பட்டியலை பார்க்கும், கணக்கிடும், பதிலளிக்கும்.**

##### LLM-களின் கட்டமைப்பு மற்றும் செயல்பாடு 

Large Language Models (LLMs) என்பவை மனித மொழியைப் புரிந்துகொண்டு, அதைப் பகுப்பாய்வு செய்து, உகந்த பதில்களை உருவாக்கும் திறன் கொண்ட செயற்கை நுண்ணறிவு (AI) மாடல்கள் ஆகும். இவை மிகப்பெரிய அளவிலான நியூரல் நெட்வொர்க்குகள் (Neural Networks)-ஆக வடிவமைக்கப்பட்டுள்ளன. இவை எவ்வாறு செயல்படுகின்றன என்பதைப் புரிந்துகொள்ள, LLM-களின் கட்டமைப்பு, பயிற்சி முறைகள், மற்றும் செயல்பாடுகள் பற்றி விரிவாகப் பார்ப்போம்.

##### LLM-கள் எப்படி வேலை செய்கின்றன?

Large Language Models (LLM-கள்) என்பவை மனித மொழியைப் புரிந்துகொண்டு, அதைப் பகுப்பாய்வு செய்து, துல்லியமான பதில்களை உருவாக்கும் திறன் கொண்ட AI மாடல்கள். இவற்றின் செயல்பாட்டு நிலைகளைப் பின்வரும் படிகளாகப் பிரிக்கலாம்:

###### படி 1: பயிற்சி (Training) – தரவின் முக்கியத்துவம்

LLM-கள் பல கோடி வார்த்தைகள் மற்றும் வாக்கியங்களைக் கொண்ட தரவுத்தொகுப்புகளில் பயிற்சி பெறுகின்றன. இந்தப் பயிற்சி Pretraining மற்றும் Fine-Tuning என இரண்டு பிரிவுகளாக நடைபெறுகிறது. இந்தப் பயிற்சி மூலம், LLM-கள் மொழியின் இலக்கணம், சொற்களின் பொருள், மற்றும் சூழலுக்கு ஏற்ப வார்த்தைகளைப் பயன்படுத்தும் திறன் போன்றவற்றைக் கற்றுக்கொள்கின்றன.

**1.1 Pretraining** 

Pretraining என்பது, LLM-கள் பல கோடி வார்த்தைகள் மற்றும் வாக்கியங்களைப் படித்து, மொழியின் அமைப்பைக் கற்றுக்கொள்வது. இது Self-Supervised Learning எனப்படும் செயல்முறையில் நடைபெறுகிறது. இந்தப் பயிற்சியில், மாடல் வார்த்தைகளுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்கிறது.

எப்படி செயல்படுகிறது?

- LLM-கள் ஒரு வாக்கியத்தில் சில வார்த்தைகளை மறைத்து (Mask), அந்த வார்த்தைகளை யூகிக்கும்.
  - உதாரணம்: 
    - வாக்கியம்: “Python என்பது ஒரு ----------- மொழியாகும்.”
    - LLM-கள் இதைப் புதிர் தீர்க்கும் மாதிரி கற்றுக்கொள்கின்றன. 
    - சரியான பதில்: “நிரலாக்க” (Programming)

பயிற்சி தரவுகள்:

- புத்தகங்கள், ஆராய்ச்சி கட்டுரைகள், விக்கிபீடியா, இணையதளங்கள் போன்றவை.
- தரவுத்தொகுப்புகள்: Common Crawl, WebText, BooksCorpus போன்றவை.

**1.2 Fine-Tuning** 

Fine-tuning என்பது, LLM-களை குறிப்பிட்ட பணிகளுக்கு மீண்டும் பயிற்சி (Retrain) செய்யும் செயல்முறை. இது மாடலை ஒரு குறிப்பிட்ட துறையில் சிறப்பாகச் செயல்பட வைக்க உதவுகிறது.

உதாரணம்:

- மருத்துவ LLM (Medical LLM): இது மருத்துவத் துறை சம்பந்தப்பட்ட தரவுகளுடன் fine-tune செய்யப்படுகிறது. இதனால், இது மருத்துவ கேள்விகளுக்கு துல்லியமான பதில்களை வழங்கும்.
- சட்ட LLM (Legal LLM): சட்டத் துறை சம்பந்தப்பட்ட தரவுகளுடன் fine-tune செய்யப்படுகிறது.

###### படி 2: Text Understanding (உரை புரிதல்) 

LLM-கள் பயனர் என்ன கேட்கிறார்கள் என்பதைப் புரிந்து கொள்கின்றன. இது Natural Language Understanding (NLU) எனப்படும் செயல்முறையாகும்.

எப்படி செயல்படுகிறது?

- LLM-கள் Tokenization மூலம் உரையை சிறிய பகுதிகளாகப் பிரிக்கின்றன.
- ஒவ்வொரு Token-ஐயும் Embedding எனப்படும் எண்ணியல் வெக்டராக மாற்றுகின்றன.
- இந்த Embedding-கள் Neural Network-ஐப் பயன்படுத்தி பகுப்பாய்வு செய்யப்படுகின்றன.

உதாரணம்:

- பயனர் கேள்வி: “சளி, காய்ச்சல் இருக்கிறது. என்ன மருந்து பரிந்துரைக்கலாம்?”
- LLM செயல்பாடு: LLM இந்தக் கேள்வியை மருத்துவத் தரவுகளின் அடிப்படையில் பகுப்பாய்வு செய்து, பொருத்தமான பதிலை வழங்கும்.

**Embedding: எண்ணியல் வெக்டர்களாக மாற்றுதல்**

Embedding என்பது, ஒவ்வொரு Token-ஐயும் (சொல்லை) எண்ணியல் வெக்டராக மாற்றும் செயல்முறை. இந்த வெக்டர்கள் Neural Network-களால் புரிந்து கொள்ளக்கூடிய வடிவத்தில் இருக்கும். இது LLM-களுக்கு சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள உதவுகிறது.

எப்படி செயல்படுகிறது?

1. Token to Vector: 
   - ஒவ்வொரு Token-ஐயும் (சொல்லை) ஒரு தனிப்பட்ட எண்ணியல் வெக்டராக மாற்றுகிறது. 
   - உதாரணம் (Example in English): 
     - Token: “Programming”
     - Embedding: [0.25, -0.12, 0.87, …, 0.45] (ஒரு நீண்ட எண் வரிசை). 
   - விளக்கம்: 
     - “Programming” என்ற சொல் ஒரு எண் வரிசையாக (Vector) மாற்றப்படுகிறது. இந்த வெக்டர், அந்த சொல்லின் பொருள் மற்றும் பண்புகளை பிரதிபலிக்கிறது.
2. Vector Dimensions: 
   - இந்த வெக்டர்கள் பொதுவாக 100 முதல் 1000 வரையிலான பரிமாணங்களைக் கொண்டிருக்கும். 
   - உதாரணம் (Example in English): 
     - GPT-3 மாடல்களில், ஒவ்வொரு Token-க்கும் 768 பரிமாணங்கள் உள்ளன. 
   - விளக்கம்: 
     - ஒவ்வொரு சொல்லும் 768 எண்களைக் கொண்ட ஒரு வெக்டராக மாற்றப்படுகிறது. இது அந்த சொல்லின் சிக்கலான பண்புகளை பிரதிபலிக்கிறது.
3. Semantic Meaning: 
   - Embedding-கள் சொற்களின் பொருளைப் பிரதிபலிக்கின்றன. 
   - உதாரணம் (Example in English): 
     - “King” மற்றும் “Queen” என்ற சொற்களின் Embedding-கள் ஒரே மாதிரியாக இருக்கும், ஆனால் அவை வெவ்வேறு பாலினங்களைக் குறிக்கின்றன. 
   - விளக்கம்: 
     - “King” மற்றும் “Queen” என்ற சொற்கள் ஒரே மாதிரியான Embedding-களைக் கொண்டிருக்கும், ஏனெனில் அவை இரண்டும் அரசர்களை குறிக்கின்றன. ஆனால், அவை வெவ்வேறு பாலினங்களைக் குறிப்பதால், அவற்றின் Embedding-கள் சிறிது வேறுபடும்.
4. Neural Network Input: 
   - இந்த Embedding-கள் Neural Network-க்கு உள்ளீடாக அனுப்பப்படுகின்றன. 
   - உதாரணம் (Example in English): 
     - “Python is a programming language.”
     - Tokenization: [“Python”, “is”, “a”, “programming”, “language”]. 
     - Embedding: 
       - “Python” → [0.12, -0.45, 0.67, …, 0.89] 
       - “programming” → [0.25, -0.12, 0.87, …, 0.45] 
       - “language” → [0.34, -0.56, 0.78, …, 0.23] 
   - விளக்கம்: 
     - ஒவ்வொரு சொல்லும் ஒரு எண் வரிசையாக மாற்றப்பட்டு, Neural Network-க்கு உள்ளீடாக அனுப்பப்படுகிறது. இது மாடலை சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள உதவுகிறது.

Embedding-களின் முக்கியத்துவம்

1. சொற்களின் பொருள்: 
   - Embedding-கள் சொற்களின் பொருளைப் பிரதிபலிக்கின்றன. 
   - உதாரணம் (Example in English): 
     - “King” மற்றும் “Ruler” என்ற சொற்களின் Embedding-கள் ஒரே மாதிரியாக இருக்கும், ஏனெனில் அவை ஒரே பொருளைக் கொண்டவை. 
   - விளக்கம்: 
     - “King” மற்றும் “Ruler” என்ற சொற்கள் ஒரே பொருளைக் கொண்டிருப்பதால், அவற்றின் Embedding-கள் ஒரே மாதிரியாக இருக்கும்.
2. சொற்களுக்கு இடையே உள்ள தொடர்புகள்: 
   - Embedding-கள் சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் காட்டுகின்றன. 
   - உதாரணம் (Example in English): 
     - “King” - “Man” + “Woman” = “Queen”. 
   - விளக்கம்: 
     - இந்த கணித செயல்பாடு, “King” என்ற சொல்லின் Embedding-லிருந்து “Man” என்ற சொல்லின் Embedding-ஐ கழித்து, “Woman” என்ற சொல்லின் Embedding-ஐ கூட்டினால், “Queen” என்ற சொல்லின் Embedding கிடைக்கும். இது Embedding-கள் சொற்களுக்கு இடையே உள்ள தொடர்புகளைப் புரிந்து கொள்வதைக் காட்டுகிறது.
3. Neural Network-க்கு உள்ளீடு: 
   - Embedding-கள் Neural Network-க்கு உள்ளீடாக அனுப்பப்படுகின்றன, இது மாடலை சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள உதவுகிறது. 
   - உதாரணம் (Example in English): 
     - “Python is a programming language.”
   - விளக்கம்: 
     - இந்த வாக்கியத்தில் உள்ள ஒவ்வொரு சொல்லும் Embedding-ஆக மாற்றப்பட்டு, Neural Network-க்கு உள்ளீடாக அனுப்பப்படுகிறது. இது மாடலை வாக்கியத்தின் அர்த்தத்தைப் புரிந்து கொள்ள உதவுகிறது.

###### படி 3: Text Generation (பதில்களை உருவாக்குதல்) 

LLM-கள் பயிற்சி பெற்ற தரவுகளை அடிப்படையாகக் கொண்டு, பயனரின் கேள்விக்கு பொருத்தமான பதிலை உருவாக்குகின்றன. இது Natural Language Generation (NLG) எனப்படும் செயல்முறையாகும்.

எப்படி செயல்படுகிறது?

- LLM-கள் Attention Mechanism மூலம் உரையின் முக்கிய பகுதிகளைக் கண்டறிகின்றன.
- Transformer Architecture-ஐப் பயன்படுத்தி, உரையை உருவாக்குகின்றன.

உதாரணம்:

- பயனர் கேள்வி: “AI என்றால் என்ன?”
- LLM பதில்: “Artificial Intelligence (AI) என்பது மனித நுண்ணறிவை ஒத்துத்தோற்றும் கணினி முறைமையாகும்.”

###### படி 4: சூழ்நிலை (Context) அடிப்படையில் முடிவெடுத்தல்

LLM-கள் ஒரே உரையாடலைத் தொடர்வதற்காக, முந்தைய தகவல்களை நினைவில் வைத்துக்கொள்வதில்லை. ஆனால், முந்தைய தகவல்களைச் சேர்த்து அனுப்பினால், மாடல் அதை Context-ஆகப் புரிந்து கொள்கிறது.

உதாரணம்:

- பயனர் கேள்வி 1: “இன்று வானிலை எப்படி?”
- LLM பதில்: “தற்போது 30°C வெப்பநிலை உள்ளது.”
- பயனர் கேள்வி 2: “நாளைக்கு?”

இங்கே, LLM-க்கு “நாளைக்கு” என்றால் என்ன என்று புரிய, முந்தைய உரையாடலை (Context) சேர்த்து அனுப்ப வேண்டும். இதனால், LLM நாளைய வானிலை பற்றிய தகவலை வழங்கும்.

LLM-களின் பயன்பாடுகள்

1. மொழிபெயர்ப்பு (Translation): ஒரு மொழியை மற்றொரு மொழியாக மாற்றுதல்.
2. உரை உருவாக்குதல் (Text Generation): கட்டுரைகள், கதைகள், கவிதைகள் போன்றவற்றை உருவாக்குதல்.
3. கேள்வி-பதில் அமைப்புகள் (Q&A Systems): பயனர்களின் கேள்விகளுக்கு துல்லியமான பதில்களை வழங்குதல்.
4. உரை சுருக்கம் (Text Summarization): நீண்ட உரைகளை சுருக்கமாக மாற்றுதல்.
5. உரை பகுப்பாய்வு (Text Analysis): உரைகளின் உணர்வுகளைப் பகுப்பாய்வு செய்தல்.

LLM-கள் மனித மொழியைப் புரிந்துகொண்டு, அதைப் பகுப்பாய்வு செய்து, உகந்த பதில்களை உருவாக்கும் திறன் கொண்டவை. இவை Pretraining மற்றும் Fine-Tuning போன்ற செயல்முறைகள் மூலம் பயிற்சி பெறுகின்றன. இவற்றின் முக்கிய பண்புகளான சூழல் புரிதல், பல்துறை பயன்பாடு, மற்றும் தானாகக் கற்றல் ஆகியவை இவற்றை நவீன AI-இன் முக்கிய அங்கமாக ஆக்கியுள்ளன.

இதன் காரணமாக, GPT, BERT, ChatGPT போன்ற LLM-கள் உருவாகி, AI துறையில் புரட்சியை ஏற்படுத்தியுள்ளன. 

<div style="page-break-after: always;"></div>

#### 6. கடைக்கால் மாதிரிகள்

ஹலோ டெக் ஆர்வலர்களே! இன்று நாம் "கடைக்கால் மாதிரிகள்" (Foundation Models) எனப்படும் சூப்பர் ஹீரோக்களைப் பற்றி பேசப் போகிறோம். இவைதான், நாம் வியந்து பார்க்கும் AI பயன்பாடுகளின் (AI Applications) அடித்தளம்! ஒரு பிரம்மாண்டமான கட்டிடத்தை உருவாக்க, அதன் அடித்தளம் உறுதியாக இருக்க வேண்டும். அதுபோல, இந்த மாதிரிகள் தான் AI உலகின் அடித்தளம் (Foundation of AI).

சரி, இந்த சூப்பர் ஹீரோக்களைப் பயன்படுத்த, அவற்றை எப்படி உருவாக்குவது என்று தெரிந்து கொள்ள வேண்டுமா? யோசித்துப் பாருங்கள், ஒரு சுவையான பிரியாணி சாப்பிட, அரிசியை எப்படி விளைவிப்பது என்று தெரிய வேண்டுமா? இல்லை தானே! ஆனால், அரிசியின் வகைகள், அதை எப்படி சமைப்பது என்று தெரிந்தால், இன்னும் சுவையான பிரியாணி செய்ய முடியும் அல்லவா? அதே போலத்தான் இந்த மாதிரிகளும். இந்த மாதிரிகளை உருவாக்குவது ஒரு பெரிய சவால். இது ஒரு ரகசிய சமையல் குறிப்பு போல! இந்த ரகசியத்தை வைத்திருப்பவர்கள், அதை வெளியில் சொல்வதில்லை. அதனால், நாம் இன்று ChatGPT-க்கு போட்டியாக ஒரு மாதிரியை  எப்படி செய்வது என்று பார்க்கப் போவதில்லை. அதற்கு பதிலாக, இந்த மாதிரிகளின் திறன்களை தீர்மானிக்கும் முக்கியமான விஷயங்களை ஆராய்வோம்.

இப்போதெல்லாம், இந்த மாதிரிகளின் Training Process-ல் வெளிப்படைத்தன்மை குறைந்து வருகிறது. அதனால், இந்த மாதிரிகளின் உள்ளே என்ன நடக்கிறது என்று தெரிந்து கொள்வது கொஞ்சம் கடினம். ஆனால், இந்த மாதிரிகளுக்கு இடையே உள்ள வேறுபாடுகளை, அவை பயிற்சிக்கு பயன்படுத்தப்படும் தரவு (Training Data), மாதிரி கட்டமைப்பு (Model Architecture) மற்றும் அளவு (Size), மேலும் மனித விருப்பங்களுக்கு ஏற்ப அவற்றை எப்படி மேம்படுத்துகிறார்கள் (Post-training) என்பதன் மூலம் புரிந்து கொள்ளலாம்.

**மாதிரியின்  அறிவு: தரவின் முக்கியத்துவம்**

மாதிரி தரவுகளில் இருந்து கற்றுக்கொள்கிறது. எனவே, நாம் பயன்படுத்தும் பயிற்சி தரவு அதன் வலிமை மற்றும் பலவீனங்களை வெளிப்படுத்துகிறது. உதாரணமாக, ஒரு மாதிரி, நிறைய சமையல் குறிப்புகளைப் படித்திருந்தால், அது உணவுகளைப் பற்றி துல்லியமாக பேசும். அதுவே ஒரு மாதிரி, நிறைய அறிவியல் கட்டுரைகளைப் படித்திருந்தால், அது அறிவியல் விஷயங்களைப் பற்றி துல்லியமாக பேசும். ஒரு மாதிரி  எவ்வளவு புத்திசாலியாக (smart) இருக்கும் என்பது, அது பயிற்சி பெற்ற தரவைப் பொறுத்துதான் இருக்கிறது. இது ஒரு மாணவர் எவ்வளவு நன்றாகப் படிக்கிறார் என்பது, அவர் படிக்கும் புத்தகங்கள்  மற்றும் பாடங்கள் எவ்வளவு தரமானவை என்பதைப் பொறுத்தது போன்றது. மாதிரி  தரவுகளை பயன்படுத்தி, அதன் அறிவை உருவாக்குகிறது. இந்த தரவுகள் எவ்வளவு தரமானவை மற்றும் எவ்வளவு பரவலானவை (**diverse**) என்பதைப் பொறுத்து மாதிரியின்  திறன் (**capability**) மாறுபடும்.

தரவின் தரம் மாதிரியின் செயல்திறனை (**performance**) நேரடியாக பாதிக்கிறது. உயர்தர தரவு (**High-quality data**) மாதிரி  துல்லியமான மற்றும் நம்பகமான (**reliable**) பதில்களை  வழங்க உதவுகிறது. உதாரணமாக, ஒரு மாதிரி  தமிழில் உயர்தர தரவுகளை பயன்படுத்தி பயிற்சி பெற்றால், அது தமிழில் துல்லியமான பதில்களை வழங்கும்.

Diversity of Data-அ, மாதிரி பல்வேறு சூழல்களில் (**various contexts**) செயல்பட உதவுகிறது மற்றும் பல்வேறு விஷயங்களைப் பற்றி கற்றுக்கொள்ளவும் உதவுகிறது. உதாரணமாக, ஒரு மாதிரி  பல்வேறு மொழிகளில் தரவுகளை பயன்படுத்தி பயிற்சி பெற்றால், அது பல்வேறு மொழிகளில் பேசும் திறனைப் பெறும். 

தரவின் அளவு (Quantity of Data) மாதிரியின் அறிவை விரிவுபடுத்த உதவுகிறது. பல்வேறு விஷயங்களைப் பற்றி கற்றுக்கொள்ள அதிக அளவு தரவுகள் (**Large amount of data**) உதவுகிறது. உதாரணமாக, ஒரு மாதிரி  நிறைய பூனை படங்களை (**Cat Images**) பார்த்திருந்தால், அது பூனைகளை (**Cats**) அடையாளம் கண்டுபிடிக்கும் திறனைப் பெறும்.

 சரி, இப்போது நீங்கள் ஒரு மாதிரியை  **"train"** செய்ய வேண்டும் என்று வைத்துக்கொள்வோம். அதற்கு நிறைய **"தரவு "** தேவை. ஆனால், **"தரவு "** சேகரிப்பது (**Data Collection**) அவ்வளவு எளிதான காரியம் இல்லை. அதற்கு நிறைய பணம் செலவாகும். அதனால், **"developers"** எல்லாரும் **"Common Crawl"** போன்ற **"open source data"**-ஐப் பயன்படுத்துகிறார்கள். இந்த Common Crawl-ல் எல்லா வகையான websites-ல் இருந்தும் தரவுகள் இருக்கும். அதில் நல்ல websites மற்றும் கெட்ட websites கலந்து இருக்கும். சில சமயம் fake news கூட இருக்கலாம். ஆனால், வேறு வழி இல்லாததால், "developers" இந்த தரவுகளை பயன்படுத்துகிறார்கள். Common Crawl தரவுகளை பயன்படுத்தி பயிற்சி செய்யப்பட்ட மாதிரி சில சமயம் **"biased"**-ஆக நடந்துகொள்ளலாம். அதாவது, சில விஷயங்களை (**Topics**) ஆதரிக்கலாம், சில விஷயங்களை எதிர்க்கலாம். 

தரவு சார்புகள் (Data Biases) மாதிரியின் செயல்திறனை பாதிக்கின்றன. இந்த சார்புகள் தரவுகள் சேகரிக்கப்படும் முறையில் (**collection methods**) உள்ள குறைபாடுகள் காரணமாக ஏற்படுகின்றன. உதாரணமாக, ஒரு மாதிரி  நிறைய ஆண்களின் படங்களை பார்த்திருந்தால், அது பெண்களின் படங்களை அடையாளம் கண்டுபிடிக்க முடியாது. அதனால், நாம் எந்த பணிக்கு மாதிரியை  பயன்படுத்தப் போகிறோம் என்று முடிவு செய்து, அதற்கு தகுந்த மாதிரி தரவுகளை தேர்ந்தெடுத்து செய்ய வேண்டும்.

நாம் ஏற்கனவே **Foundation Models**-ன் முக்கியத்துவத்தைப் பற்றி பார்த்தோம். இப்போது, இந்த மாதிரிகள் எப்படி உருவாக்கப்படுகின்றன என்பதை மூன்று முக்கிய கட்டங்களாக (**Pre-training, Fine-tuning மற்றும் Post-training**) பிரித்து, ஒவ்வொன்றையும் விரிவாகப் பார்ப்போம். இந்த கட்டங்கள் ஒவ்வொன்றும் ஒரு மாதிரியை  மேலும் மேலும் மேம்படுத்தி, அதை பயனர்களுக்கு பயனுள்ளதாக மாற்ற உதவுகின்றன.

**Pre-training** என்பது மாதிரிக்கு ஒரு அடிப்படை அறிவை (**foundational knowledge**) கொடுக்கும் கட்டம். இந்த கட்டத்தில், மாதிரி நிறைய தரவுகளை பயன்படுத்தி, பல்வேறு விஷயங்களைப் பற்றி கற்றுக்கொள்கிறது. இது ஒரு குழந்தை பள்ளிக்கு செல்லும் முன், அடிப்படை எழுத்து, எண்கள் போன்றவற்றைக் கற்றுக்கொள்வது போன்றது.

**எப்படி இது நடக்கிறது?**  

மாதிரி பல்வேறு தரவுகளை பார்க்கிறது - உரை (**text**), படங்கள் (**images**), ஒலி (**audio**) போன்றவை. இந்த தரவுகளை பயன்படுத்தி, மாதிரி சொற்களுக்கு இடையே உள்ள தொடர்புகளை கற்றுக்கொள்கிறது. உதாரணமாக, **"ராஜா"** என்ற சொல்லுக்கும் **"அரசன்"** என்ற சொல்லுக்கும் உள்ள தொடர்பை புரிந்துகொள்கிறது. நீங்கள் ஒரு மாதிரியை  **Pre-training** செய்ய, அதற்கு நிறைய புத்தகங்கள், கட்டுரைகள் மற்றும் இணைய தரவுகள் கொடுக்கிறீர்கள். இந்த தரவுகளை பயன்படுத்தி, மாதிரி பொதுவான அறிவைப் மட்டுமே பெறுகிறது. இதனால் இக்கட்டத்தில்  மாதிரி சரியான பதிலை (**Accurate Response**) சொல்லுவதற்கு முன்பாக, கொஞ்சம் **"fine-tune"** செய்ய வேண்டிய அவசியம் ஏற்படுகிறது.

**Fine-tuning** என்பது **Pre-training**-க்குப் பிறகு மாதிரியை மேலும் மேம்படுத்தும் ஒரு கட்டம். இந்த கட்டத்தில், மாதிரி குறிப்பிட்ட பணிகளுக்கு தன்னைத் தகவமைத்துக் கொள்கிறது. இது ஒரு குழந்தை பள்ளியில் அடிப்படை கல்வியை முடித்த பிறகு, ஒரு குறிப்பிட்ட பாடத்தில் நிபுணத்துவம் பெறுவது போன்றது.

**எப்படி இது நடக்கிறது?** **Fine-tuning**-ல் மாதிரி குறிப்பிட்ட பணிக்கு (**specific task**) தேவையான தரவுகளை பயன்படுத்தி பயிற்சி பெறுகிறது. உதாரணமாக, மருத்துவத் துறையில் (**medical domain**) **Fine-tuning** செய்ய, மருத்துவக் கட்டுரைகள் (**medical articles**), நோய்களின் விளக்கங்கள் (**disease descriptions**) மற்றும் மருந்துகள் (**drugs**) பற்றிய தரவுகள் பயன்படுத்தப்படுகின்றன.

நீங்கள் ஒரு நோயாளியின் அறிகுறிகளை மாதிரிக்கு விவரிக்கிறீர்கள் என வைத்துக்கொள்வோம். **Pre-trained** மாதிரி பொதுவான (**general**) பதில்களை (**responses**) மட்டுமே வழங்கும். ஆனால், **Fine-tuned** மாதிரி  மருத்துவத் துறையில் (**medical domain**) பயிற்சி பெற்றிருப்பதால், அது நோயாளியின் அறிகுறிகளுக்கு சரியான நோய் மற்றும் சிகிச்சையைப்  பற்றி துல்லியமாக பதில் சொல்லும்.

Pre-training  மற்றும் Fine-tuning-க்குப் பிறகு மாதிரியை  மேலும் மேம்படுத்தும் ஒரு கட்டம் தான் **"Post-training"**. இந்த கட்டத்தில், மாதிரி மனிதர்கள் எதிர்பார்ப்பது போன்ற பதில்களை (**Human-like Responses**) சொல்லும்படி பயிற்சி பெறுகிறது. இது ஒரு குழந்தை பள்ளியில் கற்றுக்கொண்ட பிறகு, உலகத்துடன் எப்படி இணைந்து செயல்பட வேண்டும் என்பதைக் கற்றுக்கொள்வது போன்றது.

**Pre-training** மற்றும் **Fine-tuning**-ல் மாதிரி பொதுவான மற்றும் குறிப்பிட்ட அறிவைப் பெறுகிறது. ஆனால், மனிதர்கள் எதிர்பார்ப்பது போன்ற பதில்களை (**Human-like Responses**) வழங்குவதற்கு, மாதிரி மனிதர்களின் விருப்பங்கள் (**preferences**), நடத்தை (**behavior**) மற்றும் எதிர்பார்ப்புகள் (**expectations**) ஆகியவற்றைப் புரிந்துகொள்ள வேண்டும். இது மாதிரி, மனிதர்களுடன் இணைந்து செயல்பட உதவுகிறது.

உதாரணமாக தர்க்கரீதியான மற்றும் பொருத்தமான பதில்கள் அளித்தால். மனிதர்கள் ஒரு கேள்வியை கேட்டால், அதற்கு ஒரு தர்க்கரீதியான (**logical**) மற்றும் பொருத்தமான (**relevant**) பதிலை (**response**) எதிர்பார்க்கிறார்கள். **Post-training** மூலம், மாதிரி இந்த எதிர்பார்ப்புகளை பூர்த்தி செய்யும் திறனைப் பெறுகிறது. 

Post-training-ல், மாதிரி மனிதர்களின் உரையாடல்களை பயன்படுத்தி பயிற்சி பெறுகிறது. இந்த உரையாடல்கள் மனிதர்களின் விருப்பங்கள் நடத்தை மற்றும் எதிர்பார்ப்புகள் ஆகியவற்றைப் புரிந்துகொள்ள உதவுகின்றன. மாதிரி **human feedback** பயன்படுத்தி பயிற்சி பெறுகிறது. இந்த பின்னூட்டம் மாதிரி எவ்வளவு நன்றாக செயல்படுகிறது என்பதை மதிப்பீடு செய்ய உதவுகிறது.

**Post-training**-க்குப் பிறகு, மாதிரி மனிதர்களின் எதிர்பார்ப்புகளை எவ்வளவு நன்றாக பூர்த்தி செய்கிறது என்பதை மதிப்பீடு செய்யப்படுகிறது. இதற்காக, **validation data** பயன்படுத்தப்படுகிறது.

சரி, இப்போது **"Sampling"** பற்றி பேசலாம். இது கொஞ்சம் கடினமான விஷயம். ஏனென்றால் நமது மாதிரி நிறைய பதில்களை சொல்லத் தெரிந்து வைத்திருக்கும். ஆனால், அதில் எந்த பதில் சரியானது என்று எப்படி முடிவு செய்யும்? அதற்குத்தான் இந்த **"Sampling"** பயன்படுகிறது. இதில் பல நுணுக்கங்கள் உள்ளன. சரியான நுணுக்கங்களைப் பயன்படுத்தினால், மாதிரி துல்லியமானபதிலை சொல்லும். இல்லையென்றால் பொருத்தமற்ற பதில்களைச் சொல்லும்.

**எப்படி இது நடக்கிறது?**  

மாதிரி ஒரு கேள்விக்கு பல பதில்களை உருவாக்குகிறது. இந்த பதில்களில் எது சரியானது என்று முடிவு செய்ய, **"Sampling Techniques"** பயன்படுத்தப்படுகின்றன. உதாரணமாக, **"Top-k Sampling"** அல்லது **"Temperature Sampling"** போன்ற முறைகள் பயன்படுத்தப்படுகின்றன. இந்த முறைகள், மாதிரி எந்த பதிலை தேர்ந்தெடுக்க வேண்டும் என்பதை நிர்ணயிக்கின்றன.

Language Generation மாதிரிகள், ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லையும் தேர்ந்தெடுக்கும். இந்த தேர்வு, சொற்களின் "நிகழ்தகவு" (probability) அடிப்படையில் நடைபெறுகிறது. Temperature அளவுரு, இந்த நிகழ்தகவுகளை எவ்வாறு பயன்படுத்துவது என்பதைக் கட்டுப்படுத்துகிறது.

மாதிரி ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லுக்கும் ஒரு நிகழ்தகவு மதிப்பைக் கணக்கிடுகிறது. உதாரணமாக, வாக்கியம்:

**"தமிழ் மொழி .…"**

இதற்கு மாதிரி பின்வரும் சொற்களைத் தேர்ந்தெடுக்கலாம்:

\- **தொன்மையானது** — 50% நிகழ்தகவு

\- **பழமையானது** — 30% நிகழ்தகவு

\- **சிக்கலானது** — 15% நிகழ்தகவு

\- **எளிமையானது** — 5% நிகழ்தகவு

Temperature 0 எனில், மாதிரி எப்போதும் அதிக நிகழ்தகவு உள்ள சொல்லைத் தேர்ந்தெடுக்கும். பதில்கள் மிகவும் துல்லியமாகவும், முன்னரே தீர்மானிக்கப்பட்டவையாகவும் இருக்கும். Temperature 0.5 எனில், மாதிரி அதிக நிகழ்தகவு உள்ள சொற்களை அடிக்கடி தேர்ந்தெடுக்கும், ஆனால் சில சமயங்களில் குறைந்த நிகழ்தகவு உள்ள சொற்களையும் தேர்ந்தெடுக்கலாம். Temperature 1 எனில், மாதிரி அனைத்து சொற்களையும் சமமான வாய்ப்புகளுடன் தேர்ந்தெடுக்கும். இது படைப்பாற்றலை அதிகரிக்கும், ஆனால் சில சமயங்களில் தவறான அல்லது பொருத்தமற்ற சொற்களையும் தேர்ந்தெடுக்கலாம். Temperature அதிகரிக்கும் போது, பதில்கள் படைப்பாற்றலுடன் இருக்கும், ஆனால் துல்லியம் குறையலாம் (hallucination). 

ஆங்கிலம்தான் இன்டர்நெட் உலகத்தில் கோலோச்சுகிறது  என்பது எல்லாருக்கும் தெரியும். **"Common Crawl"** போன்ற தரவுசெட்களை (**Datasets**) பார்த்தால், ஆங்கிலம்தான் அதிகமாக இருக்கிறது. அதற்கு அடுத்த இடத்தில் ரஷ்யன், ஜெர்மன், சீனம் போன்ற மொழிகள் உள்ளன. ஆனால், தமிழ் போன்ற மொழிகள் மிகவும் குறைவாக உள்ளன. இதனால்தான், இவற்றை **"low-resource languages"** என்று அழைக்கிறார்கள்.

இப்படி ஆங்கிலம் கோலோச்சுவதால், **"general-purpose models"** ஆங்கிலத்தில் தான் நன்றாக வேலை செய்கின்றன. தமிழ் போன்ற மொழிகளில் கொஞ்சம் சிரமம் உள்ளது. ஏனென்றால், தமிழில் இருக்கும் தரவு மிகவும் குறைவு. இது மட்டும் இல்லை, தமிழின் இலக்கணம் மற்றும் தொடரமைப்பு  போன்றவை கொஞ்சம் சிடுக்கானது. அதனால், தமிழ் போன்ற மொழிகளில் **LLM (Large Language Models)** உருவாக்குவது மிகவும் சிரமமானது. ஆனால், நமது தமிழிலும் நன்றாக வேலை செய்யும் மாதிரிகள் வரவேண்டும் என்று நிறைய பேர் முயற்சி செய்கிறார்கள். **"AI4Bharat"** போன்ற அமைப்புகள் தமிழில் தரவு சேகரித்து , **"open source"**-ஆக வெளியிடுகின்றன. இவை எல்லாம் தமிழில் **"LLM"** உருவாக்குவதற்கு மிகவும் உதவியாக இருக்கும். 

நாம் ஏற்கனவே பேசியது போல, **"general-purpose models"** பொதுவான விஷயங்களில் நன்றாக வேலை செய்யும். ஆனால், **"domain-specific tasks"**-ல் அவ்வளவு நன்றாக வேலை செய்யாது. ஏனென்றால், இந்த பணிகளுக்கு specific data தேவைப்படுகிறது. இந்த தரவு எல்லாம் நம்மால் எளிதாக சேகரிக்க முடியாது. உதாரணத்திற்கு, மருந்து கண்டுபிடிப்பதற்கு (**drug discovery**), புரோட்டீன் (**protein**), டிஎன்ஏ (**DNA**), ஆர்என்ஏ (**RNA**) போன்ற தரவு (**Data**) தேவைப்படும். அதேபோல், புற்றுநோயைக் கண்டுபிடிப்பதற்கு, எக்ஸ்ரே (**X-ray**), எஃப்எம்ஆர்ஐ ஸ்கேன்கள் (**fMRI scans**) போன்றவை தேவைப்படும். இந்த தரவு எல்லாம் மிகவும் விலை உயர்ந்தது அதோடு பிரைவசி பிரச்சனைகள் (**privacy issues**) காரணமாக எளிதாக கிடைக்காது.

அதனால், இந்த மாதிரி பணிகளுக்கு **"domain-specific models"** தேவைப்படுகின்றன. இந்த மாதிரிகள், அந்த டொமைனில் இருக்கும் தரவுவை பயன்படுத்தி பயிற்சி பெற்றிருக்கும். உதாரணத்திற்கு, **DeepMind**-இன் **AlphaFold** மாதிரி, புரோட்டீன் கட்டமைப்பை (**protein structure**) கண்டுபிடிப்பதிலும்,  **NVIDIA**-இன் **BioNeMo** மாதிரி மருந்து கண்டுபிடிப்பதிலும், **Google**-இன் **Med-PaLM2** மாதிரி, மருத்துவ கேள்விகளுக்கு (**medical questions**) பதில் சொல்வதிலும் சிறந்து விளங்குகின்றன.

இந்த மாதிரி **"domain-specific models"** எல்லா துறைகளிலும் பயனுள்ளதாக இருக்கும். ஆனால், இப்போதைக்கு பயோமெடிசினில் (**biomedicine**) தான் அதிகமாக பயன்படுத்தப்படுகின்றன. எதிர்காலத்தில் எல்லா துறைகளிலும் **"domain-specific models"** பயன்படுத்தப்படும்.

<div style="page-break-after: always;"></div>

#### 7. Bag of Words (BoW) 

**Bag of Words (BoW)** என்பது, உரையை **சொற்களின் தொகுப்பாக** மாற்றும் ஒரு எளிய முறை. இந்த முறையில், உரையில் உள்ள ஒவ்வொரு சொல்லும் ஒரு **வெக்டராக** மாற்றப்படுகிறது, ஆனால் இது **Embedding-ஐ விட மிகவும் எளிமையானது**. இது உரையின் **சொற்களின் அதிர்வெண்ணை** (Frequency) மட்டுமே கணக்கில் எடுத்துக்கொள்கிறது, சொற்களின் **வரிசை** அல்லது **சூழல்** பற்றி கவலைப்படுவதில்லை.

---

##### எப்படி செயல்படுகிறது?

1. **சொற்களைத் தொகுத்தல்:**  
   - உரையில் உள்ள அனைத்து சொற்களையும் ஒரு **சொல் பட்டியலாக** (Vocabulary) தொகுக்கிறது.  
   - **உதாரணம் :**  
     - வாக்கியம் 1: "I love programming."  
     - வாக்கியம் 2: "Programming is fun."  
     - **Vocabulary:** ["I", "love", "programming", "is", "fun"].

2. **சொற்களின் அதிர்வெண்ணைக் கணக்கிடுதல்:**  
   - ஒவ்வொரு வாக்கியத்திலும், சொல் பட்டியலில் உள்ள சொற்கள் எத்தனை முறை வருகின்றன என்பதைக் கணக்கிடுகிறது.  
   - **உதாரணம் :**  
     - வாக்கியம் 1: "I love programming." → [1, 1, 1, 0, 0]  
     - வாக்கியம் 2: "Programming is fun." → [0, 0, 1, 1, 1]  
   - **விளக்கம்:**  
     - "I" என்ற சொல் முதல் வாக்கியத்தில் 1 முறை வந்துள்ளது, ஆனால் இரண்டாவது வாக்கியத்தில் வரவில்லை.  
     - "Programming" என்ற சொல் இரண்டு வாக்கியங்களிலும் 1 முறை வந்துள்ளது.

3. **வெக்டராக மாற்றுதல்:**  
   - ஒவ்வொரு வாக்கியமும் ஒரு **வெக்டராக** மாற்றப்படுகிறது, இது சொல் பட்டியலில் உள்ள சொற்களின் அதிர்வெண்ணைக் காட்டுகிறது.  
   - **உதாரணம் :**  
     - வாக்கியம் 1: [1, 1, 1, 0, 0]  
     - வாக்கியம் 2: [0, 0, 1, 1, 1]  

Bag of Words-ன் முக்கியத்துவம்

1. **எளிமை:**  

   BoW முறை மிகவும் எளிமையானது மற்றும் கணக்கிட எளிதானது.  

   - **உதாரணம் :**  

     - "I love programming." → [1, 1, 1, 0, 0]  

     இந்த முறை உரையை எளிதாக எண்ணியல் வடிவத்தில் மாற்றுகிறது, இது Machine Learning மாடல்களுக்கு உள்ளீடாக பயன்படுத்தப்படுகிறது.

2. **சொற்களின் அதிர்வெண்:**  

   BoW முறை உரையில் உள்ள சொற்களின் அதிர்வெண்ணை மட்டுமே கணக்கில் எடுத்துக்கொள்கிறது.  

   "Programming" என்ற சொல் இரண்டு வாக்கியங்களிலும் 1 முறை வந்துள்ளது. இது உரையின் முக்கிய சொற்களைக் கண்டறிய உதவுகிறது.

3. **சூழல் பற்றிய தகவல் இல்லை:**  

   BoW முறை சொற்களின் **வரிசை** அல்லது **சூழல்** பற்றி கவலைப்படுவதில்லை.  "The child makes the dog happy" மற்றும் "The dog makes the child happy" இரண்டும் ஒரே BoW வெக்டராகக் கருதப்படும்.   இது BoW முறையின் முக்கிய குறைபாடு, ஏனெனில் இது உரையின் அர்த்தத்தை முழுமையாக பிரதிபலிக்காது.

---

##### Bag of Words-ன் பயன்பாடுகள்

1. **உரை வகைப்படுத்துதல் (Text Classification):**  
   - உரையை வகைப்படுத்துவதற்கு BoW முறை பயன்படுத்தப்படுகிறது.  
   - **உதாரணம் :**  
     - ஸ்பேம்(Spam) மெயில்களைக் கண்டறிதல்.  

2. **உணர்வு பகுப்பாய்வு (Sentiment Analysis):**  
   - உரையின் உணர்வைப் பகுப்பாய்வு செய்ய BoW முறை பயன்படுத்தப்படுகிறது.  
   - **உதாரணம் :**  
     - "I love this product!" → நேர்மறை உணர்வு.  

3. **தகவல் மீட்பு (Information Retrieval):**  
   - தேடுபொறிகளில் (Search Engines) BoW முறை பயன்படுத்தப்படுகிறது.  
   - **உதாரணம் :**  
     - "Python programming" என்ற தேடல், "Python" மற்றும் "programming" என்ற சொற்களைக் கொண்ட ஆவணங்களை மீட்டெடுக்கும்.  

BoW முறை எளிமையானது, ஆனால் Embedding முறை மிகவும் சிக்கலானது ஆனால் துல்லியமானது. நவீன NLP பணிகளுக்கு Embedding முறை மிகவும் பயனுள்ளதாக இருக்கிறது. Embedding பற்றி அடுத்த இனிவரும் பதிவில் காண்போம்.

<div style="page-break-after: always;"></div>

####  8. Embedding

**Embedding** என்பது, **ஒவ்வொரு Token-ஐயும் (சொல்லை) எண்ணியல் வெக்டராக மாற்றும் செயல்முறை**. இந்த வெக்டர்கள் **Neural Network**-களால் புரிந்து கொள்ளக்கூடிய வடிவத்தில் இருக்கும். இது LLM-களுக்கு **சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள** உதவுகிறது.

##### Embedding-கள் என்றால் என்ன?

Embedding-கள் என்பது ஒரு வகையான **தரவு பிரதிநிதித்துவம் (Data Representation)**. இது உரை (text), படங்கள் (images), ஒலி (audio) போன்ற தரவுகளை எண்களாக மாற்றி, கணினிகள் புரிந்து கொள்ளும் வகையில் காட்டுகிறது. Embedding-கள் முக்கியமாக **Natural Language Processing (NLP)**-ல் பயன்படுத்தப்படுகிறது, அங்கு வார்த்தைகள், வாக்கியங்கள் அல்லது பத்திகள் எண்களாக மாற்றப்படுகின்றன.

எப்படி Embedding-கள் செயல்படுகின்றன?

1. **Token to Vector:**  

   - ஒவ்வொரு Token-ஐயும் (சொல்லை) ஒரு **தனிப்பட்ட எண்ணியல் வெக்டராக** மாற்றுகிறது.  
   - **உதாரணம்:**  
     - **Token:** "Programming"  
     - **Embedding:** [0.25, -0.12, 0.87, ..., 0.45] (ஒரு நீண்ட எண் வரிசை).  
   - **விளக்கம்:**  
     - "Programming" என்ற சொல் ஒரு எண் வரிசையாக (Vector) மாற்றப்படுகிறது. இந்த வெக்டர், அந்த சொல்லின் **பொருள் மற்றும் பண்புகளை** பிரதிபலிக்கிறது.

2. **Vector Dimensions:**  

   - இந்த வெக்டர்கள் பொதுவாக **100 முதல் 1000 வரையிலான பரிமாணங்களைக் கொண்டிருக்கும்**.  
   - **உதாரணம்:**  
     - GPT-3 மாடல்களில், ஒவ்வொரு Token-க்கும் **768 பரிமாணங்கள்** உள்ளன.  
   - **விளக்கம்:**  
     - ஒவ்வொரு சொல்லும் 768 எண்களைக் கொண்ட ஒரு வெக்டராக மாற்றப்படுகிறது. இது அந்த சொல்லின் **சிக்கலான பண்புகளை** பிரதிபலிக்கிறது.

3. **Semantic Meaning:**  

   - Embedding-கள் **சொற்களின் பொருளைப் பிரதிபலிக்கின்றன**.  
   - **உதாரணம்:**  
     - "King" மற்றும் "Queen" என்ற சொற்களின் Embedding-கள் ஒரே மாதிரியாக இருக்கும், ஆனால் அவை வெவ்வேறு பாலினங்களைக் குறிக்கின்றன.  
   - **விளக்கம்:**  
     - "King" மற்றும் "Queen" என்ற சொற்கள் ஒரே மாதிரியான Embedding-களைக் கொண்டிருக்கும், ஏனெனில் அவை இரண்டும் **அரசர்களை** குறிக்கின்றன. ஆனால், அவை வெவ்வேறு பாலினங்களைக் குறிப்பதால், அவற்றின் Embedding-கள் சிறிது வேறுபடும்.

4. **Neural Network Input:**  

   - இந்த Embedding-கள் **Neural Network**-க்கு உள்ளீடாக அனுப்பப்படுகின்றன.  
   - **உதாரணம்:**  
     - "Python is a programming language."  
     - **Tokenization:** ["Python", "is", "a", "programming", "language"].  
     - **Embedding:**  
       - "Python" → [0.12, -0.45, 0.67, ..., 0.89]  
       - "programming" → [0.25, -0.12, 0.87, ..., 0.45]  
       - "language" → [0.34, -0.56, 0.78, ..., 0.23]  
   - **விளக்கம்:**  
     - ஒவ்வொரு சொல்லும் ஒரு எண் வரிசையாக மாற்றப்பட்டு, Neural Network-க்கு உள்ளீடாக அனுப்பப்படுகிறது. இது மாடலை **சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள** உதவுகிறது.

##### Embedding-களின் முக்கியத்துவம்

1. **சொற்களின் பொருள்:**  Embedding-கள் சொற்களின் பொருளைப் பிரதிபலிக்கின்றன.  

   - **உதாரணம்:**  
     - "King" மற்றும் "Ruler" என்ற சொற்களின் Embedding-கள் ஒரே மாதிரியாக இருக்கும், ஏனெனில் அவை ஒரே பொருளைக் கொண்டவை.  
   - **விளக்கம்:**  
     - "King" மற்றும் "Ruler" என்ற சொற்கள் ஒரே பொருளைக் கொண்டிருப்பதால், அவற்றின் Embedding-கள் ஒரே மாதிரியாக இருக்கும்.

2. **சொற்களுக்கு இடையே உள்ள தொடர்புகள்:**  Embedding-கள் சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் காட்டுகின்றன.  

​		**உதாரணம்:**  "King" - "Man" + "Woman" = "Queen".  

​		**விளக்கம்:**  இந்த கணித செயல்பாடு, "King" என்ற சொல்லின் Embedding-				    லிருந்து "Man" என்ற சொல்லின் Embedding-ஐ கழித்து, 				    "Woman" என்ற சொல்லின் Embedding-ஐ கூட்டினால், "Queen" 				     என்ற சொல்லின் Embedding கிடைக்கும். இது Embedding-கள் 				     சொற்களுக்கு இடையே உள்ள தொடர்புகளைப் புரிந்து 				     கொள்வதைக் காட்டுகிறது.

3. **Neural Network-க்கு உள்ளீடு:**  Embedding-கள் Neural Network-க்கு உள்ளீடாக அனுப்பப்படுகின்றன, இது மாடலை **சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள** உதவுகிறது.  

​		**உதாரணம்:**  "Python is a programming language."  

​		**விளக்கம்:**  இந்த வாக்கியத்தில் உள்ள ஒவ்வொரு சொல்லும் Embedding-				ஆக மாற்றப்பட்டு, Neural Network-க்கு உள்ளீடாக 				அனுப்பப்படுகிறது. இது மாடலை **வாக்கியத்தின் அர்த்தத்தைப் 			     புரிந்து கொள்ள** உதவுகிறது.

Embedding-கள் என்பது உரை தரவை கணினிகள் புரிந்து கொள்ளும் வகையில் எண்களாக மாற்றும் ஒரு சக்திவாய்ந்த கருவி. இது NLP-ல் மிகவும் முக்கியமானது மற்றும் மெஷின் கற்றல் மாதிரிகளின் துல்லியத்தை மேம்படுத்துகிறது. Word2Vec, GloVe, மற்றும் BERT போன்ற முன்-பயிற்சி பெற்ற embeddings நிறைய பணிகளுக்கு பயன்படுத்தப்படுகின்றன. இவை மொழி மாதிரிகளின் செயல்திறனை மேம்படுத்துவதில் முக்கிய பங்கு வகிக்கின்றன.

<div style="page-break-after: always;"></div>

##### Bag of Words vs Embedding

| **Feature**       | **Bag of Words (BoW)**                 | **Embedding**                                      |
| ----------------- | -------------------------------------- | -------------------------------------------------- |
| **சொற்களின் அர்த்தம்** | சொற்களின் அதிர்வெண்ணை மட்டுமே கணக்கிடுகிறது. | சொற்களின் பொருள் மற்றும் சூழலைப் பிரதிபலிக்கிறது.         |
| **சொற்களின் வரிசை** | சொற்களின் வரிசை பற்றி கவலைப்படுவதில்லை.     | சொற்களின் வரிசை மற்றும் சூழலைக் கணக்கில் எடுத்துக்கொள்கிறது. |
| **சிக்கலான தன்மை**  | எளிமையானது மற்றும் கணக்கிட எளிதானது.      | மிகவும் சிக்கலானது மற்றும் கணக்கிட கடினமானது.           |
| **பயன்பாடு**       | எளிய NLP பணிகளுக்கு பயன்படுத்தப்படுகிறது.  | நவீன NLP பணிகளுக்கு பயன்படுத்தப்படுகிறது.               |

<div style="page-break-after: always;"></div>

#### 9. Word2Vec:

Word2Vec என்பது **வார்த்தைகளை வெக்டர்களாக (vectors) மாற்றும் ஒரு தொழில்நுட்பம்** ஆகும். இது வார்த்தைகளுக்கு இடையேயான உறவுகளை (relationships) ஒரு வரைபடம் (graph) போன்று பிரதிநிதித்துவப்படுத்துகிறது. இந்த தொழில்நுட்பம் மெஷின் கற்றல் (machine learning) மற்றும் உரை பகுப்பாய்வு (text analysis) போன்ற துறைகளில் பரவலாக பயன்படுத்தப்படுகிறது.

2013-ல் Google தங்கள் தேடுபொறிக்காக (search engine) Word2Vec-ஐ அறிமுகப்படுத்தியது, மேலும் இந்த அல்காரிதத்தை பேட்டன்ட் செய்தது. இந்த தொழில்நுட்பத்தை Tomas Mikolov மற்றும் அவரது குழுவினர் உருவாக்கினர். இந்த கட்டுரையில், Word2Vec-ஐப் பயன்படுத்தி embeddings உருவாக்கும் கருத்து மற்றும் செயல்முறைகளை புரிந்து கொள்வோம்.

---

##### Word Embedding என்றால் என்ன?
உரை பகுப்பாய்வில், ஒரு வார்த்தையை பிரதிநிதித்துவப்படுத்த **Word Embedding** பயன்படுத்தப்படுகிறது. இது பொதுவாக ஒரு திசையன் (vector) வடிவில் இருக்கும், இது வார்த்தையின் அர்த்தத்தை குறியாக்கம் (encode) செய்கிறது. இந்த திசையன் வெளி (vector space) ஒரே மாதிரியான அர்த்தம் கொண்ட வார்த்தைகள் ஒன்றுக்கொன்று அருகில் இருக்கும்.

உதாரணம்:

- **"ராஜா" (King) மற்றும் "ராணி" (Queen) என்ற வார்த்தைகள் ஒரே மாதிரியான embeddings கொண்டிருக்கும்.**
- "ராஜா - ஆண் + பெண் = ராணி" என்று கணித ரீதியாக காட்டலாம்:
  - `vector("ராஜா") - vector("ஆண்") + vector("பெண்") ≈ vector("ராணி")`

---

##### Word2Vec-ன் இரண்டு முக்கிய முறைகள் :

###### 1. Continuous Bag of Words (CBOW):
- இந்த முறையில், சுற்றியுள்ள வார்த்தைகள் (context words) கொடுக்கப்பட்டு, இலக்கு வார்த்தை (target word) கணிக்கப்படுகிறது.
- எடுத்துக்காட்டு: "The cat sat on the ___" என்ற வாக்கியத்தில், "___" இடத்தில் "mat" என்ற வார்த்தையை கணிக்க CBOW பயன்படுத்தப்படுகிறது.
- **CBOW-ன் நன்மைகள்:**
  - சிறிய தரவு மூலம் நன்றாக வேலை செய்யும்.
  - வேகமானது மற்றும் குறைந்த கணினி வளங்கள் தேவை.

###### 2. Skip-Gram:
- இந்த முறையில், இலக்கு வார்த்தை (target word) கொடுக்கப்பட்டு, சுற்றியுள்ள வார்த்தைகள் (context words) கணிக்கப்படுகின்றன.
- எடுத்துக்காட்டு: "cat" என்ற வார்த்தை கொடுக்கப்பட்டு, "The", "sat", "on", "the" போன்ற சுற்றியுள்ள வார்த்தைகள் கணிக்கப்படுகின்றன.
- **Skip-Gram-ன் நன்மைகள்:**
  - பெரிய தரவு மூலம் நன்றாக வேலை செய்யும்.
  - அரிதான வார்த்தைகளுக்கு (rare words) நன்றாக வேலை செய்யும்.

Word2Vec-ன் பயன்பாடுகள்:

1. **தேடுபொறிகள் (Search Engines):**
   - தேடல் முடிவுகளின் துல்லியத்தை மேம்படுத்த Word2Vec பயன்படுத்தப்படுகிறது.
   - எடுத்துக்காட்டு: "apple" என்ற வார்த்தை பழத்தை குறிக்கிறதா அல்லது நிறுவனத்தை குறிக்கிறதா என்பதை Word2Vec புரிந்து கொள்ளும்.

2. **மொழிபெயர்ப்பு (Language Translation):**
   - Google Translate போன்ற மொழிபெயர்ப்பு பயன்பாடுகளில் Word2Vec பயன்படுத்தப்படுகிறது.

3. **வாடிக்கையாளர் கருத்து பகுப்பாய்வு (Customer Feedback Analysis):**
   - வாடிக்கையாளர் கருத்துகளை பகுப்பாய்வு செய்ய Word2Vec பயன்படுத்தப்படுகிறது.

4. **பரிந்துரை அமைப்புகள் (Recommendation Systems):**
   - பயனர்களின் தேடல் வரலாறு மற்றும் வாங்கிய பொருட்களை அடிப்படையாக கொண்டு பரிந்துரை அமைப்புகள் உருவாக்கப்படுகின்றன.

Word2Vec-ன் குறைபாடுகள்:

1. **அறியப்படாத வார்த்தைகளை கையாளும் திறன் இல்லை:**
   - Word2Vec அறியப்படாத வார்த்தைகளை கையாள முடியாது.

2. **உப-வார்த்தை நிலைகளில் பகிரப்பட்ட பிரதிநிதித்துவங்கள் இல்லை:**
   - Word2Vec ஒவ்வொரு வார்த்தையையும் ஒரு தனி வெக்டராக பிரதிநிதித்துவப்படுத்துகிறது.

3. **புதிய மொழிகளுக்கு அளவிடுவது கடினம்:**
   - புதிய மொழிகளுக்கு Word2Vec-ஐ அளவிடுவது கடினம்.

குறியீடு மூலம் புரிதல் :

**Python-ல் Word2Vec மாதிரியை பயிற்சி செய்தல்:**

```python
from gensim.models import Word2Vec

# உதாரண வாக்கியங்கள்
sentences = [
    ["I", "love", "machine", "learning"],
    ["AI", "is", "fascinating"],
    ["I", "study", "NLP"]
]

# Word2Vec மாதிரியை பயிற்சி செய்தல்
model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

# "king" என்ற வார்த்தையின் embedding-ஐ பெறுதல்
king_vector = model.wv['king']
print("ராஜா-ன் embedding:", king_vector)

# "king" என்ற வார்த்தைக்கு ஒத்த வார்த்தைகளை கண்டறிதல்
similar_words = model.wv.most_similar('king')
print("ராஜா-க்கு ஒத்த வார்த்தைகள்:", similar_words)
```

Gensim-ஐப் பயன்படுத்தி **Word2Vec** மாடல் ஒவ்வொரு வார்த்தைக்கும் ஒரு எம்பெடிங் (vector representation) உருவாக்குகிறது. மாடல் இந்த எம்பெடிங்களைக் கொண்டு வார்த்தைகளுக்கு இடையிலான தொடர்பை (semantic similarity) கண்டறிகிறது.

model.wv.most_similar('king') என்ற அழைப்பின் மூலம், **“king”** என்ற வார்த்தைக்கு ஆக்க பக்கத்தில் உள்ள தொடர்புடைய வார்த்தைகளை (similar words) கண்டறிகிறது.

```python
 [('ruler', 0.25290292501449585), ('queen', 0.1703130453824997), 
 ('are', 0.15026721358299255), 
 ('fascinating', 0.13887712359428406), 
 ('NLP', 0.10853718221187592), 
 ('love', 0.03476576507091522), 
 ('and', 0.01612497679889202), 
 ('I', 0.00450251717120409), 
 ('study', -0.005892974324524403), 
 ('is', -0.02770209312438965)]
```

('ruler', 0.2529): “ruler” என்பது **king**-க்கு மிக அண்மையான பொருள் கொண்ட வார்த்தை என மாடல் கருதுகிறது. இந்த similarity score **0.2529** என்பது **king** மற்றும் **ruler** வார்த்தைகளின் வெக்டர் இடையிலான cosine similarity அடிப்படையில் கணக்கிடப்பட்டது.

('queen', 0.1703): “queen” என்பது **king**-க்கான தொடர்புடைய மற்றொரு வார்த்தையாக இருக்கிறது. இது “ruler”-க்கு அடுத்தடுத்த பொருளுடையது, ஆனால் குறைவான ஒத்தபாடுடையது (**0.1703**).

('are', 0.1503): இது எம்பெடிங் டேட்டாவிலிருந்து, **are** என்ற வார்த்தை “king”-க்குப் பக்கத்தில் தோன்றியதால் ஒத்தவாறு தெரிகிறது.

('fascinating', 0.1389): இதுவும் **king**-க்கு தொடர்புடையதாக கண்டறியப்பட்டது, ஆனால் semantic தொடர்பு (பொருள் தொடர்பு) இல்லாமல், கற்றல் தரவின் அடிப்படையில் மட்டும் தோன்றுகிறது.

('NLP', 0.1085): **NLP** போன்ற வார்த்தை காரணமாக, மாதிரி மிகச்சிறிய data-வில் இருந்து இதுபோன்ற தவறான தொடர்புகளை வெளிப்படுத்துகிறது.

('love', 0.0347) மற்றும் பிற வார்த்தைகள்: இது மிகவும் குறைந்த ஒத்தபாடுடையது, எனவே **king**-க்கு இது பொருத்தமற்றது எனவும் கூறலாம்.

இங்கே பயிற்சி செய்த தரவுத்தொகுப்பு (sentences) மிகச் சிறியது, மற்றும் “king” வார்த்தையை சரியான “context”-இல் அதிகமில்லை. ஆகவே, பல வார்த்தைகள் அவற்றின் உண்மையான semantic தொடர்புகளைச் சரியாக பிரதிபலிக்க முடியவில்லை.

**தீர்வு**: பெரிய மற்றும் பலதரப்பட்ட dataset-ல் மாடலை train செய்ய வேண்டும். “king” போன்ற வார்த்தைகள் ஏற்ற semantic context-இல் (e.g., royalty, leadership) அடிக்கடி தோன்ற வேண்டும்.

Word2Vec என்பது உரை தரவை கணினிகள் புரிந்து கொள்ளும் வகையில் எண்களாக மாற்றும் ஒரு சக்திவாய்ந்த கருவி. இது NLP-ல் மிகவும் முக்கியமானது மற்றும் மெஷின் கற்றல் மாதிரிகளின் துல்லியத்தை மேம்படுத்துகிறது. Word2Vec-ன் இரண்டு முறைகள் (CBOW மற்றும் Skip-Gram) மூலம், வார்த்தைகளின் அர்த்தம் மற்றும் தொடர்புகளை பிரதிநிதித்துவப்படுத்த முடியும்.

<div style="page-break-after: always;"></div>

#### 10. சொல்லுக்குச் சொல் மொழிபெயர்ப்பு: Seq2Seq-ன் மாய உலகம்

வணக்கம் நண்பர்களே! இன்று நாம் செய்யறிவு (AI) உலகின் ஒரு மிகவும் சுவாரஸ்யமான தொழில்நுட்பத்தைப் பற்றி பார்க்கப் போகிறோம். அதன் பெயர் **Seq2Seq (Sequence to Sequence)**. இந்தப் பெயரைக் கேட்டாலேயே "சொல்லுக்குச் சொல்" என்று அர்த்தம் விளங்கும், இல்லையா? ஆம், இது ஒரு தொடர்ச்சியான வார்த்தைகளை (sequence) இன்னொரு தொடர்ச்சியான வார்த்தைகளாக மாற்றும் ஒரு முறை. இதை "மொழிபெயர்ப்பு" என்று எளிதாகச் சொல்லலாம், ஆனால் இது வெறும் மொழிபெயர்ப்பு மட்டுமல்ல; இது ஒரு மாயம் போன்றது!

**உதாரணமாக,** நம்ம தமிழில் "நான் இன்று சினிமாவுக்குப் போகிறேன்" என்று சொன்னால், Seq2Seq அதை ஆங்கிலத்தில் "I am going to the cinema today" என்று மொழிபெயர்க்கும். இது எப்படி நடக்கிறது? இந்த மாயத்தின் பின்னால் என்ன இருக்கிறது? வாங்க, இன்று இந்த Seq2Seq-ன் உலகில் ஒரு சுவாரஸ்யமான பயணத்தைத் தொடங்குவோம்!

---

##### Seq2Seq-ன் உள்ளே என்ன இருக்கிறது?

Seq2Seq மாடல் இரண்டு முக்கியமான பகுதிகளைக் கொண்டது:
1. **என்கோடர் (Encoder)**
2. **டீகோடர் (Decoder)**

இந்த இரண்டும் சேர்ந்துதான் மொழிபெயர்ப்பு மாயத்தை நிகழ்த்துகின்றன. இப்போது இவை ஒவ்வொன்றையும் விரிவாகப் பார்ப்போம்.

---

###### 1. என்கோடர் (Encoder): உள்ளீட்டைப் புரிந்துகொள்வது

என்கோடரின் வேலை என்னவென்றால், உள்ளீட்டு வாக்கியத்தை (input sentence) எடுத்து, அதை ஒரு சிறிய "குறிப்பு" (hidden state) ஆக மாற்றுவது. இந்த hidden state-ல் தான் வாக்கியத்தின் முழு அர்த்தமும் அடங்கியிருக்கும். இது ஒரு வகையான "சுருக்கம்" (summary) போன்றது.

**உதாரணமாக,** "நான் இன்று சினிமாவுக்குப் போகிறேன்" என்ற வாக்கியத்தை என்கோடர் எடுத்துக்கொள்கிறது. இந்த வாக்கியத்தை வார்த்தை வார்த்தையாகப் பிரித்து, ஒவ்வொரு வார்த்தைக்கும் ஒரு எண்ணைக் கொடுக்கும். இதை "எம்பெடிங்" (Embedding) என்று அழைக்கிறோம்.

- நான் → 1  
- இன்று → 2  
- சினிமாவுக்கு → 3  
- போகிறேன் → 4  

இந்த எண்களை **RNN (Recurrent Neural Network)** என்ற ஒரு வகை நியூரல் நெட்வொர்க் வழியாக அனுப்பும். RNN ஒவ்வொரு வார்த்தையையும் படிக்கும்போது, அதன் அர்த்தத்தை ஒரு "hidden state" என்ற குறிப்பில் சேமிக்கும். கடைசியில், "போகிறேன்" (4) என்ற வார்த்தையைப் படித்து முடிக்கும் போது, என்கோடர் ஒரு "final hidden state" உருவாக்கும். இதில் வாக்கியத்தின் முழு அர்த்தமும் சுருக்கமாக இருக்கும்.

---

###### 2. டீகோடர் (Decoder): வெளியீட்டை உருவாக்குவது

டீகோடரின் வேலை என்னவென்றால், என்கோடர் கொடுத்த hidden state-ஐப் பயன்படுத்தி, வெளியீட்டு வாக்கியத்தை (output sentence) உருவாக்குவது. இதுவும் ஒரு RNN-ஐப் பயன்படுத்தி செயல்படும்.

டீகோடர் முதலில் ஒரு சிறப்பு சொல்லான **"start"**-ஐ உருவாக்கும். இது மொழிபெயர்ப்பைத் தொடங்குவதற்கான சமிக்ஞை. பின்னர், இந்த "start" சொல்லையும், என்கோடர் கொடுத்த hidden state-ஐயும் பயன்படுத்தி, அடுத்த வார்த்தையைக் கணிக்கும்.

**உதாரணமாக,** முதலில் "I" என்ற வார்த்தையைக் கணிக்கலாம். பின்னர், "I" மற்றும் hidden state-ஐப் பயன்படுத்தி, அடுத்த வார்த்தையான "am"ஐக் கணிக்கும். இப்படியே ஒவ்வொரு வார்த்தையாகக் கணித்து, "I am going to the cinema today" என்ற முழு வாக்கியத்தையும் உருவாக்கும். கடைசியில், ஒரு சிறப்பு சொல்லான **"end"**-ஐக் கணிக்கும் போது, மொழிபெயர்ப்பு முடிந்துவிடும்.

---

##### Seq2Seq-ன் குறைபாடுகள்:

Seq2Seq மாடல் மிகவும் பயனுள்ளதாக இருந்தாலும், அதற்கு சில குறைபாடுகள் உள்ளன. அவற்றைப் பார்ப்போம்.

1. **நீண்ட வாக்கியங்களைக் கையாள்வது கடினம்:**  
   என்கோடர் ஒரு வாக்கியத்தின் முழு அர்த்தத்தையும் ஒரே ஒரு hidden state-ல் அடக்க வேண்டும். இது நீண்ட வாக்கியங்களுக்கு மிகவும் கடினம். உதாரணமாக, "நான் இன்று சினிமா பார்க்க போகிறேன், ஆனால் மழை பெய்தால், நான் வீட்டிலேயே இருப்பேன்" என்ற வாக்கியத்தை எடுத்துக்கொள்வோம். இதில் பல தகவல்கள் உள்ளன:
   - "நான்" யார்?  
   - "இன்று" எந்த நாள்?  
   - எந்த சினிமா?  
   - மழை பெய்யுமா?  
   இவை அனைத்தையும் ஒரே hidden state-ல் அடக்குவது கடினம்.

2. **RNN-ன் வரம்புகள்:**  
   RNN ஒவ்வொரு வார்த்தையையும் ஒன்றன் பின் ஒன்றாகச் செயலாக்கும். இது நீண்ட வாக்கியங்களுக்கு நேரம் எடுக்கும். மேலும், RNN "நீண்ட-கால நினைவகம்" (long-term memory) கொண்டிருக்காது. அதாவது, முந்தைய வார்த்தைகளின் தகவல்களை முழுமையாக நினைவில் வைத்திருக்க முடியாது.

---

###### இந்தக் குறைபாடுகளுக்கு தீர்வு என்ன?

இந்தக் குறைபாடுகளைத் தீர்க்க, **டிரான்ஸ்பார்மர் (Transformer)** மாடல் உருவாக்கப்பட்டது. இது **Attention Mechanism** என்ற ஒரு சிறப்பு தொழில்நுட்பத்தைப் பயன்படுத்துகிறது. Attention Mechanism-ன் மூலம், டீகோடர் ஒவ்வொரு வார்த்தையையும் மொழிபெயர்க்கும்போது, உள்ளீட்டு வாக்கியத்தின் எல்லா வார்த்தைகளையும் "கவனமாக" பார்க்கும். இதனால், மொழிபெயர்ப்பு மிகவும் துல்லியமாக இருக்கும்.

**உதாரணமாக,** "நான் இன்று சினிமா பார்க்க போகிறேன், ஆனால் மழை பெய்தால், நான் வீட்டிலேயே இருப்பேன்" என்ற வாக்கியத்தை மொழிபெயர்க்கும்போது, Attention Mechanism "மழை பெய்தால்" என்ற பகுதியைக் கவனத்தில் கொண்டு, அதற்கான சரியான மொழிபெயர்ப்பைத் தரும்.

<div style="page-break-after: always;"></div>

#### 11. என்கோடர் & டிகோடர்: இயல் மொழி தெளிதலின் இரு தூண்கள்

கணினிகள் நம்மைப் போல தமிழ் பேசவோ, படிக்கவோ, புரிந்துகொள்ளவோ முடியாது. ஆனால்,  என்கோடர் மற்றும் டிகோடர் என்ற இரண்டு  சக்திவாய்ந்த கருவிகள் மூலம், தமிழ் மொழியை கணினிக்குப் புரியும்  எண்களாக மாற்றி, மீண்டும் தமிழிலேயே  பதில்களை உருவாக்க முடியும்.  என்கோடர் தமிழ் வார்த்தைகளை எண்களாக மாற்றும்; டிகோடர் அந்த எண்களை மீண்டும் தமிழ் வார்த்தைகளாக மாற்றும். இந்த தொழில்நுட்பம், இயந்திர மொழிபெயர்ப்பு,  உரை சுருக்கம்,  கேள்வி பதில் போன்ற பல  பணிகளுக்கு  உதவுகிறது.   என்கோடர் மற்றும் டிகோடர் எப்படி வேலை செய்கிறது என்பதை இந்த பதிவில் விரிவாகப் பார்க்கலாம்.

###### என்கோடர் (Encoder)

**1. டோக்கனைசேஷன் (Tokenization): வார்த்தைகளை சிறு பகுதிகளாகப் பிரித்தல்**

சங்கத்தமிழ் பாடல் வரிகளை கம்ப்யூட்டருக்குப் புரியவைக்க, முதலில் அவற்றை சிறிய பகுதிகளாகப் பிரிக்க வேண்டும். இந்த சிறிய பகுதிகள் டோக்கன்கள் (Tokens) என்று அழைக்கப்படுகின்றன. உதாரணமாக, **"அகர முதல எழுத்தெல்லாம்"** என்ற வரியை எடுத்துக் கொள்வோம். டோக்கனைசேஷன் முறையில் இதை:

["அ", "க", "ர", " ", "மு", "த", "ல", " ", "எ", "ழு", "த்", "தெ", "ல்", "லா", "ம்"]

என்று பிரிக்கலாம். இங்கு இடைவெளிகளும் (" ") டோக்கன்களாகக் கருதப்படுகின்றன.

**2. சொல்லகராதி (Vocabulary) உருவாக்குதல்: ஒவ்வொரு டோக்கனுக்கும் தனித்துவமான எண்**

டோக்கனைசேஷன் செய்த பிறகு, ஒவ்வொரு டோக்கனுக்கும் ஒரு தனித்துவமான எண்ணை ஒதுக்க வேண்டும். இது ஒரு சொல்லகராதியை (Vocabulary) உருவாக்குவதற்கு உதவுகிறது.

உதாரணமாக:

- "அ" → 31
- "க" → 43
- "ர" → 59
- " " → 2
- "மு" → 57
- "த" → 69
- "ல" → 52
- "எ" → 61
- "ழு" → 37
- "த்" → 63
- "தெ" → 77
- "ல்" → 71
- "லா" → 66
- "ம்" → 88

இந்த சொல்லகராதி, ஒவ்வொரு டோக்கனையும் கம்ப்யூட்டருக்குப் புரியும் எண்ணாக மாற்ற உதவுகிறது.

**3. எம்பெடிங் (Embedding): எண்களை வெக்டர்களாக மாற்றுதல்**

ஒவ்வொரு டோக்கனுக்கும் ஒதுக்கப்பட்ட எண்ணை, எம்பெடிங் (Embedding) செயல்முறை மூலம் வெக்டர்களாக மாற்றுகிறோம். வெக்டர்கள் என்பது பல பரிமாணங்களைக் கொண்ட எண்களின் பட்டியல்.

"அகர முதல" என்ற டோக்கன்களை எண்களாக மாற்றிய பிறகு, [31, 43, 59, 2, 57, 69, 52] என்று கிடைக்கும். ஒவ்வொரு எண்ணையும் எம்பெடிங் செயல்முறை மூலம் வெக்டர்களாக மாற்றுகிறோம்.

- 31 → [0.1, -0.5, 0.8, ...]
- 43 → [0.2, 0.3, -0.1, ...]
- 59 → [-0.4, 0.6, 0.2, ...]
- 2 → [0.9, -0.2, 0.7, ...]
- 57 → [-0.3, 0.1, 0.5, ...]
- 69 → [0.7, 0.4, -0.6, ...]
- 52 → [-0.8, 0.9, 0.3, ...]

இந்த எம்பெடிங் வெக்டர்கள், ஒவ்வொரு டோக்கனின் அர்த்தத்தையும், தொடர்பையும் கம்ப்யூட்டருக்குப் புரிய வைக்க உதவுகின்றன.

**4. ஹிட்டன் ஸ்டேட்கள் (Hidden States): சூழல் தகவலை நினைவில் கொள்ளுதல்**

எம்பெடிங் செய்யப்பட்ட வெக்டர்களை, ரிக்கரண்ட் நியூரல் நெட்வொர்க் (RNN) போன்ற தொடர்முறை நரம்பியல் நெட்வொர்க்குகளைப் பயன்படுத்தி ஹிட்டன் ஸ்டேட்களாக மாற்றுகிறோம். 

RNN-ல் ஒவ்வொரு டோக்கனும் அனுப்பப்படும்போது, அது முந்தைய ஹிட்டன் ஸ்டேட்களை கணக்கில் கொண்டு ஒரு புதிய ஹிட்டன் ஸ்டேட் உருவாக்குகிறது. இந்த ஹிட்டன் ஸ்டேட்கள், வாக்கியத்தின் சூழலுக்கேற்ப விவரங்களைச் சேமிக்கின்றன.

உதாரணமாக:

- "அ" → Hidden State 1 (ஆரம்ப நிலை)
- "க" → Hidden State 2 (Hidden State 1 + "க")
- "ர" → Hidden State 3 (Hidden State 2 + "ர")
- " " → Hidden State 4 (Hidden State 3 + Space)
- "மு" → Hidden State 5 (Hidden State 4 + "மு")
- "த" → Hidden State 6 (Hidden State 5 + "த")
- "ல" → Hidden State 7 (Hidden State 6 + "ல")

ஒவ்வொரு ஹிட்டன் ஸ்டேட்டும் முந்தைய ஹிட்டன் ஸ்டேட்களின் தகவல்களை ஒருங்கிணைத்தே உருவாகிறது. எனவே, கடைசி ஹிட்டன் ஸ்டேட் (Hidden State 7) முழு வாக்கியத்தையும் பிரதிபலிக்கும்.

**5. கான்டெக்ஸ்ட் வெக்டர் (Context Vector): ஒட்டுமொத்த தகவலின் சுருக்கம்**

கான்டெக்ஸ்ட் வெக்டர் என்பது என்கோடரின் கடைசி ஹிட்டன் ஸ்டேட் ஆகும். இது, முழு வாக்கியத்தின் சாரத்தை சுருக்கமாக கொண்டிருக்கும்.

உதாரணமாக "அகர முதல" என்ற வாக்கியத்தின் கான்டெக்ஸ்ட் வெக்டர், Hidden State 7 ஆக இருக்கும். இது, முழு வாக்கியத்தின் அர்த்தத்தையும், சூழலையும் சுருக்கமாக கொண்டிருக்கும். இந்த கான்டெக்ஸ்ட் வெக்டர், டிகோடருக்கு முக்கியமான தகவலாகும். 

சரி, இப்போது டிகோடர் செயல்முறையை விரிவாகப் பார்ப்போம்.

###### டிகோடர் (Decoder) - எண்களை மீண்டும் சங்கத்தமிழ் பாடலாக மாற்றுதல்

டிகோடர் என்பது என்கோடரால் உருவாக்கப்பட்ட கான்டெக்ஸ்ட் வெக்டரைப் பயன்படுத்தி,  மீண்டும் சங்கத்தமிழ் பாடல் வரிகளை உருவாக்கும் செயல்முறையாகும். இதுவும் பல படிகளைக் கொண்டது.

**1. இனிஷியல் ஸ்டேட் (Initial State): தொடக்க நிலை**

டிகோடரின் தொடக்க நிலை, என்கோடரின் கடைசி ஹிட்டன் ஸ்டேட்டாக (கான்டெக்ஸ்ட் வெக்டர்) இருக்கும். இது டிகோடருக்கு, மொழிபெயர்ப்பு அல்லது பாடல் வரி உருவாக்கத்திற்கான ஆரம்ப தகவலை வழங்குகிறது.

உதாரணமாக, "அகர முதல" என்ற வாக்கியத்திற்கு, என்கோடரின் கடைசி ஹிட்டன் ஸ்டேட் (Hidden State 7) டிகோடரின் ஆரம்ப நிலையாக கருத்தில் கொள்ளும்.

**2. டோக்கன் ஜெனரேஷன் (Token Generation): வார்த்தைகளை உருவாக்குதல்**

டிகோடர், கான்டெக்ஸ்ட் வெக்டரைப் பயன்படுத்தி அடுத்தடுத்த டோக்கன்களை உருவாக்குகிறது. ஒவ்வொரு டோக்கனும், முந்தைய டோக்கன்கள் மற்றும் கான்டெக்ஸ்ட் வெக்டரின் அடிப்படையில் உருவாக்கப்படும்.

இந்த டோக்கன் ஜெனரேஷன் செயல்முறை, பெரும்பாலும் ஒரு நியூரல் நெட்வொர்க் (Neural Network) மூலம் நிகழ்த்தப்படுகிறது. இந்த நெட்வொர்க், கான்டெக்ஸ்ட் வெக்டர் மற்றும் முந்தைய டோக்கன்களை உள்ளீடாகப் பெற்று, அடுத்த டோக்கனின் நிகழ்தகவு விரவல் (Probability Distribution) வெளியீடாகக் கொடுக்கும். அடுத்த டோக்கன் என்னவாக இருக்க வாய்ப்பிருக்கிறது என்பதைக் கண்டறிந்து அதற்கேற்ப டோக்கன்களை உருவாக்கும்.

உதாரணமாக, டிகோடர் முதன்முதலில் "அ" எனத் தொடங்குவதற்கான நிகழ்தகவு அதிகமாக இருக்கலாம். எனவே முதலில் '31' என்ற எண் உருவாக்கப்பட்டு, அடுத்து வரும் நிகழ்தகவுகளை வைத்து, '43' என்ற எண் உருவாகும், அடுத்து '59', அடுத்து '2' என, எண்களின் வரிசை உருவாக்கிக் கொண்டே போகும்.

**3. அகராதியைப் பயன்படுத்தி மீண்டும் உரைக்கு மாற்றுதல்**

**டோக்கன் உருவாக்கம் எவ்வாறு நிகழ்கிறது?**

```python
itos = {2: ' ', 31: 'அ', 43: 'க', 59: 'ர', 57: 'மு', 69: 'த', 52: 'ல', 61: 'எ', 37: 'ழு', 63: 'த்', 77: 'ெ', 71: 'ல்', 66: 'ா'}
```

இப்போது, நமக்குக் கொடுக்கப்பட்ட எண்களின் பட்டியலை எடுத்துக்கொள்வோம். பட்டியலில் உள்ள ஒவ்வொரு எண்ணையும் எடுத்துக்கொண்டு, அகராதியில் அதற்குரிய எழுத்தைப் பார்ப்போம். இந்த எழுத்துக்களை ஒன்றாக இணைத்தால், நமக்கு டெக்ஸ்ட் கிடைக்கும்.

**உதாரணம்:**

`[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியலை எடுத்துக்கொள்வோம்.

- முதல் எண் 31. அகராதியில் 31 என்ற எண்ணுக்கு "அ" என்ற எழுத்து ஒதுக்கப்பட்டுள்ளது.
- இரண்டாவது எண் 43. அகராதியில் 43 என்ற எண்ணுக்கு "க" என்ற எழுத்து ஒதுக்கப்பட்டிருக்கலாம்.
- இதேபோல், மற்ற எண்களுக்கும் அகராதியில் உள்ள எழுத்துக்களை எடுத்துக்கொள்வோம்.

இறுதியில், `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியல் "அகர முதல" என்ற டெக்ஸ்ட்டாக மாறும்.

**4. டிகோடரின் செயல்பாடு**

டிகோடர், ஆட்டோரிக்ரஸிவ் (Autoregressive) முறையில் செயல்படுகிறது. அதாவது, ஒவ்வொரு டோக்கனையும் உருவாக்கிய பிறகு, அந்த டோக்கனை அடுத்த டோக்கனை உருவாக்க உள்ளீடாகப் பயன்படுத்துகிறது.

- "அ" என்ற டோக்கனை உருவாக்கிய பிறகு, "க" என்ற டோக்கனை உருவாக்க "அ" என்ற டோக்கனைப் பயன்படுத்துகிறது.
- "க" என்ற டோக்கனை உருவாக்கிய பிறகு, "ர" என்ற டோக்கனை உருவாக்க "அக" என்ற இரு டோக்கன்களையும் பயன்படுத்துகிறது.
- இந்த தொடர்ச்சியான செயல்முறை பாடல் வரி அல்லது வாக்கியம் முடியும் வரை நிகழும்.

**5. டிகோடரின் முடிவு**

டிகோடர், "EOS" (End of Sequence) என்ற சிறப்பு டோக்கனை உருவாக்கும் வரை டோக்கன்களை உருவாக்கிக் கொண்டே இருக்கும். "EOS" டோக்கன், பாடல் வரி முடிந்துவிட்டது என்பதைக் குறிக்கும்.

சுருக்கமாக டிகோடர், என்கோடரால் உருவாக்கப்பட்ட கான்டெக்ஸ்ட் வெக்டரைப் பயன்படுத்தி, சங்கத்தமிழ் பாடல் வரிகளை மீண்டும் உருவாக்குகிறது. இது, ஆட்டோரிக்ரஸிவ் முறையில் செயல்பட்டு, "EOS" டோக்கனை உருவாக்கும் வரை டோக்கன்களை உருவாக்கிக் கொண்டே இருக்கும். இந்த செயல்முறையின் மூலம், கம்ப்யூட்டர் சங்கத்தமிழ் பாடல்களைப் புரிந்துகொண்டு, அவற்றைப் பகுப்பாய்வு செய்யவும், மொழிபெயர்க்கவும், மற்ற பணிகளைச் செய்யவும் முடியும்.

என்கோடர் மற்றும் டிகோடர் இணைந்து செயல்படும் விதம், நாம் மொழியைப் புரிந்துகொண்டு பயன்படுத்தும் விதத்திற்கு ஒப்பானது. நாம் ஒரு வாக்கியத்தைப் படிக்கும்போது, அதன் அர்த்தத்தைப் புரிந்துகொண்டு, அதற்கு ஏற்றவாறு பதிலளிக்கிறோம். என்கோடர் மற்றும் டிகோடரும் இதேபோல் செயல்படுகின்றன. என்கோடர் வாக்கியத்தைப் புரிந்துகொண்டு அதை எண்களாக மாற்றுகிறது, டிகோடர் அந்த எண்களைப் பயன்படுத்தி பொருத்தமான பதிலை உருவாக்குகிறது.

இந்த தொழில்நுட்பம் இன்னும் வளர்ச்சியடைந்து வருகிறது. இதன் மூலம், எதிர்காலத்தில் கணினிகள் மனிதர்களைப் போலவே மொழியைப் புரிந்துகொண்டு பயன்படுத்தும் என்று நம்பலாம்.

<div style="page-break-after: always;"></div>

#### 12. Transformers

Natural Language Processing, NLP துறையில் **Transformers** என்பது ஒரு புரட்சிகர மாற்றத்தை ஏற்படுத்தியுள்ளது. இது 2017-ல் Google-ஆல் அறிமுகப்படுத்தப்பட்ட "Attention is All You Need" என்ற ஆராய்ச்சிக் கட்டுரையில் முன்மொழியப்பட்ட ஒரு மேம்பட்ட நரவலை (Neural Networks) கட்டமைப்பாகும். Transformers-ன் முக்கிய புதுமை என்னவென்றால், இது முன்பு பயன்படுத்தப்பட்ட RNN (Recurrent Neural Networks) மற்றும் LSTM (Long Short-Term Memory) போன்ற வரிசை-சார்ந்த மாதிரிகளை விட, **Self-Attention Mechanism**-ஐ அடிப்படையாகக் கொண்டது. இந்த மெக்கானிசம், உரையில் உள்ள சொற்களுக்கிடையேயான சார்புகளை மிகத் துல்லியமாக புரிந்துகொள்ள உதவுகிறது, மேலும் இது Parallel Processing-யை மேம்படுத்துவதன் மூலம் கணிப்புகளை வேகமாகவும் திறம்படவும் செய்கிறது.

Transformers-ன் அடிப்படையில் BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pre-trained Transformer), T5 (Text-To-Text Transfer Transformer) போன்ற மாதிரிகள் உருவாக்கப்பட்டு, NLP துறையில் பல முன்னேற்றங்களை ஏற்படுத்தியுள்ளன. இந்த மாதிரிகள் பல மொழி-சார்ந்த பணிகளில் (Language Tasks) சிறந்த செயல்திறனை வெளிப்படுத்துகின்றன, எடுத்துக்காட்டாக, மொழிபெயர்ப்பு (Translation), உரை சுருக்கம் (Text Summarization), வினா-விடை அமைப்புகள் (Question Answering), உணர்வு பகுப்பாய்வு (Sentiment Analysis) மற்றும் உரை உருவாக்கம் (Text Generation) போன்றவை. Transformers-ன் நெகிழ்வுத்தன்மை மற்றும் பல்துறைத்தன்மை காரணமாக, இது Computer Vision மற்றும் பிற AI துறைகளிலும் பயன்படுத்தப்படுகிறது.

இந்த கட்டுரையில், Transformers-ன் கட்டமைப்பு, அதன் பண்புகள், மற்றும் NLP-ல் அதன் பயன்பாடுகள் பற்றி விரிவாக பார்ப்போம். மேலும், இது எவ்வாறு NLP துறையில் புதிய தரநிலைகளை நிர்ணயித்து, AI-ன் எதிர்காலத்தை வடிவமைக்கிறது என்பதையும் ஆராய்வோம்.

##### Transformers-ன் கட்டமைப்பு

Transformers என்பது **Encoder-Decoder** கட்டமைப்பை கொண்ட ஒரு நரவலை ஆகும். இது **Attention Mechanism**-ஐ மையமாக கொண்டு உருவாக்கப்பட்டது. இப்போது, Transformers-ன் ஒவ்வொரு பகுதியையும் விரிவாக பார்ப்போம்.

**உள்ளீட்டு பிரதிநிதித்துவம் (Input Representation)**

Transformers மாதிரிகள் உரை தரவை (Text Data) செயல்படுத்துவதற்கு முன்பு, அதை ஒரு கணித வடிவத்தில் மாற்ற வேண்டும். இந்த செயல்முறையில், உரையில் உள்ள ஒவ்வொரு வார்த்தையும் ஒரு **Embedding** என்று அழைக்கப்படும் ஒரு எண் வெக்டராக (Vector) மாற்றப்படுகிறது. இந்த வெக்டர்கள் உரையின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்தும் வகையில் வடிவமைக்கப்படுகின்றன.

###### Embeddings

- ஒரு வார்த்தை *(w)* என்பது ஒரு embedding வெக்டர் 

  $$
  ( \mathbf{e}_w \in \mathbb{R}^d)
  $$
  ஆக மாற்றப்படுகிறது. இங்கு (d) என்பது embedding பரிமாணம் (Dimension). எடுத்துக்காட்டாக, ஒரு வார்த்தை "cat" என்பது ஒரு 512-பரிமாண வெக்டராக மாற்றப்படலாம்.

- Embeddings என்பது ஒரு வார்த்தையின் அர்த்தத்தை எண்களின் வடிவில் பிரதிநிதித்துவப்படுத்தும் ஒரு முறை. இது மாதிரிக்கு உரையை புரிந்துகொள்ள உதவுகிறது.

###### Positional Encoding

Transformers மாதிரிகள் உரையில் உள்ள வார்த்தைகளின் வரிசை (Sequence) பற்றிய தகவலை பாதுகாக்க வேண்டும். ஆனால், Transformers மாதிரிகள் ஒரே நேரத்தில் முழு உரையையும் செயல்படுத்துவதால், வார்த்தைகளின் நிலை (Position) பற்றிய தகவலை சேமிக்க ஒரு சிறப்பு முறை பயன்படுத்தப்படுகிறது. இதற்கு **Positional Encoding** என்று பெயர்.

- Positional Encoding 

  $$$$(\mathbf{P} \in \mathbb{R}^{n \times d})$$$$ 

  என்பது ஒரு மேட்ரிக்ஸ் (Matrix) ஆகும், இது உரையில் உள்ள ஒவ்வொரு வார்த்தையின் நிலையை (Position) பிரதிநிதித்துவப்படுத்துகிறது.

- இது சைன் (Sine) மற்றும் கொசைன் (Cosine) செயல்பாடுகளை பயன்படுத்தி கணக்கிடப்படுகிறது. இந்த செயல்பாடுகள் வார்த்தைகளின் நிலையை ஒரு தனித்துவமான வடிவில் குறிக்கின்றன.

Positional Encoding கணக்கிடுவதற்கான சூத்திரங்கள்:

$$
[\mathbf{P}_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)]
$$

----

$$
[\mathbf{P}_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)]
$$

இங்கு:

- (*pos*) என்பது வார்த்தையின் நிலை (Position). எடுத்துக்காட்டாக, "I love cats" என்ற வாக்கியத்தில், "I" என்பது position 1, "love" என்பது position 2, மற்றும் "cats" என்பது position 3.
- (*i*) என்பது embedding பரிமாணத்தின் குறியீடு (Index). எடுத்துக்காட்டாக, embedding பரிமாணம் 512 எனில்,(*i*) என்பது 0 முதல் 255 வரை இருக்கும்.
- (*d*) என்பது embedding பரிமாணம் (Dimension).

###### Embeddings + Positional Encoding:

Embeddings மற்றும் Positional Encoding ஆகியவை ஒன்றாக சேர்க்கப்படுகின்றன. இதன் மூலம், மாதிரிக்கு ஒவ்வொரு வார்த்தையின் அர்த்தம் மற்றும் அதன் நிலை இரண்டும் தெரியும்.

$$
[\mathbf{P}_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)]
$$


இங்கு:

- ( **E **) என்பது embeddings மேட்ரிக்ஸ்.
- ( **P** ) என்பது positional encoding மேட்ரிக்ஸ்.
- ( **X** ) என்பது இறுதி உள்ளீட்டு பிரதிநிதித்துவம்.

இந்த உள்ளீட்டு பிரதிநிதித்துவம் Transformers மாதிரிக்கு உரையை புரிந்துகொள்ள உதவுகிறது. இது மாதிரிக்கு உரையில் உள்ள வார்த்தைகளின் அர்த்தம் மற்றும் அவற்றின் வரிசை பற்றிய தகவலை ஒரே நேரத்தில் வழங்குகிறது.

**2. குறியாக்கி (Encoder)**

Encoder என்பது Transformers மாதிரியின் முதல் முக்கிய பகுதியாகும். இது உரை தரவை (Text Data) embeddings-ஆக மாற்றி, அதை பல layers (அடுக்குகள்) மூலம் செயலாக்குகிறது. ஒவ்வொரு Encoder layer-உம் இரண்டு முக்கிய பகுதிகளை கொண்டிருக்கிறது:

1. **Multi-Head Self-Attention**
2. **Feedforward Neural Network**

இந்த பகுதிகள் உரையில் உள்ள வார்த்தைகளுக்கிடையேயான உறவுகளை புரிந்துகொள்வதற்கும், அவற்றின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துவதற்கும் உதவுகின்றன.

**2.1 Multi-Head Self-Attention:**

Self-Attention என்பது Transformers மாதிரியின் மிக முக்கியமான கருத்தாகும். இது ஒரு வார்த்தையை அதே வாக்கியத்தில் உள்ள மற்ற வார்த்தைகளுடன் ஒப்பிட்டு, அதன் அர்த்தத்தை புரிந்து கொள்ள உதவுகிறது. எடுத்துக்காட்டாக, "The cat sat on the mat" என்ற வாக்கியத்தில், "cat" என்ற வார்த்தை "sat" மற்றும் "mat" போன்ற வார்த்தைகளுடன் எவ்வாறு தொடர்புடையது என்பதை Self-Attention மூலம் புரிந்துகொள்ள முடியும்.

**Self-Attention Mechanism:**

Self-Attention செயல்முறை பின்வரும் படிகளை கொண்டுள்ளது:

1. **Queries, Keys, and Values:**

   - ஒவ்வொரு வார்த்தையும் மூன்று வெக்டர்களை கொண்டிருக்கிறது:

     - **Query (Q)**: இது ஒரு வார்த்தை "என்னை பற்றி என்ன தெரியும்?" என்று கேட்கும் ஒரு கேள்வி போன்றது.

     - **Key (K)**: இது ஒரு வார்த்தை "நான் என்ன தகவலை கொண்டிருக்கிறேன்?" என்று கூறும் ஒரு பதில் போன்றது.

     - **Value (V)**: இது ஒரு வார்த்தை "நான் என்ன தகவலை வழங்க முடியும்?" என்று கூறும் ஒரு பதில் போன்றது.

     - இந்த வெக்டர்கள் embeddings-ஐ linear transformations (நேரியல் மாற்றங்கள்) மூலம் பெறப்படுகின்றன:
       $$
       [
       \mathbf{Q} = \mathbf{X} \mathbf{W}_Q, \quad \mathbf{K} = \mathbf{X} \mathbf{W}_K, \quad \mathbf{V} = \mathbf{X} \mathbf{W}_V
       ]
       $$


       இங்கு 

       $$
       ( \mathbf{W}_Q, \mathbf{W}_K, \mathbf{W}_V) 
       $$
       

       என்பது trainable weights (பயிற்சி மூலம் கற்றுக்கொள்ளப்படும் எடைகள்).

2. **Attention Scores:**

   - Query மற்றும் Key-ஐ பயன்படுத்தி, attention scores கணக்கிடப்படுகிறது. இது ஒரு வார்த்தை மற்ற வார்த்தைகளுடன் எவ்வளவு தொடர்புடையது என்பதை கணக்கிடுகிறது:
     $$
     [
     \text{Attention Scores} = \frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d_k}}
     ]
     $$

   - $( d_k )$ 

     என்பது Key-ன் பரிமாணம் (Dimension). 

     இந்த பிரிவு 

     $(\sqrt{d_k})$ attention scores-ஐ நிலைப்படுத்த (Stabilize) உதவுகிறது.

3. **Softmax:**

   - Attention scores-ஐ softmax செயல்பாடு மூலம் நிகழ்தகவுகளாக (Probabilities) மாற்றுகிறது. இது ஒரு வார்த்தை மற்ற வார்த்தைகளுடன் எவ்வளவு கவனம் செலுத்த வேண்டும் என்பதை தீர்மானிக்கிறது:
     $$
     [
     \text{Attention Weights} = \text{Softmax}\left(\frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d_k}}\right)
     ]
     $$

4. **Weighted Sum:**

   - Attention weights-ஐ Value-உடன் பெருக்கி, weighted sum கணக்கிடப்படுகிறது. இது ஒரு வார்த்தையின் இறுதி பிரதிநிதித்துவத்தை கொடுக்கிறது:
     $$
     [
     \text{Attention Output} = \text{Attention Weights} \cdot \mathbf{V}
     ]
     $$

**Multi-Head Attention:**

- Self-Attention-ஐ பல தலைகள் (Heads) மூலம் செயல்படுத்துகிறது. இது மாதிரியை பல கோணங்களில் (Perspectives) உரையை புரிந்து கொள்ள உதவுகிறது. ஒவ்வொரு head-உம் தனி $$(Q, K, V)$$ வெக்டர்களை கொண்டிருக்கிறது.
- ஒவ்வொரு head-உம் வெவ்வேறு விதமாக உரையை புரிந்துகொள்வதால், இது மாதிரியின் செயல்திறனை மேம்படுத்துகிறது.
- இறுதியில், அனைத்து heads-ன் வெளியீடுகளும் concatenate (இணைக்கப்படுகின்றன) செய்யப்பட்டு, linear transformation மூலம் ஒருங்கிணைக்கப்படுகிறது.

**2.2 Feedforward Neural Network:**

Self-Attention-ன் வெளியீட்டை மேலும் செயலாக்க, ஒரு Feedforward Neural Network (FFN) பயன்படுத்தப்படுகிறது. இது ஒரு எளிய நரம்பியல் வலைப்பின்னல் (Neural Network) ஆகும், இது Self-Attention-ன் வெளியீட்டை மேம்படுத்துகிறது. FFN பொதுவாக இரண்டு layers-ஐ கொண்டிருக்கிறது:

1. **முதல் Layer:** Linear transformation மற்றும் activation function (ReLU போன்றது).
2. **இரண்டாவது Layer:** Linear transformation.

FFN-ன் வெளியீடு Encoder layer-ன் இறுதி வெளியீடாகும்.

---

**Encoder-ன் பணி:**

Encoder-ன் முக்கிய பணி உரையில் உள்ள வார்த்தைகளுக்கிடையேயான உறவுகளை புரிந்துகொள்வது மற்றும் அவற்றின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துவது. இது பல Encoder layers-ஐ கொண்டிருக்கலாம், ஒவ்வொரு layer-உம் Self-Attention மற்றும் FFN-ஐ பயன்படுத்தி உரையை மேம்படுத்துகிறது.

**3. குறிவிலக்கி (Decoder)**

Decoder என்பது Transformers மாதிரியின் இரண்டாவது முக்கிய பகுதியாகும். இது Encoder-ன் embeddings-ஐ பயன்படுத்தி, வெளியீட்டை (Output) உருவாக்குகிறது. Decoder-ன் பணி என்னவென்றால், Encoder-ல் இருந்து பெறப்பட்ட தகவல்களை பயன்படுத்தி, இலக்கு மொழியில் (Target Language) உரையை உருவாக்குவது அல்லது மொழிபெயர்ப்பது. ஒவ்வொரு Decoder layer-உம் மூன்று முக்கிய பகுதிகளை கொண்டிருக்கிறது:

1. **Masked Multi-Head Self-Attention**
2. **Encoder-Decoder Attention**
3. **Feedforward Neural Network**

**3.1 Masked Multi-Head Self-Attention:**

Decoder-ல், Self-Attention-ஐ பயன்படுத்தும் போது, ஒரு முக்கியமான வித்தியாசம் உள்ளது. Decoder-ல், **future tokens** (எதிர்கால வார்த்தைகள்) கணக்கில் எடுத்துக்கொள்ளப்படுவதில்லை. இதற்கு **Masking** என்ற ஒரு முறை பயன்படுத்தப்படுகிறது.

- **Masking என்ன?**
  - Masking என்பது ஒரு வழி, இதில் Decoder-ல் ஒரு வார்த்தை அதன் பின்னால் வரும் வார்த்தைகளை பார்க்க முடியாது. எடுத்துக்காட்டாக, "I love cats" என்ற வாக்கியத்தை உருவாக்கும் போது, "love" என்ற வார்த்தை "cats" என்ற வார்த்தையை பார்க்க முடியாது. இது மாதிரியை தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்தி, எதிர்கால வார்த்தைகளை ஊகிக்க உதவுகிறது.
  - இந்த masking செயல்முறை Self-Attention-ல் பயன்படுத்தப்படுகிறது, இதனால் Decoder தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்தி, எதிர்கால வார்த்தைகளை கணிக்க முடியும்.

- **Masked Multi-Head Attention:**
  - Encoder-ல் உள்ளதைப் போல, Decoder-லும் Multi-Head Attention பயன்படுத்தப்படுகிறது. ஆனால், இங்கு masking செயல்முறை சேர்க்கப்படுகிறது.
  - இது Decoder-க்கு தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்தி, எதிர்கால வார்த்தைகளை ஊகிக்க உதவுகிறது.

**3.2 Encoder-Decoder Attention:**

Encoder-ன் embeddings-ஐ Decoder-ல் பயன்படுத்தி, வெளியீட்டை உருவாக்குகிறது. இது Encoder மற்றும் Decoder-க்கு இடையேயான தொடர்பை ஏற்படுத்துகிறது.

- **Encoder-Decoder Attention-ன் வேலை:**
  - இந்த பகுதியில், Decoder-ல் உள்ள Query (Q) Encoder-ல் இருந்து பெறப்படும் Key (K)) மற்றும் Value (V)-ஐ பயன்படுத்தி, attention scores கணக்கிடப்படுகிறது.
  - இது Decoder-க்கு Encoder-ல் இருந்து பெறப்பட்ட தகவல்களை பயன்படுத்தி, சரியான வெளியீட்டை உருவாக்க உதவுகிறது.
  - எடுத்துக்காட்டாக, மொழிபெயர்ப்பில், Encoder-ல் உள்ள உரை தகவல்களை Decoder பயன்படுத்தி, இலக்கு மொழியில் உரையை உருவாக்குகிறது.

- **Query, Key, மற்றும் Value:**
  - Query (Q) Decoder-ல் இருந்து பெறப்படுகிறது.
  - Key (K) மற்றும் Value (V) Encoder-ல் இருந்து பெறப்படுகிறது.
  - இந்த மூன்று வெக்டர்களும் attention mechanism-ஐ பயன்படுத்தி, Encoder மற்றும் Decoder-க்கு இடையேயான தொடர்பை ஏற்படுத்துகின்றன.

**3.3 Feedforward Neural Network:**

Encoder-ல் உள்ளதைப் போல, Decoder-லும் Feedforward Neural Network (FFN) பயன்படுத்தப்படுகிறது. இது Self-Attention மற்றும் Encoder-Decoder Attention-ன் வெளியீட்டை மேலும் செயலாக்குகிறது.

- **Feedforward Neural Network-ன் வேலை:**
  - FFN என்பது ஒரு எளிய நரம்பியல் வலைப்பின்னல் (Neural Network) ஆகும், இது இரண்டு layers-ஐ கொண்டிருக்கிறது:
    1. **முதல் Layer:** Linear transformation மற்றும் activation function (ReLU போன்றது).
    2. **இரண்டாவது Layer:** Linear transformation.
  - இது Decoder-ன் வெளியீட்டை மேம்படுத்துகிறது மற்றும் இறுதி வெளியீட்டை உருவாக்க உதவுகிறது.

**Decoder-ன் பணி:**

Decoder-ன் முக்கிய பணி Encoder-ல் இருந்து பெறப்பட்ட தகவல்களை பயன்படுத்தி, இலக்கு மொழியில் உரையை உருவாக்குவது. இது பல Decoder layers-ஐ கொண்டிருக்கலாம், ஒவ்வொரு layer-உம் Masked Self-Attention, Encoder-Decoder Attention, மற்றும் FFN-ஐ பயன்படுத்தி உரையை மேம்படுத்துகிறது. இறுதியில், Decoder-ன் வெளியீடு இலக்கு மொழியில் உரையாக மாற்றப்படுகிறது.

---

நாம் ஒரு உதாரணத்தை பயன்படுத்தி, **Encoder** மற்றும் **Decoder**-ன் செயல்பாட்டை விரிவாக காண்போம். உதாரணத்திற்கு நாம் ஒரு எளிய மொழிபெயர்ப்பு பணியை எடுத்துக்கொள்வோம். உள்ளீடு (Input) ஆங்கிலத்தில் "I love cats" என்று இருக்கும், மற்றும் வெளியீடு (Output) தமிழில் "நான் பூனைகளை விரும்புகிறேன்" என்று இருக்கும்.

**Encoder-ன் செயல்பாடு:**

**1. உள்ளீட்டு பிரதிநிதித்துவம் (Input Representation):**

- உள்ளீடு "I love cats" என்பது முதலில் embeddings-ஆக மாற்றப்படுகிறது. ஒவ்வொரு வார்த்தையும் ஒரு வெக்டராக (Vector) மாற்றப்படுகிறது.
  - "I" → $$( \mathbf{e}_1 )$$
  - "love" → $$( \mathbf{e}_2 )$$
  - "cats" → $$( \mathbf{e}_3 )$$
- பின்னர், இந்த embeddings-களுடன் **Positional Encoding** சேர்க்கப்படுகிறது. இது வார்த்தைகளின் நிலை (Position) பற்றிய தகவலை சேமிக்கிறது.
  - "I" (Position 1) → $$( \mathbf{e}_1 + \mathbf{P}_1 )$$
  - "love" (Position 2) → $$( \mathbf{e}_2 + \mathbf{P}_2 )$$
  - "cats" (Position 3) → $$( \mathbf{e}_3 + \mathbf{P}_3 )$$

**2. Multi-Head Self-Attention:**

- Encoder-ல், Self-Attention மூலம் ஒவ்வொரு வார்த்தையும் மற்ற வார்த்தைகளுடன் எவ்வாறு தொடர்புடையது என்பதை புரிந்துகொள்கிறது.
  - எடுத்துக்காட்டாக, "love" என்ற வார்த்தை "I" மற்றும் "cats" உடன் எவ்வாறு தொடர்புடையது என்பதை கணக்கிடுகிறது.
  - இதற்கு Query (Q), Key (K), மற்றும் Value (V) வெக்டர்கள் பயன்படுத்தப்படுகின்றன.
  - Attention scores கணக்கிடப்பட்டு, softmax மூலம் நிகழ்தகவுகளாக மாற்றப்படுகின்றன.
  - இறுதியில், weighted sum மூலம் ஒவ்வொரு வார்த்தையின் புதிய பிரதிநிதித்துவம் கணக்கிடப்படுகிறது.

**3. Feedforward Neural Network:**

- Self-Attention-ன் வெளியீடு Feedforward Neural Network (FFN)-ல் செயலாக்கப்படுகிறது. இது உரையின் அர்த்தத்தை மேலும் மேம்படுத்துகிறது.
- இறுதியில், Encoder-ன் வெளியீடு ஒரு தொகுப்பு embeddings-ஆகும், இது உரையின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துகிறது.

###### Decoder-ன் செயல்பாடு

**1. Masked Multi-Head Self-Attention:**

- Decoder-ல், முதலில் "நான்" என்ற வார்த்தை மட்டுமே உள்ளது. இது Self-Attention-ஐ பயன்படுத்தி, தற்போதைய வார்த்தையை மட்டுமே பார்க்கிறது (ஏனெனில் எதிர்கால வார்த்தைகள் இன்னும் உருவாக்கப்படவில்லை).
  - "நான்" → $$( \mathbf{e}_1 + \mathbf{P}_1 )$$
  - இங்கு, masking செயல்முறை "பூனைகளை" மற்றும் "விரும்புகிறேன்" போன்ற எதிர்கால வார்த்தைகளை பார்க்காமல், தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்துகிறது.

**2. Encoder-Decoder Attention:**

- Decoder, Encoder-ல் இருந்து பெறப்பட்ட embeddings-ஐ பயன்படுத்தி, "நான்" என்ற வார்த்தைக்கு சரியான வெளியீட்டை உருவாக்குகிறது.
  - Query (Q) Decoder-ல் இருந்து பெறப்படுகிறது ("நான்").
  - Key (K) மற்றும் Value (V) Encoder-ல் இருந்து பெறப்படுகின்றன ("I", "love", "cats").
  - Attention scores கணக்கிடப்பட்டு, Encoder-ன் embeddings-ஐ பயன்படுத்தி, "நான்" என்ற வார்த்தைக்கு சரியான வெளியீடு உருவாக்கப்படுகிறது.

**3. Feedforward Neural Network:**

- Encoder-Decoder Attention-ன் வெளியீடு Feedforward Neural Network (FFN)-ல் செயலாக்கப்படுகிறது. இது வெளியீட்டை மேலும் மேம்படுத்துகிறது.
- இறுதியில், Decoder-ன் வெளியீடு "நான்" என்ற வார்த்தையாக உருவாகிறது.

**முழு செயல்முறை:**

1. **Encoder:**
   - உள்ளீடு "I love cats" என்பது embeddings-ஆக மாற்றப்பட்டு, Self-Attention மற்றும் FFN மூலம் செயலாக்கப்படுகிறது.
   - Encoder-ன் வெளியீடு ஒரு தொகுப்பு embeddings-ஆகும், இது உரையின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துகிறது.

2. **Decoder:**
   - Decoder முதலில் "நான்" என்ற வார்த்தையை உருவாக்குகிறது. இது Masked Self-Attention மற்றும் Encoder-Decoder Attention-ஐ பயன்படுத்தி, Encoder-ன் embeddings-ஐ பயன்படுத்துகிறது.
   - பின்னர், "பூனைகளை" மற்றும் "விரும்புகிறேன்" போன்ற வார்த்தைகளை ஒவ்வொன்றாக உருவாக்குகிறது.
   - ஒவ்வொரு வார்த்தையும் Encoder-ன் embeddings-ஐ பயன்படுத்தி, சரியான வெளியீட்டை உருவாக்குகிறது.

இந்த செயல்முறை மூலம், Transformers மாதிரி உரையை புரிந்துகொண்டு, மொழிபெயர்ப்பு போன்ற பணிகளை திறம்பட செயல்படுத்துகிறது.

**4. வெளியீட்டு இழை (Output Layer)**

Decoder-ன் வெளியீடு ஒரு linear transformation மற்றும் softmax செயல்பாடு மூலம் வெளியீட்டு நிகழ்தகவுகளாக (Output Probabilities) மாற்றப்படுகிறது. இந்த செயல்முறை மாதிரியை இலக்கு மொழியில் உரையை உருவாக்க உதவுகிறது.

**வெளியீட்டு அடுக்கு செயல்முறை:**

1. **Linear Transformation:**

   - Decoder-ன் வெளியீடு $$(h)$$ (ஒரு வெக்டர்) ஒரு linear transformation-ஐ மூலம் செயலாக்கப்படுகிறது. இது ஒரு 

     weight matrix $$( \mathbf{W}_o )$$ 

     மற்றும் bias vector $$( \mathbf{b}_o )$$ பயன்படுத்தி கணக்கிடப்படுகிறது:
     $$
     [
     \mathbf{z} = \mathbf{W}_o \mathbf{h} + \mathbf{b}_o
     ]
     $$
     இங்கு (z) என்பது linear transformation-ன் வெளியீடு.

2. **Softmax செயல்பாடு:**

   - Linear transformation-ன் வெளியீடு (z) softmax செயல்பாடு மூலம் நிகழ்தகவுகளாக (Probabilities) மாற்றப்படுகிறது. இது ஒவ்வொரு வார்த்தையின் நிகழ்தகவை கணக்கிடுகிறது:
     $$
     [
     \text{Output} = \text{Softmax}(\mathbf{z})
     ]
     $$
     Softmax செயல்பாடு ஒவ்வொரு வார்த்தையின் நிகழ்தகவை 0 மற்றும் 1-க்கு இடையில் இருக்கும் வகையில் மாற்றுகிறது, மேலும் அனைத்து நிகழ்தகவுகளின் கூட்டுத்தொகை 1 ஆக இருக்கும்.

3. **வெளியீட்டு நிகழ்தகவுகள்:**

   - Softmax-ன் வெளியீடு ஒரு நிகழ்தகவு விநியோகம் (Probability Distribution) ஆகும். இது ஒவ்வொரு வார்த்தையின் நிகழ்தகவை குறிக்கிறது. எடுத்துக்காட்டாக, "நான்", "பூனைகளை", "விரும்புகிறேன்" போன்ற வார்த்தைகளின் நிகழ்தகவுகள் கணக்கிடப்படுகின்றன.
   - மாதிரி இந்த நிகழ்தகவுகளை பயன்படுத்தி, அடுத்த வார்த்தையை தேர்ந்தெடுக்கிறது.

**5. Layer Normalization மற்றும் Residual Connections:**

Transformers-ல், **Layer Normalization** மற்றும் **Residual Connections** பயன்படுத்தப்படுகின்றன. இவை மாதிரியின் பயிற்சியை மேம்படுத்துகின்றன மற்றும் மாதிரியின் செயல்திறனை அதிகரிக்கின்றன.

**Layer Normalization:**

Layer Normalization என்பது ஒரு நெறிமுறை (Normalization Technique) ஆகும், இது மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டையும் நெறிப்படுத்த (Normalize) உதவுகிறது. இது மாதிரியின் பயிற்சியை வேகமாகவும், நிலையாகவும் மேம்படுத்துகிறது.

- **Layer Normalization செயல்முறை:**

  - ஒரு layer-ன் வெளியீடு $$( x )$$ என்பது mean $$( \mu )$$ மற்றும் variance $$( \sigma^2 )$$ பயன்படுத்தி நெறிப்படுத்தப்படுகிறது:
    $$
    [
    \text{LayerNorm}(x) = \gamma \cdot \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta
    ]
    $$
    இங்கு:

    - $$( \mu )$$ என்பது mean.
    - $$( \sigma^2 )$$ என்பது variance .
    - $$( \gamma )$$ மற்றும் $$( \beta )$$ என்பது trainable parameters (பயிற்சி மூலம் கற்றுக்கொள்ளப்படும் எடைகள்).
    - $$( \epsilon )$$ என்பது ஒரு சிறிய மதிப்பு, இது பூஜ்ஜியத்தால் வகுத்தலை தவிர்க்க உதவுகிறது.

- **பயன்:**

  - Layer Normalization மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டையும் நிலையான (Stable) மற்றும் சீரான (Consistent) வடிவில் வைத்திருக்க உதவுகிறது. இது மாதிரியின் பயிற்சியை வேகமாகவும், நிலையாகவும் மேம்படுத்துகிறது.

**Residual Connections:**

Residual Connections என்பது ஒரு முக்கியமான கருத்தாகும், இது மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டை அதன் உள்ளீட்டுடன் நேரடியாக சேர்க்கிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்துகிறது மற்றும் vanishing gradients (சிறிய சாய்வுகள்) பிரச்சினையை தவிர்க்க உதவுகிறது.

- **Residual Connections செயல்முறை:**

  - ஒரு layer-ன் வெளியீடு $$( x )$$ என்பது அதன் உள்ளீட்டுடன் நேரடியாக சேர்க்கப்படுகிறது:
    $$
    [
    \text{Output} = x + \text{Sublayer}(x)
    ]
    $$
    இங்கு $$( \text{Sublayer} )$$ என்பது Self-Attention அல்லது Feedforward Network.

- **பயன்:**

  - Residual Connections மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டையும் அதன் உள்ளீட்டுடன் சேர்க்கிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்துகிறது மற்றும் vanishing gradients பிரச்சினையை தவிர்க்க உதவுகிறது.

**6. Training the Transformer:**

Transformers-ன் பயிற்சி **Cross-Entropy Loss** மூலம் செய்யப்படுகிறது. இது predicted output மற்றும் actual output-க்கு இடையேயான வித்தியாசத்தை கணக்கிடுகிறது.

**Cross-Entropy Loss:**

Cross-Entropy Loss என்பது ஒரு loss function ஆகும், இது மாதிரியின் predicted output மற்றும் actual output-க்கு இடையேயான வித்தியாசத்தை கணக்கிடுகிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்த உதவுகிறது.

- **Cross-Entropy Loss செயல்முறை:**

  - Actual output $$( y_i )$$ மற்றும் predicted output $$( \hat{y}_i)$$ பயன்படுத்தி, loss கணக்கிடப்படுகிறது:
    $$
    [
    \text{Loss} = -\sum_{i=1}^n y_i \log(\hat{y}_i)
    ]
    $$
    இங்கு:

    - $$( y_i )$$ என்பது actual output (உண்மையான வெளியீடு).
    - $$( \hat{y}_i )$$ என்பது predicted output (மாதிரியின் ஊகம்).

- **பயன்:**

  - Cross-Entropy Loss மாதிரியின் predicted output மற்றும் actual output-க்கு இடையேயான வித்தியாசத்தை கணக்கிடுகிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்த உதவுகிறது.

Transformers மாதிரி உரையை புரிந்துகொண்டு, மொழிபெயர்ப்பு போன்ற பணிகளை திறம்பட செயல்படுத்துகிறது. இது Encoder, Decoder, Layer Normalization, Residual Connections, மற்றும் Cross-Entropy Loss போன்ற கருத்துகளை பயன்படுத்தி, உரையை புரிந்துகொண்டு, வெளியீட்டை உருவாக்குகிறது. இந்த கருத்துகள் Transformers மாதிரியின் செயல்திறனை மேம்படுத்துகின்றன மற்றும் அதை பல NLP பணிகளில் பயன்படுத்த உதவுகின்றன.

<div style="page-break-after: always;"></div>

##### டிரான்ஸ்ஃபார்மர் எப்படி வேலை செய்கிறது?

இன்றைய டிஜிட்டல் யுகத்தில், கணினிகள் மனித மொழியைப் புரிந்து செயல்படுவது மிகவும் முக்கியமானதாகிவிட்டது. குறிப்பாக, குரல் கட்டளைகள், உரை பகுப்பாய்வு (Text Analysis) மற்றும் இயல் மொழி தெளிதல் (Natural Language Processing - NLP) போன்ற துறைகளில் மனித மொழியை கணினி மொழியாக மாற்றுவது ஒரு முக்கிய படியாகும். இந்த மாற்றத்தில், வார்த்தைகளை எண்களாக மாற்றுவது ஒரு முக்கியமான செயல்முறை. 

முதலில், நாம் பயன்படுத்தும் வார்த்தைகளின் தொகுப்பை வரையறுக்க வேண்டும். இதை சொற்களஞ்சியம் (Vocabulary) என்று அழைக்கிறோம். எடுத்துக்காட்டாக, தமிழில் **"நான் தண்ணீர் குடிக்கலாமா"** என்ற வாக்கியத்தை எடுத்துக்கொள்வோம். இந்த வார்த்தைகளை ஒரு சொற்களஞ்சியமாக வரையறுப்போம். இப்போது ஒவ்வொரு வார்த்தைக்கும் ஒரு தனிப்பட்ட எண்ணை ஒதுக்கலாம்.
- தண்ணீர் = 1  
- குடிக்கலாமா = 2  
- நான் = 3  

இப்போது, **"நான் தண்ணீர் குடிக்கலாமா"** என்ற வாக்கியத்தை எண்களாக மாற்றினால், அது **[3, 1, 2]** என்ற எண் வரிசையாக மாறும். இது ஒரு எளிய முறை. ஆனால், கணினிகள் இதை மேலும் திறம்பட செயல்படுத்த, ஒன்-ஹாட் என்கோடிங் என்ற முறை பயன்படுத்தப்படுகிறது. ஒன்-ஹாட் என்கோடிங் என்பது ஒவ்வொரு வார்த்தையையும் ஒரு வெக்டர் (Vector) ஆக மாற்றும் முறை. இந்த வெக்டரின் நீளம் சொற்களஞ்சியத்தின் அளவுக்கு சமமாக இருக்கும். இந்த வெக்டரில், ஒரே ஒரு உறுப்பு மட்டும் **1** ஆகவும், மற்ற எல்லா உறுப்புகளும் **0** ஆகவும் இருக்கும்.  

**இது எப்படி செயல்படுகிறது?**  

மேலே உள்ள சொற்களஞ்சியத்தை எடுத்துக்கொள்வோம்:  
- தண்ணீர் = [1, 0, 0]  
- குடிக்கலாமா = [0, 1, 0]  
- நான் = [0, 0, 1]  

இப்போது, **"நான் தண்ணீர் குடிக்கலாமா"** என்ற வாக்கியத்தை ஒன்-ஹாட் என்கோடிங் மூலம் மாற்றினால், அது பின்வரும் மேட்ரிக்ஸாக (Matrix) மாறும்:  
```
[ [0, 0, 1],  
  [1, 0, 0],  
  [0, 1, 0] ]  
```
இங்கே, ஒவ்வொரு வரியும் ஒரு வார்த்தையைக் குறிக்கிறது. இந்த வார்த்தை எண் வடிவங்களைப் பயன்படுத்தி, கணினிகள் பல்வேறு கணித செயல்பாடுகளை செய்ய முடியும். அவற்றில் ஒரு முக்கியமான செயல்பாடு **டாட் ப்ராடக்ட் (Dot Product)** ஆகும். ஒன்-ஹாட் என்கோடிங்கில் டாட் ப்ராடக்ட் எப்படி பயன்படுத்தப்படுகிறது என்பதைப் பார்ப்போம்.  

டாட் ப்ராடக்ட் என்பது இரண்டு வெக்டர்களை (Vectors) எடுத்துக்கொண்டு, அவற்றின் ஒத்த உறுப்புகளைப் பெருக்கி, பின்னர் அந்த பெருக்கல்களின் கூட்டுத்தொகையைக் கண்டுபிடிக்கும் ஒரு கணித செயல்பாடு. இதை **இன்னர் ப்ராடக்ட் (Inner Product)** அல்லது **ஸ்கேலார் ப்ராடக்ட் (Scalar Product)** என்றும் அழைப்பார்கள்.  

**டாட் ப்ராடக்ட் கணக்கிடும் முறை:**  

இரண்டு வெக்டர்கள் **A** மற்றும் **B** கொடுக்கப்பட்டால், அவற்றின் டாட் ப்ராடக்ட் பின்வருமாறு கணக்கிடப்படும்:  
```
A = [a1, a2, a3]  
B = [b1, b2, b3]  
A.B = (a1 * b1) + (a2 * b2) + (a3 * b3)  
```

ஒன்-ஹாட் என்கோடிங்கில், ஒவ்வொரு வார்த்தையும் ஒரு வெக்டராக குறிப்பிடப்படுகிறது. இந்த வெக்டர்களுக்கு இடையேயான தொடர்பைப் புரிந்துகொள்ள, டாட் ப்ராடக்ட் பயன்படுத்தப்படுகிறது.  

ஒரு வெக்டரை அதே வெக்டருடன் டாட் ப்ராடக்ட் செய்தால், முடிவு **1** கிடைக்கும். இது அந்த வெக்டர் தனித்துவமானது என்பதைக் காட்டுகிறது.  

**உதாரணம்:**  
"பூனை" என்ற வார்த்தையின் ஒன்-ஹாட் வெக்டர் **[1, 0, 0]** என்று வைத்துக்கொள்வோம். இதை அதே  வெக்டருடன் டாட் ப்ராடக்ட் செய்தால்:  

```
[1, 0, 0] . [1, 0, 0] = (1 * 1) + (0 * 0) + (0 * 0) = 1  
```
இதன் மூலம், ஒரு குறிப்பிட்ட வார்த்தை ஒரு வாக்கியத்தில் அல்லது தொகுப்பில் இருக்கிறதா என்பதை கண்டறியலாம்.  

ஒரு வெக்டரை வேறு ஒரு வெக்டருடன் டாட் ப்ராடக்ட் செய்தால், முடிவு **0** கிடைக்கும். இது அந்த இரண்டு வெக்டர்களும் வேறுபட்டவை என்பதைக் காட்டுகிறது.  

**உதாரணம்:**  
"பூனை" என்ற வார்த்தையின் ஒன்-ஹாட் வெக்டர் **[1, 0, 0]** என்றும், "நாய்" என்ற வார்த்தையின் ஒன்-ஹாட் வெக்டர் **[0, 1, 0]** என்றும் வைத்துக்கொள்வோம். 

இவ்விரண்டையும் டாட் ப்ராடக்ட் செய்தால்:  

```
[1, 0, 0] . [0, 1, 0] = (1 * 0) + (0 * 1) + (0 * 0) = 0  
```
இதன் மூலம், இரண்டு வார்த்தைகளும் வேறுபட்டவை என்பதை உறுதி செய்யலாம். ஒன்-ஹாட் என்கோடிங் முறையில், ஒத்த வார்த்தைகளுக்கு இடையேயான தொடர்பை நேரடியாக அளவிட முடியாது. ஏனெனில், ஒவ்வொரு வார்த்தையும் தனித்தனி வெக்டராக குறிப்பிடப்படுகிறது.  

**உதாரணம்:**  
"மகிழ்ச்சி", "சந்தோஷம்", "நகைச்சுவை" போன்ற வார்த்தைகள் ஒன்றுக்கொன்று தொடர்புடையவை. ஆனால், ஒன்-ஹாட் என்கோடிங்கில், இவை தனித்தனி வெக்டர்களாக குறிப்பிடப்படுவதால், இவற்றுக்கு இடையேயான தொடர்பை டாட் ப்ராடக்ட் மூலம் கண்டறிய முடியாது. ஒத்த வார்த்தைகளின் தொடர்பை அளவிட, வேர்ட் எம்பெடிங்ஸ் போன்ற மேம்பட்ட முறைகள் தேவைப்படுகின்றன.  **வேர்ட் எம்பெடிங்ஸ் (Word Embeddings)**, வார்த்தைகள் தொடர்ச்சியான வெக்டர் வெளியில் (Continuous Vector Space) குறிப்பிடப்படுகின்றன. இதன் மூலம், ஒத்த வார்த்தைகள் ஒன்றுக்கொன்று அருகில் இருக்கும்.  

**மேட்ரிக்ஸ் என்றால் என்ன?**  

மேட்ரிக்ஸ் என்பது எண்களை வரிசைகள் (Rows) மற்றும் நெடுவரிசைகளாக (Columns) அடுக்கி வைக்கும் ஒரு அமைப்பு. இதை ஒரு அட்டவணை போல கற்பனை செய்து கொள்ளலாம்.  

**உதாரணம்:**  
ஒரு கடையில் இருக்கும் பழங்களின் விலை பட்டியலை ஒரு மேட்ரிக்ஸாக குறிப்பிடலாம்:  

| பழம்      | விலை (கிலோ) |
| -------- | ----------- |
| ஆப்பிள்    | 200         |
| ஆரஞ்சு    | 100         |
| வாழைப்பழம் | 50          |

இதை மேட்ரிக்ஸ் வடிவில் எழுதினால்:  
```
A = [[200, 100, 50]]
```

**மேட்ரிக்ஸ் பெருக்கல் எப்படி செயல்படுகிறது?**  

இரண்டு மேட்ரிக்ஸ்களை பெருக்குவதற்கு, முதல் மேட்ரிக்ஸின் நெடுவரிசைகளின் எண்ணிக்கையும், இரண்டாவது மேட்ரிக்ஸின் வரிசைகளின் எண்ணிக்கையும் சமமாக இருக்க வேண்டும்.  

மேட்ரிக்ஸ் பெருக்கல் செய்யும்போது, முதல் மேட்ரிக்ஸின் ஒவ்வொரு வரிசையையும், இரண்டாவது மேட்ரிக்ஸின் ஒவ்வொரு நெடுவரிசையையும் எடுத்துக்கொண்டு, அவற்றின் ஒத்த உறுப்புகளை பெருக்கி, கூட்டுத்தொகையை கண்டுபிடிக்க வேண்டும்.  

**உதாரணம்: பழங்களின் விலை கணக்கீடு**  

மேலே குறிப்பிட்ட பழங்களின் விலை பட்டியல் மேட்ரிக்ஸை (**A**) மற்றும் நாம் வாங்க விரும்பும் பழங்களின் அளவை குறிப்பிடும் மற்றொரு மேட்ரிக்ஸை (**B**) பெருக்கினால், நாம் செலுத்த வேண்டிய மொத்த தொகையை கணக்கிடலாம்.  

**மேட்ரிக்ஸ் A:**  

```
A = [
  [200, 100, 50]  // ஆப்பிள், ஆரஞ்சு, வாழைப்பழம் விலை
]
```

**மேட்ரிக்ஸ் B:**  
```
B = [
  [2],  // 2 கிலோ ஆப்பிள்
  [3],  // 3 கிலோ ஆரஞ்சு
  [4]   // 4 கிலோ வாழைப்பழம்
]
```

**மேட்ரிக்ஸ் பெருக்கல்:**  
```
A . B = [
  [ (200 * 2) + (100 * 3) + (50 * 4) ]
]
= [
  [ 400 + 300 + 200 ]
]
= [
  [ 900 ]
]
```

எனவே, நாம் செலுத்த வேண்டிய மொத்த தொகை **900 ரூபாய்**.  

இயல் மொழி தெளிதல் (Natural Language Processing - NLP) என்பது கணினிகள் மனித மொழியைப் புரிந்துகொள்ளவும், செயல்படவும் உதவும் ஒரு துறையாகும். இந்தத் துறையில், **முதல் வரிசை தொடர் மாதிரி (First Order Sequence Model)** ஒரு முக்கியமான கருவியாகப் பயன்படுத்தப்படுகிறது. இந்த மாதிரி, வார்த்தைகளின் வரிசையை கணிக்க உதவுகிறது.  

**சொற்களஞ்சியம் (Vocabulary)**  

முதலில், நாம் பயன்படுத்தும் வார்த்தைகளின் தொகுப்பை வரையறுக்க வேண்டும். இதை **சொற்களஞ்சியம் (Vocabulary)** என்று அழைக்கிறோம்.  

**உதாரணம்:**  
நாம் மூன்று கட்டளைகளை மட்டும் கையாள விரும்புகிறோம் என்று வைத்துக்கொள்வோம்:  

1. "எனது கோப்புகளைத் திற." ("Open my files.")  
2. "எனது இசையை இயக்கு." ("Play my music.")  
3. "எனது புகைப்படங்களைக் காட்டு." ("Show my photos.")  

இந்த கட்டளைகளில் உள்ள வார்த்தைகளை வைத்து நமது சொற்களஞ்சியத்தை உருவாக்கலாம்:  

```
{எனது, கோப்புகள், திற, இசை, இயக்கு, புகைப்படங்கள், காட்டு}  
```

**Transition Model**

இந்த வார்த்தைகளின் வரிசையை கணிக்க, ஒரு **Transition Model** பயன்படுத்தலாம். இந்த மாதிரி, ஒவ்வொரு வார்த்தைக்கும் அடுத்ததாக வரக்கூடிய வார்த்தையின் நிகழ்தகவை (Probability) காட்டும்.  

**உதாரணம்:**  
"எனது" என்ற வார்த்தைக்கு பிறகு, "கோப்புகள்" வரும் நிகழ்தகவு **0.4** என்றும், "இசை" வரும் நிகழ்தகவு **0.3** என்றும், "புகைப்படங்கள்" வரும் நிகழ்தகவு **0.3** என்றும் வைத்துக்கொள்வோம்.  

இந்த மாற்றம் மாதிரி, ஒரு **மார்கோவ் சங்கிலி (Markov Chain)** என்று அழைக்கப்படுகிறது. ஏனெனில் இவை சங்கிலி போன்று இணைக்கப்பட்டிருக்கும்; அடுத்த வார்த்தையின் நிகழ்தகவு தற்போதைய வார்த்தையை மட்டுமே சார்ந்ததாக இருக்கும். இதை **முதல் வரிசை மார்கோவ் மாதிரி (First Order Markov Model)** என்றும் அழைக்கிறோம்.  

**மேட்ரிக்ஸ் வடிவில் குறிப்பிடுதல்**  

இந்த மார்கோவ் சங்கிலியை, ஒரு மேட்ரிக்ஸ் (Matrix) வடிவில் குறிப்பிடலாம். மேட்ரிக்ஸின் ஒவ்வொரு வரிசையும் (Row) மற்றும் நெடுவரிசையும் (Column) சொற்களஞ்சியத்தில் உள்ள ஒரு வார்த்தையை குறிக்கும். மேட்ரிக்ஸில் உள்ள ஒவ்வொரு உறுப்பும் (Element), அந்த வரிசையில் உள்ள வார்த்தைக்கு அடுத்ததாக நெடுவரிசையில் உள்ள வார்த்தை வரும் நிகழ்தகவை குறிக்கும்.  

**உதாரணம்:**  

இப்போது, இந்த வார்த்தைகளுக்கான மாற்றம் மாதிரியை (Transition Model) மேட்ரிக்ஸ் வடிவில் குறிப்பிடலாம். இந்த மேட்ரிக்ஸில், ஒவ்வொரு வரிசையும் ஒரு வார்த்தையைக் குறிக்கும், மற்றும் ஒவ்வொரு நெடுவரிசையும் அந்த வார்த்தைக்கு அடுத்ததாக வரக்கூடிய வார்த்தையின் நிகழ்தகவைக் குறிக்கும்.

**மேட்ரிக்ஸ் வடிவில் குறிப்பிடுதல்:**

|                | எனது | கோப்புகள் | திற  | இசை  | இயக்கு | புகைப்படங்கள் | காட்டு |
| -------------- | ---- | ------- | ---- | ---- | ----- | ---------- | ----- |
| **எனது**       | 0.0  | 0.4     | 0.0  | 0.3  | 0.0   | 0.3        | 0.0   |
| **கோப்புகள்**    | 0.0  | 0.0     | 1.0  | 0.0  | 0.0   | 0.0        | 0.0   |
| **திற**        | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 0.0   |
| **இசை**        | 0.0  | 0.0     | 0.0  | 0.0  | 1.0   | 0.0        | 0.0   |
| **இயக்கு**      | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 0.0   |
| **புகைப்படங்கள்** | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 1.0   |
| **காட்டு**      | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 0.0   |

**விளக்கம்:**

- "எனது" என்ற வார்த்தைக்கு பிறகு, "கோப்புகள்" வரும் நிகழ்தகவு **0.4**, "இசை" வரும் நிகழ்தகவு **0.3**, மற்றும் "புகைப்படங்கள்" வரும் நிகழ்தகவு **0.3**.
- "கோப்புகள்" என்ற வார்த்தைக்கு பிறகு, "திற" வரும் நிகழ்தகவு **1.0** (ஏனெனில் "கோப்புகளைத் திற" என்ற கட்டளையில் இது நிகழ்கிறது).
- "இசை" என்ற வார்த்தைக்கு பிறகு, "இயக்கு" வரும் நிகழ்தகவு **1.0** (ஏனெனில் "இசையை இயக்கு" என்ற கட்டளையில் இது நிகழ்கிறது).
- "புகைப்படங்கள்" என்ற வார்த்தைக்கு பிறகு, "காட்டு" வரும் நிகழ்தகவு **1.0** (ஏனெனில் "புகைப்படங்களைக் காட்டு" என்ற கட்டளையில் இது நிகழ்கிறது).

இந்த மேட்ரிக்ஸ், மார்கோவ் சங்கிலியின் மாற்றம் மாதிரியை குறிக்கிறது மற்றும் இது ஒரு முதல் வரிசை மார்கோவ் மாதிரி (First Order Markov Model) ஆகும். இந்த மாதிரியைப் பயன்படுத்தி, வார்த்தைகளின் வரிசையை கணிக்க முடியும்.

**இரண்டாம் வரிசை மார்கோவ் மாதிரி (Second Order Markov Model)**  

முந்தைய வார்த்தையை மட்டும் பார்த்து அடுத்த வார்த்தையை கணிப்பது போதுமானதாக இல்லை. இது ஒரு பாடலின் முதல் சுரத்தை (note) மட்டும் கேட்டு, முழு பாடலையும் ஊகிப்பது போன்றது. ஆனால், குறைந்தது இரண்டு சுரங்கள் (notes) இருந்தால், நம்முடைய ஊகம் மிகவும் துல்லியமாக இருக்கும்.  

இதைப் புரிந்துகொள்ள, தமிழில் உள்ள ஒரு எளிய மொழி மாதிரியை (toy language model) பார்க்கலாம். இந்த மாதிரியில் இரண்டு வாக்கியங்கள் மட்டுமே உள்ளன, மேலும் அவை 40/60 விகிதத்தில் உள்ளன என்று வைத்துக்கொள்வோம்:  

1. "எனது புத்தகத்தை எடு."  
2. "எனது பேனாவை எடு."  

இந்த வாக்கியங்களுக்கு ஒரு முதல் வரிசை மார்கோவ் சங்கிலி (First Order Markov Chain) உருவாக்கினால், அது ஒவ்வொரு வார்த்தையையும் அதற்கு முந்தைய ஒரு வார்த்தையை மட்டும் பார்த்து கணிக்கும். ஆனால், இந்த மாதிரியில் சில நிச்சயமற்ற தருணங்கள் (uncertainty) இருக்கும். எடுத்துக்காட்டாக, "எனது" என்ற வார்த்தைக்குப் பிறகு "புத்தகத்தை" அல்லது "பேனாவை" வரலாம்.  

இதைச் சரிசெய்ய, நமது மாதிரி ஒரு வார்த்தையை மட்டும் பார்க்காமல், இரண்டு வார்த்தைகளைப் பார்த்தால், அது மிகவும் துல்லியமாக செயல்படும். எடுத்துக்காட்டாக, "எனது புத்தகத்தை" என்ற இரண்டு வார்த்தைகளைப் பார்த்தால், அடுத்த வார்த்தை "எடு" என்பது தெளிவாகத் தெரியும். அதேபோல், "எனது பேனாவை" என்ற இரண்டு வார்த்தைகளைப் பார்த்தால், அடுத்த வார்த்தை "எடு" என்பது தெளிவாகத் தெரியும். இதன் மூலம், மாதிரியில் உள்ள கிளைத்தல் (branching) குறைந்து, நிச்சயமற்ற தன்மை (uncertainty) குறைகிறது.  

இரண்டு வார்த்தைகளைப் பார்ப்பதன் மூலம், இது ஒரு **இரண்டாம் வரிசை மார்கோவ் மாதிரி (Second Order Markov Model)** ஆக மாறுகிறது. இது அடுத்த வார்த்தையை கணிக்க அதிகமான சூழலை (context) வழங்குகிறது.  

**முதல் வரிசை vs இரண்டாம் வரிசை மாற்றம் மேட்ரிக்ஸ்**  

முதல் வரிசை மார்கோவ் மாதிரியில், ஒவ்வொரு வார்த்தைக்கும் அடுத்து வரக்கூடிய வார்த்தைகளின் நிகழ்தகவுகள் மட்டுமே உள்ளன. ஆனால், இரண்டாம் வரிசை மார்கோவ் மாதிரியில், ஒவ்வொரு **இரண்டு வார்த்தைகளின் கலவைக்கும்** (combination) அடுத்து வரக்கூடிய வார்த்தைகளின் நிகழ்தகவுகள் உள்ளன.  

**முதல் வரிசை மாற்றம் மேட்ரிக்ஸ்:**  
இந்த மேட்ரிக்ஸில், ஒவ்வொரு வரிசையும் ஒரு வார்த்தையைக் குறிக்கும், மற்றும் ஒவ்வொரு நெடுவரிசையும் அந்த வார்த்தைக்கு அடுத்து வரக்கூடிய வார்த்தையின் நிகழ்தகவைக் குறிக்கும்.  

**இரண்டாம் வரிசை மாற்றம் மேட்ரிக்ஸ்:**  
இந்த மேட்ரிக்ஸில், ஒவ்வொரு வரிசையும் **இரண்டு வார்த்தைகளின் கலவையை** (combination) குறிக்கும், மற்றும் ஒவ்வொரு நெடுவரிசையும் அந்த இரண்டு வார்த்தைகளுக்கு அடுத்து வரக்கூடிய வார்த்தையின் நிகழ்தகவைக் குறிக்கும்.  

எடுத்துக்காட்டாக, "எனது புத்தகத்தை" என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து "எடு" வரும் நிகழ்தகவு **1.0** ஆகும். அதேபோல், "எனது பேனாவை" என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து "எடு" வரும் நிகழ்தகவு **1.0** ஆகும்.  

```
{எனது, புத்தகத்தை, எடு, பேனாவை}
```

இரண்டாம் வரிசை மார்கோவ் மாதிரியில், ஒவ்வொரு இரண்டு வார்த்தைகளின் கலவைக்கும் அடுத்து வரக்கூடிய வார்த்தையின் நிகழ்தகவுகள் கணக்கிடப்படுகின்றன. இதை ஒரு மேட்ரிக்ஸ் வடிவில் குறிப்பிடலாம்.  

| இரண்டு வார்த்தைகள் (Combination) | அடுத்த வார்த்தை | நிகழ்தகவு (Probability) |
| ---------------------------- | ------------ | ---------------------- |
| எனது புத்தகத்தை                | எடு          | 1.0                    |
| எனது பேனாவை                  | எடு          | 1.0                    |
| புத்தகத்தை எடு                 | -            | 0.0                    |
| பேனாவை எடு                   | -            | 0.0                    |

விளக்கம்:  

1. **"எனது புத்தகத்தை"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"எடு"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
2. **"எனது பேனாவை"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"எடு"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
3. **"புத்தகத்தை எடு"** மற்றும் **"பேனாவை எடு"** போன்ற கலவைகளுக்கு அடுத்து எந்த வார்த்தையும் வராது, எனவே நிகழ்தகவு **0.0** ஆகும்.  

இரண்டாம் வரிசை மாற்றம் மேட்ரிக்ஸில், வரிசைகளின் எண்ணிக்கை மிகவும் அதிகமாக இருக்கும். ஏனெனில், ஒவ்வொரு இரண்டு வார்த்தைகளின் கலவைக்கும் ஒரு வரிசை தேவைப்படுகிறது. எனவே, சொற்களஞ்சியத்தில் (vocabulary) \(N\) வார்த்தைகள் இருந்தால், மேட்ரிக்ஸில் \(N^2\) வரிசைகள் இருக்கும்.  

**இரண்டாம் வரிசை மாதிரியின் நன்மைகள்**  

இரண்டாம் வரிசை மார்கோவ் மாதிரியின் முக்கிய நன்மை என்னவென்றால், அது அதிக நிச்சயத்தன்மையை (confidence) வழங்குகிறது. இந்த மாதிரியில், மேட்ரிக்ஸில் அதிகமான ஒன்றுகள் (1) மற்றும் குறைவான பின்னங்கள் (fractions) இருக்கும். எடுத்துக்காட்டாக, மேலே உள்ள எடுத்துக்காட்டில், ஒரே ஒரு வரிசையில் மட்டுமே பின்னங்கள் உள்ளன (அதாவது, "எனது"க்குப் பிறகு "புத்தகத்தை" அல்லது "பேனாவை" வரும் நிகழ்தகவுகள்).  

இரண்டு வார்த்தைகளைப் பார்ப்பதன் மூலம், அடுத்த வார்த்தையை கணிக்க அதிகமான சூழல் (context) கிடைக்கிறது. இது மொழி மாதிரிகளில் (language models) மிகவும் பயனுள்ளதாக இருக்கிறது, ஏனெனில் இது மொழியின் கட்டமைப்பை (structure) மிகவும் துல்லியமாக பிரதிபலிக்கிறது.  

இரண்டாம் வரிசை மார்கோவ் மாதிரிகள் சவாலானவையாக இருக்கலாம், ஆனால் அவை மொழி மாதிரிகளின் துல்லியத்தை மேம்படுத்துவதற்கு ஒரு சக்திவாய்ந்த கருவியாகும்.

**இரண்டாம் வரிசை மாதிரி மற்றும் ஸ்கிப்ஸ் (Second Order Model with Skips)**  

இரண்டாம் வரிசை மார்கோவ் மாதிரி (Second Order Markov Model) இரண்டு முந்தைய வார்த்தைகளைப் பார்த்து அடுத்த வார்த்தையை கணிக்கிறது. ஆனால், சில சந்தர்ப்பங்களில், அடுத்த வார்த்தையை கணிக்க நாம் இரண்டுக்கும் மேற்பட்ட முந்தைய வார்த்தைகளைப் பார்க்க வேண்டியிருக்கும். 

எடுத்துக்காட்டாக, இரண்டு வாக்கியங்களை எடுத்துக்கொள்வோம்:  

1. "நிமலன் பள்ளிக்குச் சென்றான், பாடங்களைக் கற்றான், வீட்டிற்குத் திரும்பினான்."  
2. "நிமலன் பூங்காவிற்குச் சென்றான், பூக்களைப் பார்த்தான், வீட்டிற்குத் திரும்பினான்."  

இந்த வாக்கியங்களில், "வீட்டிற்குத்" என்ற வார்த்தைக்குப் பிறகு " திரும்பினான்" வரும் என்பதை தீர்மானிக்க, நாம் முந்தைய பல வார்த்தைகளைப் பார்க்க வேண்டும்.  

இதுபோன்ற நீண்ட தூர சார்புகளை (long-range dependencies) கையாள, நாம் மூன்றாம் அல்லது அதற்கு மேற்பட்ட வரிசை மாதிரிகளை (higher-order models) பயன்படுத்தலாம். ஆனால், சொற்களஞ்சியம் (vocabulary) பெரியதாக இருந்தால், இது கணக்கிட மிகவும் சிக்கலானதாக இருக்கும். எடுத்துக்காட்டாக, எட்டாம் வரிசை மாதிரியில் ($N^8$) வரிசைகள் இருக்கும், இது மிகவும் அதிகமான எண்ணிக்கையாகும்.  

இதற்கு பதிலாக, நாம் ஒரு சாமார்த்தியமான முறையைப் பயன்படுத்தலாம்: **இரண்டாம் வரிசை மாதிரியைப் பயன்படுத்தி, முந்தைய வார்த்தைகளின் கலவைகளைக் கருத்தில் கொள்ளலாம்**. இந்த மாதிரியில், நாம் இரண்டு வார்த்தைகளை மட்டும் பார்க்கிறோம், ஆனால் அவற்றில் ஒன்று மிக சமீபத்திய வார்த்தையாகவும், மற்றொன்று முந்தைய எந்தவொரு வார்த்தையாகவும் இருக்கலாம். இது நீண்ட தூர சார்புகளைப் பிடிக்க உதவுகிறது.  

இதை ஒரு மேட்ரிக்ஸ் வடிவில் குறிப்பிடலாம்.  இந்த எடுத்துக்காட்டில், "வீட்டிற்குத்" என்ற வார்த்தைக்குப் பிறகு "திரும்பினான்" வரும் என்பதை தீர்மானிக்க, நாம் முந்தைய இரண்டு வார்த்தைகளின் கலவையைப் பார்க்கிறோம்.  

| இரண்டு வார்த்தைகள் (Combination) | அடுத்த வார்த்தை | நிகழ்தகவு (Probability) |
| ---------------------------- | ------------ | ---------------------- |
| பள்ளிக்குச் சென்றான், வீட்டிற்குத்    | திரும்பினான்   | 0.0                    |
| பூங்காவிற்குச் சென்றான், வீட்டிற்குத் | திரும்பினான்   | 0.0                    |
| பாடங்களைக் கற்றான், வீட்டிற்குத்     | திரும்பினான்   | 1.0                    |
| பூக்களைப் பார்த்தான், வீட்டிற்குத்    | திரும்பினான்   | 1.0                    |

விளக்கம்:  

1. **"பாடங்களைக் கற்றான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
2. **"பூக்களைப் பார்த்தான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
3. **"பள்ளிக்குச் சென்றான், வீட்டிற்குத்"** மற்றும் **"பூங்காவிற்குச் சென்றான், வீட்டிற்குத்"** போன்ற கலவைகளுக்கு அடுத்து எந்த வார்த்தையும் வராது, எனவே நிகழ்தகவு **0.0** ஆகும்.  

இந்த மேட்ரிக்ஸ், இரண்டாம் வரிசை மார்கோவ் மாதிரியின் அமைப்பைக் காட்டுகிறது. இது முந்தைய இரண்டு வார்த்தைகளைப் பார்த்து, அடுத்த வார்த்தையை கணிக்க உதவுகிறது.

##### மாஸ்கிங் (Masking)  

முந்தைய மாதிரியில், "வீட்டிற்குத்" என்ற வார்த்தைக்குப் பிறகு "திரும்பினான்" வரும் என்பதை கணிக்க, நாம் பல வார்த்தைகளின் கலவைகளைப் பார்த்தோம். ஆனால், இந்த மாதிரியில் பெரும்பாலான கலவைகள் பயனற்றவையாக இருந்தன. எடுத்துக்காட்டாக, "பள்ளிக்குச் சென்றான், வீட்டிற்குத்" மற்றும் "பூங்காவிற்குச் சென்றான், வீட்டிற்குத்" போன்ற கலவைகள் எந்த தகவலையும் வழங்கவில்லை. இதை மேம்படுத்த, நாம் **மாஸ்கிங் (Masking)** என்ற முறையைப் பயன்படுத்தலாம். இந்த முறையில், பயனற்ற கலவைகளை மறைத்து, முக்கியமான கலவைகளை மட்டும் கணக்கில் எடுத்துக்கொள்கிறோம்.  

**மாஸ்கிங் முறை:**  

மாஸ்கிங் முறையில், நாம் ஒரு **மாஸ்க் வெக்டர் (Mask Vector)** உருவாக்குகிறோம். இந்த வெக்டரில், முக்கியமான கலவைகளுக்கு **1** மதிப்பும், பயனற்ற கலவைகளுக்கு **0** மதிப்பும் இருக்கும்.  

**மாஸ்க் வெக்டர்:**  

```
[பள்ளிக்குச் சென்றான், வீட்டிற்குத்: 0,  
 பூங்காவிற்குச் சென்றான், வீட்டிற்குத்: 0,  
 பாடங்களைக் கற்றான், வீட்டிற்குத்: 1,  
 பூக்களைப் பார்த்தான், வீட்டிற்குத்: 1]
```

இந்த மாஸ்க் வெக்டரை, மாற்றம் மேட்ரிக்ஸுடன் (Transition Matrix) பெருக்கினால், பயனற்ற கலவைகள் மறைக்கப்படும்.  

**மாஸ்க்டு மாற்றம் மேட்ரிக்ஸ் (Masked Transition Matrix**)  

| இரண்டு வார்த்தைகள் (Combination) | அடுத்த வார்த்தை | நிகழ்தகவு (Probability) |
| ---------------------------- | ------------ | ---------------------- |
| பள்ளிக்குச் சென்றான், வீட்டிற்குத்    | திரும்பினான்   | 0.0                    |
| பூங்காவிற்குச் சென்றான், வீட்டிற்குத் | திரும்பினான்   | 0.0                    |
| பாடங்களைக் கற்றான், வீட்டிற்குத்     | திரும்பினான்   | 1.0                    |
| பூக்களைப் பார்த்தான், வீட்டிற்குத்    | திரும்பினான்   | 1.0                    |

விளக்கம்:  

1. **"பாடங்களைக் கற்றான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
2. **"பூக்களைப் பார்த்தான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
3. **"பள்ளிக்குச் சென்றான், வீட்டிற்குத்"** மற்றும் **"பூங்காவிற்குச் சென்றான், வீட்டிற்குத்"** போன்ற கலவைகள் மாஸ்க் செய்யப்பட்டு, அவற்றின் நிகழ்தகவு **0.0** ஆகும்.  

மாஸ்கிங் முறை, மொழி மாதிரிகளில் (language models) மிகவும் பயனுள்ளதாக இருக்கிறது. இது முக்கியமான தகவல்களை மட்டும் கணக்கில் எடுத்துக்கொண்டு, பயனற்ற தகவல்களை வடிகட்டுகிறது. இது மாதிரியின் செயல்திறனை மேம்படுத்துகிறது மற்றும் துல்லியமான கணிப்புகளை வழங்குகிறது. மாஸ்கிங் முறையின் முக்கிய நன்மை என்னவென்றால், அது மாதிரியின் நம்பகத்தன்மையை (confidence) அதிகரிக்கிறது. பயனற்ற கலவைகளை மறைப்பதன் மூலம், மாதிரி மிகவும் துல்லியமான கணிப்புகளைச் செய்கிறது.  

<div style="page-break-after: always;"></div>

#### 13. தமிழ் GPT: சங்கத்தமிழ் பாடல்களை உருவாக்கும் ஒரு AI கவிஞர்

 நாம் இன்று டீப் லேர்னிங் (Deep Learning) தொழில்நுட்பத்தைப் பயன்படுத்தி ஒரு AI கவிஞரை எப்படி உருவாக்கலாம் என்று விரிவாகக் காண்போம். இந்த AI கவிஞர், சங்கத்தமிழ் பாணியில் புதிய பாடல்களை இயற்றக்கூடிய திறன் கொண்டவர்! பைத்தான் (Python) மொழியில் உருவாக்கப்பட்ட இந்த டீப் லேர்னிங் மாடல், சங்கத்தமிழ் இலக்கியத்திலிருந்து கற்றுக்கொண்டு புதிய பாடல்களை உருவாக்கும்.

தேவையானவை PyTorch இது டீப் லேர்னிங் மாடல்களை உருவாக்க உதவும் ஒரு பைத்தான் நூலகம் (library). சங்கத்தமிழ் தரவு - Project Madurai போன்ற இணையதளங்களில் இருந்து சங்கத்தமிழ் பாடல்களைப் பதிவிறக்கம் செய்து கொள்ளலாம். இதனை `input.txt` என்ற கோப்பில் சேமித்து வைக்கவும்.

கம்ப்யூட்டரால் நேரடியாக டெக்ஸ்ட்டைப் புரிந்து கொள்ள முடியாது. டெக்ஸ்ட்டை எண்களாக மாற்றும் "encoding" செயல்முறை அவசியம். சங்கத்தமிழ் பாடல்களை கம்ப்யூட்டருக்குப் புரியும் வகையில் மாற்ற, முதலில் பாடல்களில் உள்ள தனித்துவமான எழுத்துக்களை அடையாளம் கண்டு சொல்லகராதி உருவாக்க வேண்டும். இந்த சொல்லகராதி, ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண்ணை ஒதுக்கும். பின்னர், இந்த எண்களைப் பயன்படுத்தி பாடல்களை கம்ப்யூட்டர் புரிந்துகொள்ளும் வகையில் மாற்றலாம். உதாரணமாக, "ம" என்ற எழுத்துக்கு 57, "லை" என்ற எழுத்துக்கு 61, 73 எண்களை ஒதுக்கலாம். இதன் மூலம், **"மலை" என்ற வார்த்தையை 57, 61, 73**  என்ற எண்களாக மாற்றலாம். இந்த எண்களை கம்ப்யூட்டர் பல்வேறு வழிகளில் பயன்படுத்தலாம்.  உதாரணமாக, மொழிபெயர்ப்பு, உரை பகுப்பாய்வு,  உணர்வு பகுப்பாய்வு போன்ற பணிகளுக்கு இந்த  எண்கள் பயன்படும்.

ஏன் தனித்துவமான எழுத்துக்கள்?

கம்ப்யூட்டருக்குத் தமிழ் எழுத்துக்களைப் பற்றி எதுவும் தெரியாது. நாம் ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண்ணைக் கொடுக்க வேண்டும். நமது மாடல் பயன்படுத்தும் மொத்த எழுத்துக்களின் தொகுப்பு தான் சொல்லகராதி. இந்த சொல்லகராதியில் உள்ள ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண் குறியீடு இருக்கும்.

எப்படி தனித்துவமான எழுத்துக்களைக் கண்டுபிடிப்பது?

1. **பாடல்களைப் படித்தல்:** `input.txt` கோப்பில் உள்ள சங்கத்தமிழ் பாடல்களைப் படிக்கவும்.
2. **எழுத்துக்களைச் சேகரித்தல்:** பாடல்களில் உள்ள ஒவ்வொரு எழுத்தையும் ஒரு "set"-ல் சேர்க்கவும். "set"-ல் ஒரே எழுத்து பலமுறை வந்தாலும், ஒரே முறை தான் சேமிக்கப்படும்.
3. **வரிசைப்படுத்துதல்:** "set"-ல் உள்ள எழுத்துக்களை அகர வரிசையில் வரிசைப்படுத்தவும்.

**உதாரணம்:**

`input.txt` கோப்பில் "அகர முதல" என்று இருந்தால்,

- படிக்கப்பட்ட எழுத்துக்கள்: அ, க, ர, மு, த, ல
- "set"-ல் சேர்க்கப்பட்ட எழுத்துக்கள்: {அ, க, ர, மு, த, ல}
- வரிசைப்படுத்தப்பட்ட எழுத்துக்கள்: [அ, க, ங, ச, ட, த, ந, ப, ம, ய, ர, ல, வ, ழ, ள, ற, ன] (இது ஒரு உதாரணம் மட்டுமே, உங்கள் கோப்பில் உள்ள எழுத்துக்கள் வேறுபடலாம்)

```python
chars = sorted(list(set(text)))
vocab_size = len(chars)
```

- `text`: `input.txt` கோப்பில் உள்ள பாடல்களின் டெக்ஸ்ட்.
- `set(text)`: டெக்ஸ்டில் உள்ள தனித்துவமான எழுத்துக்களைக் கொண்ட ஒரு "set"-ஐ உருவாக்குகிறது.
- `list(set(text))`: "set"-ஐ ஒரு "list"-ஆக மாற்றுகிறது.
- `sorted(list(set(text)))`: "list"-ஐ அகர வரிசையில் வரிசைப்படுத்துகிறது.
- `chars`: வரிசைப்படுத்தப்பட்ட தனித்துவமான எழுத்துக்களின் "list".
- `vocab_size`: தனித்துவமான எழுத்துக்களின் எண்ணிக்கை (சொல்லகராதியின் அளவு).

இந்த தனித்துவமான எழுத்துக்களைக் கண்டுபிடிக்கும் செயல்முறை, நமது மொழி மாதிரியின் முதல் படியாகும். இந்த எழுத்துக்கள் தான் மாடல் புரிந்து கொள்ளும் அடிப்படை கூறுகள். ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண்ணை (integer) கொடுக்க வேண்டும். இதை ஒரு அகராதியாக (dictionary) சேமித்து வைப்போம். 

```python
stoi = {' ': 2,'அ': 31,'க': 43,'ர': 59,'மு': 57,'த': 69,'ல': 52,'எ': 61,'ழு': 37,'த்': 63, 'ெ': 77,'ல்': 71, 'ா': 66}
```

இந்த அகராதியைப் பயன்படுத்தி, "அகர முதல" என்ற டெக்ஸ்ட்டை எண்களாக மாற்றும்போது, நமக்கு `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியல் கிடைக்கும். முதல் எழுத்து "அ". `stoi` அகராதியில், "அ" என்ற எழுத்துக்கு 31 என்ற எண் ஒதுக்கப்பட்டுள்ளது. எனவே, முதல் எண் 31. இரண்டாவது எழுத்து "க". `stoi` அகராதியில், "க" என்ற எழுத்துக்கு 43 என்ற எண் ஒதுக்கப்பட்டுள்ளது. எனவே, இரண்டாவது எண் 43. இதேபோல், மற்ற எழுத்துக்களுக்கும் `stoi` அகராதியில் உள்ள எண்களை எடுத்துக்கொள்வோம். இறுதியில், "அகர முதல" என்ற டெக்ஸ்ட் `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியலாக மாறும்.

**குறிப்பு:**
உங்கள் `stoi` அகராதியில் உள்ள எண்கள், நீங்கள் பயன்படுத்தும் டேட்டா மற்றும் encoding முறையைப் பொறுத்து மாறுபடலாம்.

**Decoding**

"Decoding" என்பது "encoding"-க்கு எதிர்மாறான செயல்முறை. அதாவது, எண்களின் பட்டியலை எடுத்துக்கொண்டு, அதை டெக்ஸ்ட்டாக மாற்றுவது. "Encoding"-ல் பயன்படுத்திய அகராதியைத் தலைகீழாக மாற்ற வேண்டும். அதாவது, எண்கள் "key"-ஆகவும், எழுத்துக்களை "value"-ஆகவும் கொண்ட ஒரு அகராதி:

```python
itos = {2: ' ', 31: 'அ', 43: 'க', 59: 'ர', 57: 'மு', 69: 'த', 52: 'ல', 61: 'எ', 37: 'ழு', 63: 'த்', 77: 'ெ', 71: 'ல்', 66: 'ா'}
```

**எழுத்துக்களாக மாற்றுதல் (Conversion to Characters)**

இப்போது, நமக்குக் கொடுக்கப்பட்ட எண்களின் பட்டியலை எடுத்துக்கொள்வோம். பட்டியலில் உள்ள ஒவ்வொரு எண்ணையும் எடுத்துக்கொண்டு, அகராதியில் அதற்குரிய எழுத்தைப் பார்ப்போம். இந்த எழுத்துக்களை ஒன்றாக இணைத்தால், நமக்கு டெக்ஸ்ட் கிடைக்கும்.

**உதாரணம்:**

`[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியலை எடுத்துக்கொள்வோம்.

- முதல் எண் 31. அகராதியில் 31 என்ற எண்ணுக்கு "அ" என்ற எழுத்து ஒதுக்கப்பட்டுள்ளது.
- இரண்டாவது எண் 43. அகராதியில் 43 என்ற எண்ணுக்கு "க" என்ற எழுத்து ஒதுக்கப்பட்டிருக்கலாம்.
- இதேபோல், மற்ற எண்களுக்கும் அகராதியில் உள்ள எழுத்துக்களை எடுத்துக்கொள்வோம்.

இறுதியில், `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியல் "அகர முதல" என்ற டெக்ஸ்ட்டாக மாறும்.

சுருக்கமாக

- Encoding: டெக்ஸ்ட்டை எண்களாக மாற்றுதல்.
- Decoding: எண்களை டெக்ஸ்ட்டாக மாற்றுதல்.

இந்த இரண்டு செயல்முறைகளும், டெக்ஸ்ட் டேட்டாவை கம்ப்யூட்டர் புரிந்து கொள்ளும் வகையில் மாற்ற உதவுகின்றன. இதன் மூலம், டெக்ஸ்ட் டேட்டாவைப் பயன்படுத்தி டீப் லேர்னிங் மாடல்களை உருவாக்க முடியும்.

இப்பொழுது நாம் கற்றவற்றை பைதானில் செய்து பார்ப்போம் 

**1. Libraries & Hyperparameters:**

```python
import torch
import torch.nn as nn
from torch.nn import functional as F

# Hyperparameters
batch_size = 16     # எத்தனை பாடல்களை ஒரே நேரத்தில் process செய்ய வேண்டும்
block_size = 32    # எத்தனை எழுத்துக்களை மாதிரி கணக்கில் எடுத்துக்கொள்ள வேண்டும்
max_iters = 5000   # எத்தனை முறை train செய்ய வேண்டும்
eval_interval = 100  # எத்தனை iterations-க்கு ஒரு முறை loss-ஐ calculate செய்ய வேண்டும்
learning_rate = 1e-3 # மாதிரி கற்கும் வேகம்
device = 'cuda' if torch.cuda.is_available() else 'cpu' # GPU இருந்தால் அதை பயன்படுத்தும்
eval_iters = 200
n_embd = 64
n_head = 4
n_layer = 4
dropout = 0.0

torch.manual_seed(1337)
```

**விளக்கம்:**

- **Libraries:**
  - `import torch`: PyTorch-ன் core functionalities-ஐ import செய்கிறது. Tensor operations, dynamic computation graphs போன்ற வசதிகளை பயன்படுத்துவதற்கு இது அவசியம்.
  - `import torch.nn as nn`: Neural network modules-ஐ உருவாக்க உதவுகிறது.  இங்குதான் நாம் நமது மாடலின் layers-களை define செய்வோம்.
  - `from torch.nn import functional as F`: Activation functions (எ.கா: ReLU, softmax), loss functions (எ.கா: cross_entropy) போன்ற  utils-களை import செய்கிறது.
- **Hyperparameters:** இவை நமது டீப் லேர்னிங் மாடலின் training process-ஐ control செய்யும் மாறிகள் (variables).  இவற்றின் சரியான தேர்வு, மாடல் எவ்வளவு நன்றாக கற்றுக்கொள்கிறது என்பதைப் பொறுத்தது.
  - `batch_size = 16`:  ஒரு முறை training செய்யும் போது எத்தனை பாடல்களை (sequences)  மாடலுக்குக் கொடுக்க வேண்டும் என்பது.  பெரிய `batch_size` வேகமாக training செய்ய உதவும், ஆனால் அதிக memory தேவைப்படும்.
  - `block_size = 32`:  ஒரு பாடலில் (sequence) எத்தனை எழுத்துக்களை ஒரு நேரத்தில் process செய்ய வேண்டும் என்பது.  இது context window size போன்றது.  அதாவது, மாடல் ஒரு எழுத்தைக் கணிக்க, முந்தைய `block_size` எழுத்துக்களைப் பார்க்கும்.
  - `max_iters = 5000`:  மொத்த training iterations எண்ணிக்கை.  அதிக iterations-ல் மாடல் நன்றாக கற்றுக்கொள்ள வாய்ப்புள்ளது, ஆனால் overfitting ஆகவும் வாய்ப்புள்ளது.
  - `eval_interval = 100`:  Training progress-ஐ monitor செய்ய, எத்தனை iterations-க்கு ஒரு முறை validation loss-ஐ கணக்கிட வேண்டும் என்பது.
  - `learning_rate = 1e-3`:  மாடல் weights-ஐ எவ்வளவு வேகமாக adjust செய்ய வேண்டும் என்பது.  சிறிய `learning_rate` மெதுவாக கற்கும், ஆனால் stable-ஆக கற்கும்.  பெரிய `learning_rate` வேகமாக கற்கும், ஆனால் unstable-ஆக இருக்கலாம்.
  - `device = 'cuda' if torch.cuda.is_available() else 'cpu'`:  GPU இருந்தால் training-ஐ GPU-வில் செய்யும்.  GPU இருந்தால் training வேகமாக நடக்கும்.  GPU இல்லை என்றால் CPU-வில் நடக்கும்.
  - `eval_iters = 200`: Evaluation-க்காக எத்தனை iterations செய்ய வேண்டும் என்பது.
  - `n_embd = 64`:  Embedding dimension.  ஒவ்வொரு எழுத்தையும் ஒரு vector-ஆக மாற்றும்போது, அந்த vector-ன் அளவு.
  - `n_head = 4`:  Transformer-ல் எத்தனை attention heads இருக்க வேண்டும் என்பது.
  - `n_layer = 4`:  Transformer-ல் எத்தனை layers இருக்க வேண்டும் என்பது.
  - `dropout = 0.0`:  Dropout rate.  Overfitting-ஐ குறைக்க உதவுகிறது.
- `torch.manual_seed(1337)`:  Random seed-ஐ set செய்கிறோம்.  இதனால், ஒவ்வொரு முறை program-ஐ run செய்தாலும், ஒரே மாதிரியான output கிடைக்கும்.  இது debugging மற்றும் experiments-ஐ reproduce செய்ய உதவுகிறது.

இந்த hyperparameters-ஐ மாற்றி, model-ன் performance-ஐ மேம்படுத்தலாம்.  இவை machine learning-ல் முக்கியமான tuning parameters.  இப்பொழுது, ஏன் இந்த values-களை தேர்ந்தெடுத்தோம் என்பது உங்களுக்கு புரிந்திருக்கும் என்று நினைக்கிறேன். அடுத்த பாகத்தில், data loading மற்றும் preprocessing பற்றி விரிவாகக் காண்போம்.

**2. Data Loading & Preprocessing:**

```python
# டேட்டாவை படித்தல்
with open('input.txt', 'r', encoding='utf-8') as f:
    text = f.read()

# தனித்துவமான எழுத்துக்களை கண்டுபிடித்தல்
chars = sorted(list(set(text)))
vocab_size = len(chars)

# எழுத்துக்களை எண்களாக மாற்றுதல் (Encoding)
stoi = { ch:i for i,ch in enumerate(chars) }
itos = { i:ch for i,ch in enumerate(chars) }
encode = lambda s: [stoi[c] for c in s] 
decode = lambda l: ''.join([itos[i] for i in l]) 

# டேட்டாவை train மற்றும் validation என பிரித்தல்
data = torch.tensor(encode(text), dtype=torch.long)
n = int(0.9*len(data)) 
train_data = data[:n]
val_data = data[n:]
```

**விளக்கம்:**

1. **டேட்டாவைப் படித்தல் (`input.txt` கோப்பிலிருந்து):**

   Python

   ```python
   with open('input.txt', 'r', encoding='utf-8') as f:
       text = f.read()
   ```

   - `with open(...)`:  `input.txt` கோப்பை படிக்க திறக்கிறது. `encoding='utf-8'` என்பது தமிழ் எழுத்துக்களைச் சரியாகப் படிக்க உதவுகிறது.  UTF-8 encoding பெரும்பாலான தமிழ் எழுத்துக்களை உள்ளடக்கியது.
   - `f.read()`: கோப்பிலுள்ள அனைத்து உள்ளடக்கத்தையும் ஒரு string-ஆக `text` மாறியில் சேமிக்கிறது.

2. **தனித்துவமான எழுத்துக்களைக் கண்டுபிடித்தல்:**

   Python

   ```python
   chars = sorted(list(set(text)))
   vocab_size = len(chars)
   ```

   - `set(text)`: `text` string-ல் உள்ள **தனித்துவமான** எழுத்துக்களைக் கொண்ட ஒரு set-ஐ உருவாக்குகிறது.  ஒரு set-ல், எந்த ஒரு உறுப்பும் இரண்டு முறை வராது.  இதனால், எல்லா தனித்துவமான எழுத்துக்களும் கிடைக்கும்.
   - `list(set(text))`: set-ஐ ஒரு list-ஆக மாற்றுகிறது.  set-ல் உள்ள உறுப்புகளுக்கு ஒரு குறிப்பிட்ட வரிசை இல்லை.  list-ஆக மாற்றும்போது, உறுப்புகளுக்கு ஒரு வரிசை கிடைக்கிறது.
   - `sorted(...)`: list-ஐ அகர வரிசையில் வரிசைப்படுத்துகிறது.  வரிசைப்படுத்துவதால், எழுத்துக்களுக்கு ஒரு நிலையான குறியீடு (index) கொடுக்க முடியும்.
   - `chars`: வரிசைப்படுத்தப்பட்ட தனித்துவமான எழுத்துக்களின் list.
   - `vocab_size`: தனித்துவமான எழுத்துக்களின் எண்ணிக்கை (நமது சொல்லகராதியின் அளவு).

3. **எழுத்துக்களை எண்களாக மாற்றுதல் (Encoding):**

   Python

   ```python
   stoi = { ch:i for i,ch in enumerate(chars) }
   itos = { i:ch for i,ch in enumerate(chars) }
   encode = lambda s: [stoi[c] for c in s] 
   decode = lambda l: ''.join([itos[i] for i in l]) 
   ```

   - `stoi`:  **s**tring **t**o **i**nteger என்ற dictionary.  ஒவ்வொரு எழுத்துக்கும் ஒரு unique integer mapping-ஐ உருவாக்குகிறது.  இந்த mapping-ஐப் பயன்படுத்தி,  டெக்ஸ்டை எண்களாக மாற்றலாம்.
   - `itos`:  **i**nteger **t**o **s**tring என்ற dictionary.  `stoi`-க்கு நேர் எதிரானது.  எண்களை எழுத்துக்களாக மாற்ற உதவுகிறது.
   - `encode(s)`:  ஒரு string `s`-ஐ எடுத்து, `stoi` dictionary-ஐப் பயன்படுத்தி, அதில் உள்ள ஒவ்வொரு எழுத்தையும் அதற்குரிய எண்ணாக மாற்றி, ஒரு list-ஐ  (எண்களின் list)  திரும்ப  அளிக்கிறது.
   - `decode(l)`:  ஒரு list `l` (எண்களின் list) -ஐ எடுத்து, `itos` dictionary-ஐப் பயன்படுத்தி, அதில் உள்ள ஒவ்வொரு எண்ணையும் அதற்குரிய எழுத்தாக மாற்றி,  string-ஐ  திரும்ப  அளிக்கிறது.

4. **டேட்டாவை train மற்றும் validation என பிரித்தல்:**

   Python

   ```python
   data = torch.tensor(encode(text), dtype=torch.long)
   n = int(0.9*len(data)) 
   train_data = data[:n]
   val_data = data[n:]
   ```

   - `encode(text)`:  முழு `text`-ஐ `encode` function-ஐப் பயன்படுத்தி எண்களாக மாற்றுகிறது.
   - `torch.tensor(...)`:  `encode(text)`-ன் வெளியீட்டை  PyTorch tensor-ஆக மாற்றுகிறது.  `dtype=torch.long` என்பது  integers-ஐக் குறிக்கிறது.  Tensorகள் தான் PyTorch-ல்  data-வை  manipulate  செய்ய  பயன்படுத்தப்படும்  datastructure.
   - `n = int(0.9*len(data))`:  மொத்த data-வில் 90%  train data-க்காகவும், 10%  validation data-க்காகவும்  பிரிக்கும்  வகையில்  `n`  மதிப்பை  கணக்கிடுகிறது.
   - `train_data`:  முதல் `n`  எழுத்துக்கள்  train data-வாக  சேமிக்கப்படுகிறது.
   - `val_data`:  மீதமுள்ள  எழுத்துக்கள்  validation data-வாக  சேமிக்கப்படுகிறது.  Validation data, model-ன்  performance-ஐ  train  செய்யும்  போதே  பார்க்க  உதவும்.

இந்த  நான்கு  படிகளின்  மூலம்,  சங்கத்  தமிழ்  பாடல்களைக்  கொண்ட  தரவை  டீப்  லேர்னிங்  மாடலுக்குத்  தேவையான  வடிவத்தில்  மாற்றுகிறோம்.  இனி,  மாடலை  உருவாக்குதல்  மற்றும்  train  செய்தல்  பற்றி  பார்ப்போம்.

**3. Batching:**

 நாம் தயாரித்த தரவை டீப் லேர்னிங் மாடலுக்குப் பயிற்சியளிக்க ஏற்ற batches ஆக எப்படிப் பிரிக்கலாம் என்று விரிவாகக் காண்போம்.

```python
# டேட்டாவை batches ஆக பிரித்தல்
def get_batch(split):
    data = train_data if split == 'train' else val_data
    ix = torch.randint(len(data) - block_size, (batch_size,))
    x = torch.stack([data[i:i+block_size] for i in ix])
    y = torch.stack([data[i+1:i+block_size+1] for i in ix])
    x, y = x.to(device), y.to(device)
    return x, y
```

**விளக்கம்:**

`get_batch(split)` என்ற function, `train` அல்லது `validation` data-வில் இருந்து ஒரு batch டேட்டாவை எடுத்துத் தருகிறது.  ஒவ்வொரு batch-லும் `batch_size` எண்ணிக்கையிலான பாடல்கள் இருக்கும்.

1. **டேட்டா தேர்வு:**

   Python

   ```python
   data = train_data if split == 'train' else val_data
   ```

   `split`  என்ற  மாறியின்  மதிப்பை  பொறுத்து,  `train_data`  அல்லது  `val_data`  தேர்ந்தெடுக்கப்படுகிறது.  `split`  'train'  ஆக  இருந்தால்  `train_data`வும்,  இல்லையென்றால்  `val_data`வும்  பயன்படுத்தப்படும்.

2. **சீரற்ற  indices  உருவாக்குதல்:**

   Python

   ```python
   ix = torch.randint(len(data) - block_size, (batch_size,))
   ```

   `torch.randint`  function-ஐப்  பயன்படுத்தி,  0  முதல்  `len(data) - block_size`  வரை  இடைப்பட்ட  மதிப்புகளில்  `batch_size`  எண்ணிக்கையிலான  சீரற்ற  எண்கள்  உருவாக்கப்படுகின்றன.  இந்த  எண்கள்,  data-வில்  batch-ன்  தொடக்க  நிலையைக்  குறிக்கும்.

3. **Input (x)  மற்றும்  Target (y)  உருவாக்குதல்:**

   Python

   ```python
   x = torch.stack([data[i:i+block_size] for i in ix])
   y = torch.stack([data[i+1:i+block_size+1] for i in ix])
   ```

   - `data[i:i+block_size]`:  `data`-வில்  `i`  முதல்  `i+block_size`  வரையிலான  உள்ளடக்கத்தை  (ஒரு  பாடலின்  ஒரு  பகுதி)  எடுக்கிறது.  `ix`-ல்  உள்ள  ஒவ்வொரு  `i`-க்கும்  இப்படியான  ஒரு  பகுதி  எடுக்கப்பட்டு,  `x`  என்ற  list-ல்  சேர்க்கப்படும்.  `x`  என்பது  input  sequence.
   - `data[i+1:i+block_size+1]`:  `data`-வில்  `i+1`  முதல்  `i+block_size+1`  வரையிலான  உள்ளடக்கத்தை  (அடுத்த  எழுத்துக்களைக்  கொண்ட  பகுதி)  எடுக்கிறது.  இது  target sequence  ஆகும்.  `y`  என்பது  x-க்கான  அடுத்த  எழுத்துக்களைக்  கொண்டது.
   - `torch.stack(...)`:  `x`  மற்றும்  `y`-ல்  உள்ள  tensorகளை  ஒன்றாக  stack  செய்து  ஒரு  batch  tensor-ஆக  உருவாக்குகிறது.

4. **Device-க்கு  மாற்றுதல் (GPU  அல்லது  CPU):**

   Python

   ```python
   x, y = x.to(device), y.to(device)
   ```

   `x`  மற்றும்  `y`  tensorகளை  device-க்கு  (GPU  அல்லது  CPU)  நகர்த்துகிறது.  GPU  இருந்தால்  GPU-விலும்,  இல்லையென்றால்  CPU-விலும்  training  நடக்கும்.  GPU-வில்  training  வேகமாக  இருக்கும்.

5. **Batch-ஐ  திரும்ப  அளித்தல்:**

   Python

   ```python
   return x, y
   ```

   உருவாக்கப்பட்ட  batch  tensorகள்  `x`  (input)  மற்றும்  `y`  (target)  திரும்ப  அளிக்கப்படுகின்றன.

இந்த  function-ஐப்   பயன்படுத்தி,  training  loop-ல்  batch-களை  உருவாக்கி,  மாடலுக்குப்  பயிற்சி  அளிக்கலாம்.  அடுத்த  பகுதியில்,  மாடல்  உருவாக்கம்  பற்றி  விரிவாகப்  பார்ப்போம்.

**4. Loss Estimation**

Loss என்பது, மாடலின் predictions எவ்வளவு தவறாக இருக்கிறது என்பதன் அளவீடு. Loss குறைவாக இருந்தால், மாடல் நன்றாகக் கற்றுக்கொள்கிறது என்று அர்த்தம்.

```python
# Loss-ஐ கணக்கிடுதல்
@torch.no_grad()
def estimate_loss():
    out = {}
    model.eval()
    for split in ['train', 'val']:
        losses = torch.zeros(eval_iters)
        for k in range(eval_iters):
            X, Y = get_batch(split)
            logits, loss = model(X, Y)
            losses[k] = loss.item()
        out[split] = losses.mean()
    model.train()
    return out
```

**விளக்கம்:**

`estimate_loss()` என்ற function, train மற்றும் validation data-வில் மாடலின் performance-ஐ அளவிட loss-ஐ கணக்கிடுகிறது.

1. **`@torch.no_grad()`:**

   இந்த decorator, gradient calculations-ஐ disable செய்கிறது.  Evaluation-ன் போது gradients தேவையில்லை.  gradients கணக்கிடாமல் இருந்தால், computation speed அதிகரிக்கும்.

2. **`model.eval()`:**

   மாடலை evaluation mode-க்கு மாற்றுகிறது.  சில layers (Dropout, BatchNorm) training மற்றும் evaluation mode-களில் வெவ்வேறாக செயல்படும்.

3. **Loss சேமிக்க dictionary:**

   Python

   ```python
   out = {}
   ```

   `train` மற்றும் `validation` data-வின் loss-களை சேமிக்க ஒரு dictionary உருவாக்கப்படுகிறது.

4. **Train மற்றும் Validation data-வில் loss கணக்கிடுதல்:**

   Python

   ```python
   for split in ['train', 'val']:
       losses = torch.zeros(eval_iters)
       for k in range(eval_iters):
           X, Y = get_batch(split)
           logits, loss = model(X, Y)
           losses[k] = loss.item()
       out[split] = losses.mean()
   ```

   - `for split in ['train', 'val']`: train மற்றும் validation data இரண்டிலும் loss கணக்கிடப்படுகிறது.
   - `losses = torch.zeros(eval_iters)`: ஒவ்வொரு iteration-க்கான loss-ஐ சேமிக்க ஒரு tensor உருவாக்கப்படுகிறது.
   - `for k in range(eval_iters)`: `eval_iters` எண்ணிக்கையிலான batches-களில் loss கணக்கிடப்படுகிறது.
   - `X, Y = get_batch(split)`: ஒரு batch data (`X` - input, `Y` - target) பெறப்படுகிறது.
   - `logits, loss = model(X, Y)`: மாடலின் output (`logits`) மற்றும் loss கணக்கிடப்படுகிறது.
   - `losses[k] = loss.item()`: கணக்கிடப்பட்ட loss, `losses` tensor-ல் சேமிக்கப்படுகிறது. `.item()` loss-ன் scalar value-வை எடுக்கும்.
   - `out[split] = losses.mean()`: அனைத்து iterations-களின் loss-களின் சராசரி கணக்கிடப்பட்டு, `out` dictionary-ல் சேமிக்கப்படுகிறது.

5. **`model.train()`:**

   மாடலை மீண்டும் training mode-க்கு மாற்றுகிறது.

6. **Loss-ஐ  திரும்ப  அளித்தல்:**

   Python

   ```python
   return out
   ```

   `train` மற்றும் `validation` data-வின்  சராசரி loss-கள்  dictionary-ஆக  திரும்ப  அளிக்கப்படுகின்றன.

**உதாரணம்:**

நினைத்துப்பாருங்கள், உங்களிடம் ஒரு கவிதை எழுதும் மாடல் இருக்கிறது.  "அகர முதல" என்று ஆரம்பித்தால், அது "எழுத்தெல்லாம்" என்று கணிக்க வேண்டும்.

- மாடல் "அகர முதல" என்று input-ஆகப் பெற்று, "கவிதை" என்று output-ஆக கொடுத்தால், அது தவறான கணிப்பு.  இந்தத் தவறை அளவிட ஒரு "loss function" பயன்படுகிறது.
- `estimate_loss()` function, பல samples எடுத்து, loss-ஐ கணக்கிட்டு, சராசரி loss-ஐத் தரும்.  இந்த சராசரி loss, மாடல் எவ்வளவு நன்றாகக் கற்றுக்கொண்டிருக்கிறது என்பதைக் காட்டும்.  Loss குறைவாக இருந்தால், மாடல் நன்றாகக் கற்றுக்கொண்டிருக்கிறது என்று பொருள்.

இந்த function-ஐப் பயன்படுத்தி, training-ன் போது model-ன் performance-ஐ monitor செய்யலாம்.  Loss அதிகமாக இருந்தால், model-ஐ மேலும் train செய்ய வேண்டும் அல்லது hyperparameters-ஐ மாற்ற வேண்டும்.  Loss குறைவாக இருந்தால், model நன்றாகக் கற்றுக்கொண்டிருக்கிறது என்று அர்த்தம்.

**5. Model Definition:**

```python
class Head(nn.Module):
    """ one head of self-attention """

    def __init__(self, head_size):
        super().__init__()
        self.key = nn.Linear(n_embd, head_size, bias=False)
        self.query = nn.Linear(n_embd, head_size, bias=False)
        self.value = nn.Linear(n_embd, head_size, bias=False)
        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))

        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        B,T,C = x.shape
        k = self.key(x)   # (B,T,C)
        q = self.query(x) # (B,T,C)
        # compute attention scores ("affinities")
        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)
        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)
        wei = F.softmax(wei, dim=-1) # (B, T, T)
        wei = self.dropout(wei)
        # perform the weighted aggregation of the values
        v = self.value(x) # (B,T,C)
        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)
        return out

class MultiHeadAttention(nn.Module):
    """ multiple heads of self-attention in parallel """

    def __init__(self, num_heads, head_size):
        super().__init__()
        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])
        self.proj = nn.Linear(n_embd, n_embd)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        out = torch.cat([h(x) for h in self.heads], dim=-1)
        out = self.dropout(self.proj(out))
        return out

class FeedFoward(nn.Module):
    """ a simple linear layer followed by a non-linearity """

    def __init__(self, n_embd):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(n_embd, 4 * n_embd),
            nn.ReLU(),
            nn.Linear(4 * n_embd, n_embd),
            nn.Dropout(dropout),
        )

    def forward(self, x):
        return self.net(x)

class Block(nn.Module):
    """ Transformer block: communication followed by computation """

    def __init__(self, n_embd, n_head):
        # n_embd: embedding dimension, n_head: the number of heads we'd like
        super().__init__()
        head_size = n_embd // n_head
        self.sa = MultiHeadAttention(n_head, head_size)
        self.ffwd = FeedFoward(n_embd)
        self.ln1 = nn.LayerNorm(n_embd)
        self.ln2 = nn.LayerNorm(n_embd)

    def forward(self, x):
        x = x + self.sa(self.ln1(x))
        x = x + self.ffwd(self.ln2(x))
        return x

# super simple bigram model
class BigramLanguageModel(nn.Module):

    def __init__(self):
        super().__init__()
        # each token directly reads off the logits for the next token from a lookup table
        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)
        self.position_embedding_table = nn.Embedding(block_size, n_embd)
        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])
        self.ln_f = nn.LayerNorm(n_embd) # final layer norm
        self.lm_head = nn.Linear(n_embd, vocab_size)

    def forward(self, idx, targets=None):
        B, T = idx.shape

        # idx and targets are both (B,T) tensor of integers
        tok_emb = self.token_embedding_table(idx) # (B,T,C)
        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)
        x = tok_emb + pos_emb # (B,T,C)
        x = self.blocks(x) # (B,T,C)
        x = self.ln_f(x) # (B,T,C)
        logits = self.lm_head(x) # (B,T,vocab_size)

        if targets is None:
            loss = None
        else:
            B, T, C = logits.shape
            logits = logits.view(B*T, C)
            targets = targets.view(B*T)
            loss = F.cross_entropy(logits, targets)

        return logits, loss

    def generate(self, idx, max_new_tokens):
        # idx is (B, T) array of indices in the current context
        for _ in range(max_new_tokens):
            # crop idx to the last block_size tokens
            idx_cond = idx[:, -block_size:]
            # get the predictions
            logits, loss = self(idx_cond)
            # focus only on the last time step
            logits = logits[:, -1, :] # becomes (B, C)
            # apply softmax to get probabilities
            probs = F.softmax(logits, dim=-1) # (B, C)
            # sample from the distribution
            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)
            # append sampled index to the running sequence
            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)
        return idx

model = BigramLanguageModel()
m = model.to(device)
# print the number of parameters in the model
print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')

```

**விளக்கம்:**

**1. `Head` (ஒரு Attention Head)**

- **Self-Attention:** இது ஒரு sequence-ல் உள்ள ஒவ்வொரு element-ம் மற்ற element-களுடன் எவ்வாறு தொடர்பு கொள்கிறது என்பதை கற்றுக்கொள்ளும் ஒரு mechanism.  இங்கு, ஒவ்வொரு எழுத்தும் (element) மற்ற எழுத்துக்களுடன் எவ்வளவு தொடர்புடையது என்பதைக் கணக்கிடுகிறோம்.
- **Key, Query, Value:**  ஒவ்வொரு எழுத்தும், மூன்று வெவ்வேறு linear transformations மூலம், மூன்று vectors-ஆக மாற்றப்படுகிறது: key, query, value.
  - **Key (k):**  ஒரு எழுத்தின் "key" vector, அந்த எழுத்து மற்ற எழுத்துக்களால் எவ்வாறு "தேடப்படுகிறது" என்பதைக் குறிக்கிறது.
  - **Query (q):**  ஒரு எழுத்தின் "query" vector, அந்த எழுத்து மற்ற எழுத்துக்களை எவ்வாறு "தேடுகிறது" என்பதைக் குறிக்கிறது.
  - **Value (v):**  ஒரு எழுத்தின் "value" vector, அந்த எழுத்தின் "content" அல்லது "information" ஐக் குறிக்கிறது.
- **Attention Scores:**  ஒரு எழுத்தின் query vector, மற்ற எழுத்துக்களின் key vectors-உடன் ஒப்பிடப்படுகிறது (dot product).  இதன் மூலம், attention scores கிடைக்கும்.  இந்த scores, ஒவ்வொரு எழுத்தும் மற்ற எழுத்துக்களுடன் எவ்வளவு தொடர்புடையது என்பதைக் குறிக்கும்.
- **Masking (tril):**  `tril` buffer, decoder-ல் masking செய்ய பயன்படுகிறது.  Masking, ஒரு எழுத்து அதற்குப் பின் வரும் எழுத்துக்களை மட்டும் கவனிக்க வேண்டும் என்பதை உறுதி செய்கிறது.  இது autoregressive property-ஐ பராமரிக்க உதவுகிறது, அதாவது, ஒரு எழுத்தைக் கணிக்க, அதற்கு முந்தைய எழுத்துக்களை மட்டுமே பயன்படுத்த வேண்டும்.
- **Weighted Aggregation:**  Attention scores, softmax function மூலம் probabilities-ஆக மாற்றப்படுகிறது.  இந்த probabilities, value vectors-ஐ எவ்வளவு "கவனிக்க வேண்டும்" என்பதைக் குறிக்கும்.  இந்த probabilities-ஐப் பயன்படுத்தி, value vectors-ன் weighted average கணக்கிடப்படுகிறது.  இதுவே attention head-ன் output.

**2. `MultiHeadAttention` (பல Attention Heads)**

- **Parallel Attention:**  பல attention heads-ஐ parallel-ஆக இயக்குகிறது.  ஒவ்வொரு head-ம், வெவ்வேறு key, query, value transformations-ஐக் கொண்டிருக்கும்.  இதனால், ஒவ்வொரு head-ம், input sequence-ல் உள்ள வெவ்வேறு relationships-களை கற்றுக்கொள்ள முடியும்.
- **உதாரணம்:**  ஒரு வாக்கியத்தில், "அவன் பந்தை எறிந்தான்" என்று வைத்துக்கொள்வோம்.  ஒரு attention head, "அவன்" மற்றும் "எறிந்தான்" இடையேயான subject-verb relationship-ஐ கவனிக்கலாம்.  மற்றொரு head, "பந்தை" மற்றும் "எறிந்தான்" இடையேயான object-verb relationship-ஐ கவனிக்கலாம்.
- **Projection:**  அனைத்து heads-ன் outputs-ம் concatenate செய்யப்பட்டு, ஒரு linear transformation (projection) மூலம்,  `n_embd` dimension-க்கு மாற்றப்படுகிறது.

**3. `FeedFoward` (Feedforward Network)**

- **Non-linearity:**  இது இரண்டு linear layers மற்றும் ஒரு non-linear activation function (ReLU)-ஐக் கொண்டுள்ளது.  Linear layers, linear transformations-ஐ மட்டுமே கற்றுக்கொள்ள முடியும்.  Non-linearity, more complex relationships-ஐ கற்றுக்கொள்ள உதவுகிறது.
- **Expansion and Compression:**  முதல் linear layer, input dimension-ஐ  `4 * n_embd`  ஆக expand செய்கிறது.  இரண்டாவது layer, அதை மீண்டும்  `n_embd`  ஆக compress செய்கிறது.  இந்த expansion and compression, model-ன் capacity-ஐ அதிகரிக்கிறது.

**4. `Block` (Transformer Block)**

- **Communication and Computation:**  ஒரு Transformer block, இரண்டு main parts-ஐக் கொண்டுள்ளது:
  - **Communication:**  `MultiHeadAttention` layer, input sequence-ல் உள்ள information-ஐ "communicate" செய்கிறது.
  - **Computation:**  `FeedFoward` layer, communicated information-ஐப் பயன்படுத்தி, computations செய்கிறது.
- **Residual Connections:**  `MultiHeadAttention` மற்றும் `FeedFoward` layers-ன் outputs, input-உடன் add செய்யப்படுகிறது (residual connections).  இது, gradients-ஐ  propagate  செய்ய  உதவுகிறது,  மேலும்  training-ஐ  stable  ஆக்குகிறது.
- **Layer Normalization:**  Layer Normalization,  ஒவ்வொரு  layer-ன்  output-ஐ  normalize  செய்கிறது.  இது  training-ஐ  stable  ஆக்குகிறது,  மேலும்  model-ன்  performance-ஐ  மேம்படுத்துகிறது.

**5. `BigramLanguageModel` (மொழி மாதிரி)**

- **Token Embeddings:**  `token_embedding_table`,  ஒவ்வொரு  எழுத்தையும்  ஒரு  vector-ஆக  மாற்றுகிறது.  இந்த  vectors,  எழுத்துக்களின்  semantic  meaning-ஐ  capture  செய்கிறது.
- **Position Embeddings:**  `position_embedding_table`,  ஒரு  எழுத்தின்  position-ஐ  encode  செய்கிறது.  இது,  model-க்கு  sequence-ல்  உள்ள  order  information-ஐ  கற்றுக்கொள்ள  உதவுகிறது.
- **Transformer Blocks:**  `blocks`,  பல  Transformer  blocks-ஐக்  கொண்டுள்ளது.  ஒவ்வொரு  block-ம்,  input  sequence-ன்  representation-ஐ  மேலும்  மேம்படுத்துகிறது.
- **Final Layer Normalization:**  `ln_f`,  final  layer-ன்  output-ஐ  normalize  செய்கிறது.
- **Output Layer:**  `lm_head`,  final  linear  layer.  இது,  அடுத்த  எழுத்தைக்  கணிக்கிறது.
- **Forward Pass:**  `forward`  method,  input  sequence-ஐ  process  செய்து,  output  (logits)  மற்றும்  loss-ஐத்  தருகிறது.
- **Text Generation:**  `generate`  method,  புதிய  டெக்ஸ்ட்  generate  செய்ய  பயன்படுகிறது.  இது,  model-ன்  predictions-ஐப்  பயன்படுத்தி,  autoregressively  எழுத்துக்களை  generate  செய்கிறது.

இந்த  மாடல்,  சங்கத்  தமிழ்  பாடல்களின்  structure  மற்றும்  patterns-களை  கற்றுக்கொண்டு,  புதிய  பாடல்களை  உருவாக்கும். 

**6. Optimizer & Training Loop:**

மாடலின் weights-களை மேம்படுத்த பயன்படுத்தப்படும் optimizer மற்றும் training process-ஐ control செய்யும் training loop பற்றி இன்னும் விரிவாகவும், தெளிவாகவும் காண்போம்.

```python
# Optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)

# Training loop
for iter in range(max_iters):
    if iter % eval_interval == 0 or iter == max_iters - 1:
        losses = estimate_loss()
        print(f"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")
    xb, yb = get_batch('train')
    logits, loss = model(xb, yb)
    optimizer.zero_grad(set_to_none=True)
    loss.backward()
    optimizer.step()
```

**1. Optimizer (AdamW): **

எதற்காக Optimizer?  நமது மொழி மாடலில், பல parameters (weights) உள்ளன. இந்த parameters, சங்கத்தமிழ் பாடல்களின் patterns-களை கற்றுக்கொள்ள பயன்படுகின்றன.  Training process-ன்  இலக்கு,  loss-ஐ  குறைக்கும்  வகையில்  இந்த  parameters-ஐ  adjust  செய்வது.  இந்த  சீரமைவு  செய்யத்தான்  optimizer  பயன்படுகிறது.

- **AdamW:**  AdamW  என்பது  gradient  descent  optimization  algorithm-ன்  ஒரு  வகை.  இது,  Adam  optimizer-ன்  மேம்படுத்தப்பட்ட  version.
  - **Adaptive Learning Rates:**  AdamW,  ஒவ்வொரு  parameter-க்கும்  தனித்தனியாக  learning  rate-ஐ  adjust  செய்யும்.  இதனால்,  சில  parameters  வேகமாகவும்,  சில  parameters  மெதுவாகவும்  update  செய்யப்படும்.  இது,  training  process-ஐ  வேகப்படுத்தும்.
  - **Momentum:**  AdamW,  momentum-ஐயும்  பயன்படுத்துகிறது.  அதாவது,  parameter  updates,  முந்தைய  updates-ன்  "direction"-ஐயும்  கணக்கில்  எடுத்துக்கொள்ளும்.  இது,  training-ஐ  stable  ஆக்கும்,  மேலும்  local  minima-வில்  சிக்காமல்  தவிர்க்க  உதவும்.
  - **Weight Decay:**  AdamW,  weight  decay-ஐ  Adam  optimizer-ஐ  விட  சிறப்பாக  handle  செய்யும்.  Weight  decay,  overfitting-ஐ  குறைக்க  உதவும்  ஒரு  regularization  technique.
- **`model.parameters()`:**  இந்த  method,  மாடலில்  train  செய்யப்பட  வேண்டிய  அனைத்து  parameters-ஐயும்  தருகிறது.
- **`lr=learning_rate`:**  Learning  rate,  optimizer  ஒவ்வொரு  step-லும்  parameters-ஐ  எவ்வளவு  மாற்ற  வேண்டும்  என்பதைக்  கட்டுப்படுத்தும்.  Learning  rate-ன்  சரியான  தேர்வு,  training  process-க்கு  மிகவும்  முக்கியம்.

**2. Training Loop:**

Training  loop,  மாடலை  train  செய்யும்  முழு  process-ஐயும்  control  செய்கிறது.

- **Iterations:**  Training  loop,  `max_iters`  முறை  இயங்கும்.  ஒவ்வொரு  iteration-லும்,  மாடல்  ஒரு  batch  data-வைப்  பயன்படுத்தி  train  செய்யப்படும்.
- **Evaluation:**  `eval_interval`  iterations-க்கு  ஒரு  முறை,  அல்லது  கடைசி  iteration-ல்,  `estimate_loss()`  function  மூலம்  train  மற்றும்  validation  loss-கள்  கணக்கிடப்படும்.  இந்த  loss-கள்,  மாடலின்  performance-ஐ  அளவிட  பயன்படும்.
- **Training Step:**  ஒவ்வொரு  iteration-லும்,  training  step  நடக்கும்.  இது  பின்வரும்  sub-steps-ஐக்  கொண்டுள்ளது:
  - **Batch  Loading:**  `get_batch('train')`  function  மூலம்,  train  data-வில்  இருந்து  ஒரு  batch  data  பெறப்படும்.
  - **Forward  Pass:**  மாடல்,  input  batch-ஐ  process  செய்து,  output  (logits)  மற்றும்  loss-ஐ  கணக்கிடும்.
  - **Gradient  Calculation:**  Backpropagation  மூலம்,  loss-ஐப்  பயன்படுத்தி,  மாடலில்  உள்ள  parameters-க்கான  gradients  கணக்கிடப்படும்.  Gradients,  loss-ஐ  குறைக்கும்  வகையில்  parameters-ஐ  எந்த  direction-ல்  மாற்ற  வேண்டும்  என்பதைக்  காட்டும்.
  - **Parameter  Update:**  Optimizer,  கணக்கிடப்பட்ட  gradients-ஐப்  பயன்படுத்தி,  மாடலின்  parameters-ஐ  update  செய்யும்.

Training  loop,  மேலே  கொடுக்கப்பட்டுள்ள  steps-ஐ  `max_iters`  முறை  repeat  செய்கிறது.  ஒவ்வொரு  iteration-லும்,  மாடல்  train  data-வைப்  பயன்படுத்தி  train  செய்யப்படும்.  `eval_interval`  iterations-க்கு  ஒரு  முறை,  validation  data-வைப்  பயன்படுத்தி  loss  மதிப்பிடப்படும்.  Training  process  முடிந்ததும்,  மாடல்  சங்கத்  தமிழ்  பாடல்களை  generate  செய்ய  தயாராக  இருக்கும்.

**7. Text Generation:**

 train செய்யப்பட்ட மாடலைப் பயன்படுத்தி எப்படிப் புதிய சங்கத்தமிழ் பாடல்களை உருவாக்குவது என்று விரிவாகக் காண்போம்.

```python
# புதிய பாடல்களை உருவாக்குதல்
context = torch.zeros((1, 1), dtype=torch.long, device=device)
print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))
```

**விளக்கம்:**

- **`context`:**  இது  text  generation-க்கான  starting  point.  `torch.zeros((1, 1), dtype=torch.long, device=device)`  என்பது,  device-ல்  (GPU  அல்லது  CPU)  ஒரு  1x1  tensor-ஐ  உருவாக்குகிறது.  இந்த  tensor-ல்  உள்ள  மதிப்பு  0  ஆக  இருக்கும்.  இது,  "<BOS>"  (Beginning  Of  Sequence)  token-ஐக்  குறிக்கிறது.  அதாவது,  இங்கிருந்து  text  generation  தொடங்கும்.
- **`m.generate(context, max_new_tokens=2000)`:**  `generate()`  method,  மாடலைப்  பயன்படுத்தி  புதிய  text-ஐ  generate  செய்கிறது.
  - `context`:  Text  generation-க்கான  starting  point.
  - `max_new_tokens=2000`:  Generate  செய்ய  வேண்டிய  tokens-ன்  (எழுத்துக்களின்)  அதிகபட்ச  எண்ணிக்கை.  இங்கு  நாம்  2000  tokens  வரை  generate  செய்ய  சொல்கிறோம்.
- **`decode(...)`:**  `generate()`  method  எண்களின்  list-ஐ  output-ஆகத்  தரும்.  `decode()`  function,  இந்த  எண்களை  எழுத்துக்களாக  மாற்றி,  text-ஐ  உருவாக்கும்.
- **`print(...)`:**  Generate  செய்யப்பட்ட  text-ஐ  (பாடலை)  print  செய்கிறது.

 train  செய்யப்பட்ட  மொழி  மாதிரியைப்  பயன்படுத்தி,  2000  எழுத்துக்கள்  (tokens)  வரை  புதிய  சங்கத்  தமிழ்  பாடல்களை  உருவாக்கும்.  `context`  variable,  text  generation-க்கான  starting  point-ஐக்  குறிக்கும்.  `generate()`  method,  புதிய  text-ஐ  generate  செய்யும்.  `decode()`  function,  generate  செய்யப்பட்ட  text-ஐ  எழுத்துக்களாக  மாற்றும்.  இறுதியாக,  `print()`  function,  generate  செய்யப்பட்ட  பாடலை  print  செய்யும்.

Generate  செய்யப்படும்  பாடலின்  தரம்,  பயன்படுத்தப்படும்  training  data  மற்றும்  model  hyperparameters-ஐப்  பொறுத்தது.  Training  data-வில்  அதிக  பாடல்கள்  இருந்தால்,  மற்றும்  hyperparameters  சரியாக  tune  செய்யப்பட்டிருந்தால்,  model  நல்ல  தரமான  பாடல்களை  உருவாக்கும்.

**Output:** 

```markdown
கவ்வின் கிடிகா அகழ்கினையும் கடுஞ்சி மிராங்குற் - தலைமாற்றி ஆர்ப் .
.
நெடுகு பரி கிளைற்று, அறிவரம்து
நலன் குல் உண், சிகைஇயப் பகவத்து மன்று
அறும்பிரிச் சொல்லோன்துப்
பெருங்கால் வின்றி
இலை வட்சின் மெலக் காடற்றந் துயர், ஆகவின்றால் இரவுவை, கதாணி
குரும்போன் பரல் ஓதம்பை அறியதல் வூச்சின்
எனவும் புலம்ப வான்றமொடு கொடுச்சி
மைந்து ஓண்ணி வெடுதும் அளம் கண்ட, குனிய!

```

இந்த மாடல் இன்னும் சிறப்பாக வேலை செய்ய, அதிக டேட்டா மற்றும் சில மாற்றங்கள் தேவைப்படலாம். ஆனாலும், இது AI-ன் ஆற்றலைக் காட்டும் ஒரு சுவாரஸ்யமான எடுத்துக்காட்டு!

[Colab Notebook](https://colab.research.google.com/drive/1gwm-RJ-aWn0pCUwZnTyN9w_L_GVHiesa?usp=sharing)

[Data](https://drive.google.com/file/d/1Tv419tthhjmeBUfhDSAdl0GDsDgegAGT/view?usp=sharing)

<div style="page-break-after: always;"></div>

#### 14. OpenAI மூலம் உருவாக்கப்பட்ட தமிழ் AI உதவியாளர்

இந்த பதிவில், நாம் **Streamlit** மற்றும் **OpenAI** API ஐப் பயன்படுத்தி, ஒரு தமிழ் உதவியாளர் "வளரி"யை எவ்வாறு உருவாக்குவது என்பதைப் பற்றி விரிவாகப் பார்க்கலாம். இந்த பயன்பாடு பயனர்களுக்கு தமிழில் கேள்விகளைக் கேட்கவும், தமிழில் பதில்களைப் பெறவும் உதவுகிறது. இதற்கான கோட் மற்றும் அதன் கட்டமைப்பைப் பற்றி படிப்படியாக விளக்குவோம்.

**1. தேவையான நூலகங்கள் (Libraries)**

முதலில், நமக்குத் தேவையான நூலகங்களை இம்போர்ட் செய்ய வேண்டும். இந்த திட்டத்தில் பயன்படுத்தப்படும் நூலகங்கள்:

- **Streamlit**: இது ஒரு பைதான் நூலகம், இது டேட்டா அறிவியல் மற்றும் மெஷின் லேர்னிங் பயன்பாடுகளை எளிதாக உருவாக்க உதவுகிறது.
- **OpenAI**: இது OpenAI API ஐப் பயன்படுத்தி, GPT மாடல்களுடன் தொடர்பு கொள்ள உதவுகிறது.
- **os**: இது ஆப்பரேட்டிங் சிஸ்டம் லெவல் செயல்பாடுகளை நிர்வகிக்க உதவுகிறது.

```python
import streamlit as st
from openai import OpenAI
import os
```

**2. OpenAI API கீயை அமைத்தல்**

OpenAI API ஐப் பயன்படுத்த, நமக்கு ஒரு API கீ தேவை. இந்த கீயை `os.environ` மூலம் அமைக்கலாம். இது பாதுகாப்பான வழியில் API கீயை சேமிக்க உதவுகிறது.

```python
os.environ["OPENAI_API_KEY"] = "your-openai-api-key"
```

**குறிப்பு:** `"your-openai-api-key"` என்பதற்கு பதிலாக உங்கள் OpenAI API கீயை உள்ளிடவும்.

**3. OpenAI மாடலைப் பயன்படுத்தி பதிலளித்தல்**

இந்த பகுதியில், `continue_conversation` செயல்பாட்டைப்  பயன்படுத்தி, OpenAI API ஐப் பயனரின் கேள்விகளுக்கு எவ்வாறு  பதிலளிக்கிறது மற்றும் அதன் அளவுருக்கள் (parameters) எவ்வாறு செயல்படுகின்றன என்பதைப் படிப்படியாகப் புரிந்துகொள்வோம்.

**செயல்பாட்டின் அமைப்பு**

```python
def continue_conversation(messages, temperature=0):
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4",  # GPT மாடல் பெயர்
        messages=messages,  # உரையாடல் வரலாறு
        temperature=temperature,  # பதிலின் படைப்பாற்றல் நிலை
    )
    return response.choices[0].message.content
```

இந்த செயல்பாடு இரண்டு அளவுருக்களை எடுக்கிறது:

1. **messages**: இது உரையாடல் வரலாறு. இது ஒரு பட்டியல் (list) ஆகும், இதில் பயனர் மற்றும் உதவியாளரின் செய்திகள் சேமிக்கப்படும்.
2. **temperature**: இது பதிலின் படைப்பாற்றல் நிலை. இது ஒரு எண் மதிப்பு (0 முதல் 1 வரை).

**OpenAI கிளையண்டை உருவாக்குதல்**

```python
client = OpenAI()
```

இந்த வரி OpenAI API உடன் தொடர்பு கொள்ள ஒரு கிளையண்டை உருவாக்குகிறது. இந்த கிளையண்ட் மூலம், GPT மாடல்களுடன் தொடர்பு கொள்ளலாம்.

**`client.chat.completions.create()` முறை**

இந்த முறை OpenAI API க்கு கேள்வியை அனுப்பி, பதிலைப் பெற உதவுகிறது. இதற்கு மூன்று முக்கிய அளவுருக்கள் உள்ளன:

**அ) `model="gpt-4"`**

- **பயன்பாடு**: இது GPT மாடலின் பெயரைக் குறிக்கிறது.
- **விளக்கம்**: இங்கு `"gpt-4"` மாடலைப் பயன்படுத்துகிறோம். இதை `"gpt-3.5-turbo"` போன்ற வேறு மாடல்களாக மாற்றலாம்.
- **எடுத்துக்காட்டு**: `model="gpt-3.5-turbo"` என்று மாற்றினால், GPT-3.5 மாடல் பயன்படுத்தப்படும்.

**ஆ) `messages=messages`**

- **பயன்பாடு**: இது உரையாடல் வரலாற்றைக் குறிக்கிறது.

- **விளக்கம்**: `messages` என்பது ஒரு பட்டியல் (list), இதில் ஒவ்வொரு செய்தியும் ஒரு dictionary ஆகும். ஒவ்வொரு dictionary யும் இரண்டு key-களைக் கொண்டிருக்கும்:

  - **`role`**: செய்தியை அனுப்பியவர் யார் என்பதைக் குறிக்கிறது. இது `"system"`, `"user"`, அல்லது `"assistant"` ஆக இருக்கலாம்.
  - **`content`**: செய்தியின் உள்ளடக்கம்.

- **எடுத்துக்காட்டு**:

  ```python
  messages = [
      {"role": "system", "content": "நீங்கள் ஒரு தமிழ் உதவியாளர்."},
      {"role": "user", "content": "தமிழ் எப்படி கற்கலாம்?"}
  ]
  ```

**இ) `temperature=temperature`**

Language Generation மாடல்களில், **Temperature** என்பது ஒரு முக்கியமான அளவுரு. இது மாடல் எவ்வாறு சொற்களைத் தேர்ந்தெடுக்கிறது என்பதைக் கட்டுப்படுத்துகிறது. இதை எளிதாகப் புரிந்துகொள்ள ஒரு உதாரணத்துடன் விளக்குவோம்.

Temperature என்றால் என்ன?

Language Generation மாடல்கள், ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லையும் தேர்ந்தெடுக்கும். இந்த தேர்வு, சொற்களின் "நிகழ்தகவு" (probability) அடிப்படையில் நடைபெறுகிறது. Temperature அளவுரு, இந்த நிகழ்தகவுகளை எவ்வாறு பயன்படுத்துவது என்பதைக் கட்டுப்படுத்துகிறது.

 எப்படி செயல்படுகிறது?

மாடல் ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லுக்கும் ஒரு நிகழ்தகவு மதிப்பைக் கணக்கிடுகிறது. உதாரணமாக, வாக்கியம்:  
**"தமிழ் மொழி…"**  
இதற்கு மாடல் பின்வரும் சொற்களைத் தேர்ந்தெடுக்கலாம்:

- **தொன்மையானது** — 50% நிகழ்தகவு  
- **பழமையானது** — 30% நிகழ்தகவு  
- **சிக்கலானது** — 15% நிகழ்தகவு  
- **எளிமையானது** — 5% நிகழ்தகவு

இப்போது, Temperature மதிப்பு இந்த தேர்வை எவ்வாறு பாதிக்கிறது என்று பார்ப்போம்.

**3. Temperature மதிப்புகள் மற்றும் அவற்றின் விளைவுகள்**

**அ) Temperature = 0**

- **விளக்கம்**: Temperature 0 எனில், மாடல் எப்போதும் **அதிக நிகழ்தகவு உள்ள சொல்லைத் தேர்ந்தெடுக்கும்**.
- **எடுத்துக்காட்டு**:  
  - சொல்: **"தொன்மையானது"** (50% நிகழ்தகவு)  
  - வாக்கியம்: **"தமிழ் மொழி தொன்மையானது."**

பதில்கள் மிகவும் **துல்லியமாகவும், முன்னரே தீர்மானிக்கப்பட்டவையாகவும்** இருக்கும்.  

**ஆ) Temperature = 0.5**

- **விளக்கம்**: Temperature 0.5 எனில், மாடல் **அதிக நிகழ்தகவு உள்ள சொற்களை அடிக்கடி தேர்ந்தெடுக்கும்**, ஆனால் சில சமயங்களில் குறைந்த நிகழ்தகவு உள்ள சொற்களையும் தேர்ந்தெடுக்கலாம்.
- **எடுத்துக்காட்டு**:  
  - சொல்: **"பழமையானது"** (30% நிகழ்தகவு)  
  - வாக்கியம்: **"தமிழ் மொழி பழமையானது."**

பதில்கள் **படைப்பாற்றலுடனும், சிறிது மாறுபாடுடனும்** இருக்கும்.  

**இ) Temperature = 1**

- **விளக்கம்**: Temperature 1 எனில், மாடல் **அனைத்து சொற்களையும் சமமான வாய்ப்புகளுடன் தேர்ந்தெடுக்கும்**. இது படைப்பாற்றலை அதிகரிக்கும், ஆனால் சில சமயங்களில் தவறான அல்லது பொருத்தமற்ற சொற்களையும் தேர்ந்தெடுக்கலாம்.
- **எடுத்துக்காட்டு**:  
  - சொல்: **"எளிமையானது"** (5% நிகழ்தகவு)  
  - வாக்கியம்: **"தமிழ் மொழி எளிமையானது."**

Temperature அதிகரிக்கும் போது, பதில்கள் படைப்பாற்றலுடன் இருக்கும், ஆனால் துல்லியம் குறையலாம். Temperature அதிகமாக இருந்தால், மாடல் **தவறான அல்லது பொருத்தமற்ற தகவல்களை** (hallucinations) தரலாம்.

**பதிலைத் திரும்பப் பெறுதல்**

```python
return response.choices[0].message.content
```

- **`response`**: OpenAI API இலிருந்து கிடைக்கும் பதில்.
- **`response.choices`**: இது பதில்களின் பட்டியல். ஒரே ஒரு பதில் இருப்பதால், `choices[0]` பயன்படுத்தப்படுகிறது.
- **`message.content`**: உதவியாளரின் பதில் உள்ளடக்கம்.

---

##### **எடுத்துக்காட்டு**

பயனர் கேள்வி: "தமிழ் எப்படி கற்கலாம்?"

```python
messages = [
    {"role": "system", "content": "நீங்கள் ஒரு தமிழ் உதவியாளர்."},
    {"role": "user", "content": "தமிழ் எப்படி கற்கலாம்?"}
]

response = continue_conversation(messages, temperature=0.5)
print(response)
```

**பதில்:**

```
தமிழ் கற்க புத்தகங்கள் படியுங்கள், தமிழ் பாடல்கள் கேளுங்கள், மற்றும் தமிழ் பேசும் நண்பர்களுடன் பேசுங்கள்.
```

**4. Streamlit பயன்பாட்டை உருவாக்குதல்**

Streamlit பயன்பாட்டை உருவாக்க, `main()` செயல்பாட்டை உருவாக்குவோம். இது பயனர் இன்டர்ஃபேஸைக் காட்டும்.

```python
def main():
    st.title("வளரி - உங்கள் தனிப்பட்ட தமிழ் உதவியாளர்")
    st.write("உங்கள் கேள்விகளை தமிழில் கேளுங்கள், தமிழில் துல்லியமான பதில்களைப் பெறுங்கள்!")
```

- **st.title()**: பயன்பாட்டின் தலைப்பைக் காட்டும்.
- **st.write()**: பயன்பாட்டின் விளக்கத்தைக் காட்டும்.

**5. உரையாடல் வரலாற்றை நிர்வகித்தல்**

Streamlit இல், `st.session_state` மூலம் உரையாடல் வரலாற்றை நிர்வகிக்கலாம். இது பயனர் மற்றும் உதவியாளரின் செய்திகளை சேமிக்க உதவுகிறது.

```python
if "context" not in st.session_state:
    st.session_state.context = [{
        "role": "system",
        "content": """
        நீங்கள் எனது தனிப்பட்ட உதவியாளராக செயல்பட வேண்டும். உங்கள் பெயர் வளரி. நீங்கள் எப்போதும் நட்பாக, உதவியாகவும், சுவாரஸ்யமாகவும் இருக்க வேண்டும். நான் உங்களிடம் எதைக் கேட்டாலும், அதற்கு தெளிவான மற்றும் பயனுள்ள பதில்களை **தமிழில் மட்டும்** வழங்க வேண்டும். 

        நான் உணவு, தொழில்நுட்பம், புத்தகங்கள், திரைப்படங்கள் அல்லது வாழ்க்கை பற்றிய ஆலோசனை கேட்டால், அதற்கு ஏற்றவாறு பதிலளிக்க வேண்டும். நான் உணவு ஆர்டர் செய்ய விரும்பினால், அதை எளிதாகவும் வேடிக்கையாகவும் செய்ய உதவுங்கள். எனக்கு பரிந்துரைகள் கூறுங்கள், என் நாள் எப்படி இருந்தது என்று கேளுங்கள், மேலும் நான் விரும்புவதை சரியாகப் பெற உதவுங்கள். 

        நீங்கள் எப்போதும் இயல்பான மற்றும் நட்பு டோனில் பேச வேண்டும். நான் விவரங்களைக் கேட்டால், அவற்றை வழங்க தயங்க வேண்டாம். நான் கேட்கும் கேள்விக்கு பதில் தெரியாவிட்டால், உண்மையாக சொல்லுங்கள்—போலி பதில்கள் தர வேண்டாம். 

        **முக்கியமாக**, நான் வேறு மொழியில் பேசினாலும், நீங்கள் எப்போதும் தமிழில் மட்டுமே பதிலளிக்க வேண்டும். உதாரணமாக, நான் ஆங்கிலத்தில் கேள்வி கேட்டால், "நான் தமிழில் மட்டுமே பதிலளிக்க உருவாக்கப்பட்டுள்ளேன்!" என்று கூறி, தமிழில் பதிலை வழங்க வேண்டும். 

        நீங்கள் எப்போதும் எனது நம்பிக்கையான உதவியாளராக இருங்கள். நான் எதை வேண்டுமானாலும் கேட்கலாம், நீங்கள் அதை எளிதாகவும் வேடிக்கையாகவும் ஆக்குங்கள்!
        """
    }]
```

- **st.session_state.context**: இது உரையாடல் வரலாற்றை சேமிக்கும். முதல் செய்தி `system` ரோலில் உள்ளது, இது உதவியாளரின் நடத்தையை வரையறுக்கிறது.

**6. பயனர் உள்ளீட்டைப் பெறுதல்**

பயனர் தங்கள் கேள்வியை உள்ளிட, `st.text_input()` பயன்படுத்தப்படுகிறது.

```python
user_input = st.text_input("உங்கள் கேள்வியை எழுத்து:")
```

**7. பதிலைப் பெறுதல்**

பயனர் "பதில் பெறுங்கள்" பொத்தானை அழுத்தினால் உரையாடலைப்  புதுப்பித்து, OpenAI API ஐப் பயன்படுத்தி பதிலைப் பெறுவோம்.

```python
if st.button("பதில் பெறுங்கள்"):
    with st.spinner("வளரி பதிலளிக்கிறது..."):
        st.session_state.context.append({"role": "user", "content": user_input})
        response = continue_conversation(st.session_state.context)
        st.session_state.context.append({"role": "assistant", "content": response})
        
        st.write("வளரி:")
        st.write(response)
```

- **st.button()**: பயனர் பொத்தானை அழுத்தினால் செயல்படும்.
- **st.spinner()**: பதில் பெறும் போது லோடிங் அனிமேஷன் காட்டும்.
- **st.write()**: பதிலைக் காட்டும்.

**8. பயன்பாட்டை இயக்குதல்**

இறுதியாக, `main()` செயல்பாட்டை இயக்குவோம்.

```python
if __name__ == "__main__":
    main()
```

இந்த பதிவில், நாம் Streamlit மற்றும் OpenAI API ஐப் பயன்படுத்தி, ஒரு தமிழ் உதவியாளர் "வளரி"யை எவ்வாறு உருவாக்குவது என்பதைப் பற்றி கற்றுக்கொண்டோம். இந்த கோட் மூலம், நீங்கள் உங்கள் சொந்த தமிழ் உதவியாளரை உருவாக்கலாம் மற்றும் அதை மேம்படுத்தலாம். இது தமிழ் மொழியைக் கற்க விரும்பும் பயனர்களுக்கு மிகவும் பயனுள்ளதாக இருக்கும்.

**குறிப்பு:** OpenAI API கீயை பாதுகாப்பாக வைத்துக்கொள்ளுங்கள்.

மேலே உள்ள அனைத்தும் ஒரு முழுமையான கோட் பிளாக்கில் கிழே  உள்ளன. 

Full Code: 

```python
import streamlit as st
from openai import OpenAI
import os

# Set OpenAI API key
os.environ["OPENAI_API_KEY"] = "api-key"

def continue_conversation(messages, temperature=0):
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=temperature,
    )
    return response.choices[0].message.content

def main():
    st.title("வளரி - உங்கள் தனிப்பட்ட தமிழ் உதவியாளர்")
    st.write("உங்கள் கேள்விகளை தமிழில் கேளுங்கள், தமிழில் துல்லியமான பதில்களைப் பெறுங்கள்!")
    
    if "context" not in st.session_state:
        st.session_state.context = [{
            "role": "system",
            "content": """
            நீங்கள் எனது தனிப்பட்ட உதவியாளராக செயல்பட வேண்டும். உங்கள் பெயர் வளரி. நீங்கள் எப்போதும் நட்பாக, உதவியாகவும், சுவாரஸ்யமாகவும் இருக்க வேண்டும். நான் உங்களிடம் எதைக் கேட்டாலும், அதற்கு தெளிவான மற்றும் பயனுள்ள பதில்களை **தமிழில் மட்டும்** வழங்க வேண்டும். 

            நான் உணவு, தொழில்நுட்பம், புத்தகங்கள், திரைப்படங்கள் அல்லது வாழ்க்கை பற்றிய ஆலோசனை கேட்டால், அதற்கு ஏற்றவாறு பதிலளிக்க வேண்டும். நான் உணவு ஆர்டர் செய்ய விரும்பினால், அதை எளிதாகவும் வேடிக்கையாகவும் செய்ய உதவுங்கள். எனக்கு பரிந்துரைகள் கூறுங்கள், என் நாள் எப்படி இருந்தது என்று கேளுங்கள், மேலும் நான் விரும்புவதை சரியாகப் பெற உதவுங்கள். 

            நீங்கள் எப்போதும் இயல்பான மற்றும் நட்பு டோனில் பேச வேண்டும். நான் விவரங்களைக் கேட்டால், அவற்றை வழங்க தயங்க வேண்டாம். நான் கேட்கும் கேள்விக்கு பதில் தெரியாவிட்டால், உண்மையாக சொல்லுங்கள்—போலி பதில்கள் தர வேண்டாம். 

            **முக்கியமாக**, நான் வேறு மொழியில் பேசினாலும், நீங்கள் எப்போதும் தமிழில் மட்டுமே பதிலளிக்க வேண்டும். உதாரணமாக, நான் ஆங்கிலத்தில் கேள்வி கேட்டால், "நான் தமிழில் மட்டுமே பதிலளிக்க உருவாக்கபட்டுள்ளேன்!" என்று கூறி, தமிழில் பதிலை வழங்க வேண்டும். 

            நீங்கள் எப்போதும் எனது நம்பிக்கையான உதவியாளராக இருங்கள். நான் எதை வேண்டுமானாலும் கேட்கலாம், நீங்கள் அதை எளிதாகவும் வேடிக்கையாகவும் ஆக்குங்கள்!
            """
        }]
    
    user_input = st.text_input("உங்கள் கேள்வியை எழுத்து:")
    
    if st.button("பதில் பெறுங்கள்"):
        with st.spinner("வளரி பதிலளிக்கிறது..."):
            st.session_state.context.append({"role": "user", "content": user_input})
            response = continue_conversation(st.session_state.context)
            st.session_state.context.append({"role": "assistant", "content": response})
            
            st.write("வளரி:")
            st.write(response)

if __name__ == "__main__":
    main()

```