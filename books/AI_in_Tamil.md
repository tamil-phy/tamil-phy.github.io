[toc]

<hr class="pagebreak">

# கருத்தாக்கமும் நடைமுறையும்

### 1. செயற்கை நுண்ணறிவின் (AI) வரலாறும் அடிப்படைகளும்

##### 1.1. செய்யறிவின் வரலாறு  

மனிதர்கள் பல நூற்றாண்டுகளாக எவ்வாறு நுண்ணறிவை வடிவமைக்கலாம் என்பதை ஆய்வு செய்து வந்தாலும்,  செய்யறிவின் (Artificial Intelligence) வளர்ச்சி கடந்த 70 ஆண்டுகளில் தான் ஒரு சீரிய பயணத்தை மேற்கொண்டது. இந்த வளர்ச்சி தொடர்ந்தும் மாற்றங்களை சந்தித்தது, பல நேரங்களில் முன்னேற்றமும், பின்னடைவும் காணப்பட்டது. பலருக்கும் **AI Winter** எனப்படும் பின்னடைவு காலங்கள் தெரிந்திருக்கலாம், ஆனால் **AI-யின் முழுமையான வரலாற்று பயணம்**, அதன் உருவாக்கம், முன்னோடிகள், மற்றும் ஏன் பல முயற்சிகள் தோல்வியடைந்தன என்பதற்கான புரிதல் இன்னும் தேவைப்படுகிறது. அதைப் புரிந்துகொள்வதற்கு, **AI எப்போது ஆரம்பித்தது? அதன் முன்னோடிகள் யார்? முன்னேற்றங்களை எந்த நுண்ணறிவு கோட்பாடுகள் வழிநடத்தின? மற்றும் எந்த இடங்களில் சிக்கல்கள் ஏற்பட்டன?** என்பவற்றை ஆராய்வது அவசியம்.

###### 1956 – Dartmouth Conference: AI-யின் பிறப்பு

1956-ஆம் ஆண்டு, அமெரிக்காவின் **Dartmouth College**-ல் ஒரு வரலாற்றுச் சிறப்புமிக்க மாநாடு நடைபெற்றது. இதை **Dartmouth Conference** என்று அழைக்கிறோம். இம்மாநாட்டை **John McCarthy, Marvin Minsky, Nathaniel Rochester, Claude Shannon** போன்ற முக்கிய AI விஞ்ஞானிகள் ஏற்பாடு செய்தனர். இதில் அவர்கள் முன்வைத்த ஒரு முக்கியமான கருத்து:

   **“மனிதர்களைப் போல சிந்திக்கக் கூடிய கணினிகளை உருவாக்க முடியுமா?”**

இந்த கேள்வி புதியதல்ல, ஏனெனில் 1940களில் **Alan Turing** என்பவர் **Turing Test** என்ற கோட்பாட்டை முன்வைத்திருந்தார். இது, ஒரு கணினி மனிதர்களைப் போல செயல்படுகிறதா என்று பரிசோதிக்க வேண்டிய முறை.

Dartmouth மாநாட்டில் **“Artificial Intelligence”** என்ற சொல் முதன்முறையாக உபயோகிக்கப்பட்டது. இது **மனிதர்கள் மேற்கொள்கின்ற சிந்தனை, தீர்வுகள், மற்றும் முடிவெடுக்கும் செயல்முறைகளை கணினிகள் செய்யக்கூடியதாக உருவாக்கும் புதிய விஞ்ஞானத் துறையாக அறிவிக்கப்பட்டது.**

அந்த மாநாட்டின் முக்கிய நோக்கங்கள்:

* கணினிகள் தன்னிச்சையாக முடிவெடுக்க வேண்டும்.
* கணினிகள் சிக்கல்களை புரிந்து கொண்டு, அதற்கான தீர்வுகளை கண்டறிந்து, திறமையாக தீர்க்க வேண்டும்.
* கணினிகள் மனித மொழியை புரிந்து கொள்ள வேண்டும்.
* கணினிகள் தனிநபர்களைப் போல அறிவாற்றலை வெளிப்படுத்த வேண்டும்.

இந்த மாநாட்டின் முடிவில், **AI-ஆய்வு புதிய பரிமாணத்தை அடைந்தது**. விஞ்ஞானிகள் இதை **சாத்தியமான ஒன்றாக** நம்பினார்கள். ஆனால், மேலும் பல முன்னேற்றங்கள் தேவையென்பதும் தெளிவாக இருந்தது.

###### 1960களில் AI-யின் தொடக்கக்கட்டம் – Rule-Based Systems

Dartmouth மாநாட்டின் பின்னணியில், 1960களில் விஞ்ஞானிகள் AI ஆராய்ச்சியை மேலும் விரிவுபடுத்தினர். AI-யின் ஆரம்பக் கட்டத்தில் உருவாக்கப்பட்ட முறை **Rule-Based Systems** ஆகும். Rule-Based Systems என்பது **மனித நிபுணத்துவத்தை கணினியில் கோட்பாட்டாக எழுத** முயற்சி செய்த AI முறை. இதன் அடிப்படையில்:

* **மனிதர்கள் எப்படி முடிவெடுக்கிறார்கள்?**
* **அந்த முடிவுகளுக்கான தர்க்கரீதியான காரணங்கள் என்ன?**
* **கணினி முறையாக முடிவெடுக்க எந்த விதிகளை (Rules) பயன்படுத்தலாம்?**

என்பவற்றை கணினியில் நிரலாக மாற்ற முயற்சி செய்யப்பட்டது.

###### General Problem Solver (GPS) – Allen Newell & Herbert A. Simon

GPS என்பது Rule-Based Problem Solving System ஆகும். இது பிரச்சனைகளை தீர்ப்பதற்கான பொதுவான செயல்முறையை (General Approach) முன்மொழிகிறது.

இந்த முறை மனிதர்கள் சிக்கல்களை எவ்வாறு தீர்க்கிறார்கள்? என்ற கோட்பாட்டை அடிப்படையாகக் கொண்டு உருவாக்கப்பட்டது. இதன் முக்கிய செயல்முறை, “ஒரு சிக்கலை தர்க்க ரீதியாக பகுக்க வேண்டும், தீர்வுக்கான வழிகளை கண்டுபிடிக்க வேண்டும், பின்னர் சிறந்த தீர்வை தேர்வு செய்ய வேண்டும்” என்பதாகும்.

ஆனால், இந்த முறை முழுமையாக வெற்றியடையவில்லை. இயற்கையின் சிக்கலான தன்மை காரணமாக, எல்லா பிரச்சனைகளுக்கும் ஒரு பொதுவான தீர்வு இருக்க முடியாது என்பதே பின்னர் உணரப்பட்டது.

###### ELIZA – Joseph Weizenbaum (1966)

ELIZA என்பது **மனிதர்களுடன் உரையாடக்கூடிய ஒரு தானியங்கி உரையாடல் (Chatbot)** ஆகும். இது **Natural Language Processing (NLP)** முறைகளைப் பயன்படுத்தி **மனிதர்களைப் போல பதிலளிக்க** முயற்சி செய்தது. ELIZA-வின் தனிச்சிறப்பு என்னவெனில், **மனிதர்களுடன் உரையாடல்களை நகலாக உருவாக்கி, உண்மையான பதில்களைக் கொடுப்பது போல தோற்றமளித்தது**.

**ஆனால், இதில் ஒரு முக்கியமான குறைபாடு இருந்தது.** ELIZA உண்மையாக ஒரு உரையாடலை புரிந்து கொள்ளவில்லை; அது வெறும் **predefined keywords** மற்றும் **pattern-matching** முறைகளை மட்டுமே பயன்படுத்தியது. இதனால், உரையாடல் தோற்றத்திற்கேற்ப இயல்பாக நடந்தாலும், உண்மையில் AI எந்த அர்த்தத்தையும் புரிந்து கொள்ளவில்லை. மேலும், **மனித உணர்வுகளையும், சூழ்நிலையையும் அடையாளம் கண்டு பதிலளிக்க முடியாமல்** இருந்தது.**AI உண்மையாக ஒரு machine intelligence ஆக வேண்டுமெனில், இது சூழ்நிலையைப் புரிந்து கொள்ளும் திறனை வளர்த்துக்கொள்ள வேண்டும்**.

1970களில் AI-யின் முக்கியமான சிக்கலாக **Combinatorial Explosion** கண்டறியப்பட்டது. AI-யில் ஒரு சிக்கலுக்கு தீர்வு காணும்போது, அதன் அனைத்து சாத்தியமான நிலைகளும் கணக்கிடப்படும். ஆனால், ஒரு பிரச்சனை வளர்ச்சியடைந்து பெரியதாக செல்லும் போது, அதன் முடிவுகளின் எண்ணிக்கை கணிக்க முடியாத அளவுக்கு அதிகரிக்கிறது. இதுவே **Combinatorial Explosion** எனப்படும் பிரச்சனை. எடுத்துக்காட்டாக, ஒரு **10x10 pixel** கொண்ட படத்தை எடுத்துக்கொண்டால், ஒவ்வொரு pixel-க்கும் **0 முதல் 256 வரை values** இருக்கலாம். இதனால், அந்த படத்திற்கான அனைத்து சாத்தியமான combination possibilities = **$256^{100}$** ஆகும், இது **பிரபஞ்சத்தில் உள்ள அணுக்களின் எண்ணிக்கையைவிட அதிகம்!** 

இதன் விளைவாக, AI கணிப்பொறிகள் (Computers) மிகப்பெரிய **computational resources** தேவையாகிறது. அதனால், Rule-Based AI முறைகள் **மிகப் பெரிய மற்றும் சிக்கலான பிரச்சனைகளை தீர்க்க முடியாது** என்பதை விஞ்ஞானிகள் உணர்ந்தனர். 

1970களின் இறுதியில், AI-யின் வளர்ச்சி ஒரு பெரிய சிக்கலின் முன் நின்று கொண்டிருந்தது. **Rule-Based Systems** மற்றும் **Expert Systems** பல முன்னேற்றங்களை ஏற்படுத்தியிருந்தாலும், அவை சிறிய அளவிலேயே பயனுள்ளதாக இருந்தன. **Combinatorial Explosion** பிரச்சனையால், மிகப் பெரிய பிரச்சனைகளை தீர்க்க முடியாத நிலை ஏற்பட்டது. இதனால், **Rule-Based AI-க்கு மாற்றாக புதிய வழிகள் தேவைப்படும்** என்று ஆராய்ச்சியாளர்கள் எண்ணத் தொடங்கினர். இதன் விளைவாக, **Machine Learning மற்றும் Deep Learning** போன்ற புதிய அணுகுமுறைகள் உருவாக ஆரம்பித்தன, மேலும் AI ஒரு புதிய பரிணாமத்துக்குள் நுழைந்தது.

இந்நிலையில், **Geoff Hinton** ஒரு புரட்சிகரமான சிந்தனையை முன்வைத்தார்: **Backpropagation of Errors**. இதற்கு முன்பு, AI விஞ்ஞானிகள் மனித மூளையின் செயல்பாட்டை ஒத்திருக்கும் கணினி அமைப்புகளை உருவாக்க முயன்றனர். ஆனால், **Hinton முற்றிலும் மாறுபட்ட அணுகுமுறையை தேர்ந்தெடுத்தார்** – கணினி சரியான முடிவுகளை உடனடியாக கணிக்க வேண்டிய அவசியமில்லை; மாறாக, **தவறுகளை செய்ய அனுமதித்து, அவற்றிலிருந்து திருத்தம் செய்துகொண்டு படிப்படியாக கற்றுக்கொள்ள வேண்டும்**.

நாம் குழந்தையாக இருக்கும்போது, **கல்லாங்காலி (Hopscotch)** விளையாடும் போது, முதல் முயற்சியிலேயே முழுமையாக சரியாக விளையாட முடியாது. கல்லை எங்கே எறிய வேண்டும், எந்த காலால் எங்கு நிற்க வேண்டும் என்பதில் முதல் சில முயற்சிகளில் தவறுகள் செய்வோம். ஆனால், **அந்த தவறுகளை நாம் நம் அனுபவத்தின் மூலம் திருத்திக் கொண்டு மெல்ல மெல்ல சரியான முறையில் விளையாட கற்றுக்கொள்கிறோம்**. ஒவ்வொரு தவறும் **ஒரு புது பாடமாக** அமைந்து, அடுத்த முறையில் அதை திருத்தி மேலும் திறமையாக விளையாட உதவுகிறது.

அதேபோல், Backpropagation முறையிலும், ஒரு Neural Network முதலில் ஒரு கணிப்பு (Prediction) செய்யும். அது தவறாக இருந்தால், அந்த தவறை அடையாளம் கண்டு திருத்தும் வழியை தானாகவே கற்றுக்கொள்ளும். மறுபடியும் கணிப்பு செய்து, மெல்ல மெல்ல சரியான முடிவை அடைய இது iteration முறையில் மேம்படுத்தப்படும்.

**எப்படி ஒரு குழந்தை கல்லாங்காலி (Hopscotch) விளையாடும்போது தவறுகளைச் செய்யும் இடையே அவற்றில் இருந்து பயில்கிறதோ, அதேபோல் Neural Networks-க்கும் தவறுகள் ஒரு முக்கியமான பங்காக உள்ளன.** குழந்தை தொடக்கத்தில் எந்த இடத்தில் குதிக்க வேண்டும், எங்கே கல்லை எறிய வேண்டும் என்று தெரியாமல் தவறாகச் செய்யலாம். ஆனால், **ஒவ்வொரு தவறும் அதை திருத்திக் கொள்ளும் வாய்ப்பாக மாறி, மெல்ல மெல்ல சரியான முறையில் விளையாட கற்றுக்கொள்ள உதவுகிறது.**

**அதேபோல், AI முறைகளும் ஒரு பிரச்சனைக்கு முதல் முயற்சியில் சரியான தீர்வை வழங்காது.** ஆனால், **தவறுகளை அடையாளம் கண்டு திருத்திக்கொண்டு, முன் செய்த பிழைகளை அடிப்படையாகக் கொண்டு, சிறிது சிறிதாக முன்னேறி, முற்றிலும் கற்றுக்கொள்ளும் திறன் பெற்றுவிடும்.** இதுவே **Backpropagation** முறையின் முக்கியத்துவம் – **முந்தைய தவறுகளை திருத்தி, மெல்ல மெல்ல சரியான முடிவை அடைய செய்யும் ஒரு கற்றல் செயல்முறை.**

இந்த புதிய அணுகுமுறை AI-யின் வளர்ச்சியில் ஒரு **முக்கிய திருப்புமுனையாக** அமைந்தது. **David Rumelhart, Geoff Hinton, James McClelland** மற்றும் **Ronald Williams** ஆகியோரால் 1986-ஆம் ஆண்டு மேலும் மேம்படுத்தப்பட்ட **Backpropagation Algorithm** இன்று **Neural Networks-ஐ பயிற்றுவிப்பதற்கான அடிப்படை நுட்பமாக** பார்க்கப்படுகிறது. இதுவே **Deep Learning**-க்கு ஆதாரமாக அமைந்தது. இதன் விளைவாக, **Neural Networks**-ஐ பயிற்றுவிக்க மிகவும் எளிதாகியது, மேலும் பெரிய அளவிலான **Big Data**-வை கையாள AI முன்னேறியது.

1980களின் இறுதியில் **Neural Networks** பற்றிய ஆராய்ச்சி முன்னேறியிருந்தாலும், கணிப்பொறிகள் (Computers) தேவையான கணக்கீடுகளை செய்யும் அளவிற்கு வலிமையாக இருக்கவில்லை. **Parallel Computing** பெரிதாக வளராத நிலையில், மிகப்பெரிய அளவிலான தரவை (Big Data) செயலாக்க முடியாத நிலை இருந்தது. இதனால், AI விஞ்ஞானிகள் **Statistics மற்றும் Probability** சார்ந்த முறைகளை ஆராயத் தொடங்கினர். இதிலிருந்து **Machine Learning** எனும் புதிய துறை உருவாகியது, இது கணினிகளை விதிகளின் அடிப்படையில் அல்ல, முறைமுறையாக தரவிலிருந்து கற்றுக்கொள்ளும் முறையாக உருவாக்க முயற்சித்தது.

1990களில், **Machine Learning** முறைகள் உருவாகி, **Rule-Based AI-யிலிருந்து Statistical AI-க்கான பெரிய மாற்றத்தை கொண்டு வந்தன**. விஞ்ஞானிகள் **Decision Trees, Support Vector Machines (SVM), Bayesian Networks** போன்ற கோட்பாடுகளை உருவாக்கினர். இவை, AI-யை முன்பு இருந்த **நிபுணர் அமைப்புகள் (Expert Systems) அல்லது Rule-Based Systems** போன்று செயல்படுத்தாமல், **தரவின் அடிப்படையில் தானாக முடிவெடுக்கக் கூடிய திறனை கொண்டதாக** வடிவமைக்க முயன்றன. இதன் மூலம் AI சிறிய பிரச்சனைகளுக்கு மட்டுமல்லாமல், **முடிவெடுக்கும் முறைகள், தரவின் மாதிரிகள் (Patterns), மற்றும் சிக்கலான செயல்பாடுகளை** புரிந்து கொள்ளக்கூடியதாக மாறியது.

இந்த காலக்கட்டத்தில், **AI-யின் பயன்பாடுகள்** கணிசமாக அதிகரிக்கத் தொடங்கின. **Natural Language Processing (NLP)** முறைகள் வேகமாக முன்னேறியதால், மொழிபெயர்ப்பு, உரையாடல் அமைப்புகள் மற்றும் உரை பகுப்பாய்வு போன்ற துறைகள் வளர்ச்சியடைந்தன. **IBM Watson** போன்ற மேம்பட்ட **AI Systems** உருவாக்கப்பட்டன, குறிப்பாக தகவல்களை பகுப்பாய்வு செய்து, வினாக்களுக்கு பயனுள்ளதாக பதிலளிக்கக்கூடிய திறன் பெற்றன.

அதே நேரத்தில், **Fraud Detection, Recommendation Systems, மற்றும் Web Search Engines** போன்ற **Data-Driven AI Models** வணிக உலகில் பரவலாகப் பயன்படுத்தப்படத் தொடங்கின. **Computer Vision** மற்றும் **Robotics** துறைகளும் புதிய கட்டத்திற்குச் சென்றன, குறிப்பாக தொழிற்சாலைகள், மருத்துவம், மற்றும் தன்னியக்க வாகனங்கள் (Autonomous Vehicles) போன்ற துறைகளில் AI முக்கிய பங்கு வகிக்கத் தொடங்கியது. இதனால், AI ஆனது ஆய்வகங்களில் மட்டும் அல்லாது **உண்மையான தொழில்துறைகளில் நுழைந்து**, கணிசமான மாற்றங்களை உருவாக்கத் தொடங்கியது.

2000களில் கணிப்பொறிகள் பல மடங்கு வலுவடைந்தன. **Parallel Computing, Cloud Computing, GPUs (Graphics Processing Units)** போன்ற தொழில்நுட்பங்கள் வளர்ந்ததை தொடர்ந்து, **பெரிய அளவிலான தரவை (Big Data) கையாள இயலும் சூழ்நிலை உருவாகியது**. இதனால், 1980களில் தேக்கமடைந்திருந்த **Neural Networks** மீண்டும் முக்கியத்துவம் பெற தொடங்கின. கணினிகள் அதிகம் பயன்படுத்தக்கூடியதாக மாறியதால், விஞ்ஞானிகள் **Machine Learning** மற்றும் **Deep Learning** சார்ந்த ஆய்வுகளை மேலும் தீவிரப்படுத்தினர்.

**Deep Learning** என்ற புதுமையான துறை உருவாக்கப்பட்டதால், **Multi-Layered Neural Networks** மூலம் AI மிகவும் வலிமையானதாக மாறியது. இது, கணினிகளை **தானாக தரவிலிருந்து கற்றுக்கொண்டு முடிவெடுக்கக்கூடியதாக மாற்றியது**, மேலும் AI-யின் பயன்பாடுகளை வெகுவாக அதிகரித்தது. குறிப்பாக, **Speech Recognition (Google Voice, Siri, Alexa), Image Recognition (Face Detection, Self-driving Cars), Natural Language Processing (Chatbots, Machine Translation), மற்றும் Medical AI (Cancer Detection, Drug Discovery)** போன்ற துறைகள் பெரிய வளர்ச்சி கண்டன. AI முன்னேறுவதற்கு மிகப்பெரிய அடித்தளமாக **Deep Learning** துறையின் வளர்ச்சி அமைந்தது, மேலும் இது **புதிய தீர்வுகளை கண்டுபிடிக்கவும், எளிதாக பிரச்சனைகளை தீர்க்கவும் கணினிகளை மிகவும் திறமையாக மாற்றியது**.

2010களின் பிறகு, **AI-யின் வளர்ச்சி ஒரு புதிய உச்சத்தை அடைந்தது**. Deep Learning முறைகள் தரவின் **ஆழமான தன்மைகளை புரிந்துகொள்ளும் திறனை** அதிகரித்தன. முன்னதாக இருந்த **Convolutional Neural Networks (CNNs) மற்றும் Recurrent Neural Networks (RNNs)** போன்ற முறைகள் சில குறிப்பிட்ட பிரச்சனைகளுக்கு மட்டுமே பயன்பட்டன. ஆனால், **AI-யின் வளர்ச்சியில் மிகப் பெரிய மாற்றத்தை கொண்டு வந்தது – Transformers Architecture**.

2017-ஆம் ஆண்டு **Google Brain Team** வெளியிட்ட **“Attention Is All You Need”** ஆய்வு கட்டுரை, **Transformers** எனும் புதிய Deep Learning மாடலை உலகுக்கு அறிமுகப்படுத்தியது. இதன் முக்கியத்துவம் என்னவென்றால், இது **மொத்த தகவல் தொகுப்பிலிருந்தும் (Context) முக்கியமான தரவுகளை கவனத்துடன் அணுகி செயலாக்கும் திறனை கொண்டது**. இதன் மூலம், **நீண்ட உரைகளை புரிந்து கொள்ளுதல், மொழிபெயர்ப்பு, உரையாடல் (Chatbots) போன்ற செயல்பாடுகளில் பெரும் முன்னேற்றம் ஏற்பட்டது**.

Transformers-ல் அடிப்படையாக உருவான **GPT (Generative Pre-trained Transformers), BERT (Bidirectional Encoder Representations from Transformers), மற்றும் T5, Llama, Mistral, Gemini போன்ற LLMs (Large Language Models)** உள்ளிட்ட மாடல்கள் உருவாக்கப்பட்டன. இவை **மனிதர்களை ஒத்த உரையாடல், மொழிபெயர்ப்பு மற்றும் தகவல் உருவாக்கம்** போன்ற செயல்களை மிகச்சரியான முறையில் செய்யக்கூடியதாக உருவாகின.

அதே நேரத்தில், **Generative AI** வளர்ச்சி அடைந்து, AI **படங்கள், வீடியோக்கள், பாடல்கள், மற்றும் மொழிபெயர்ப்பு** போன்றவற்றை உருவாக்கும் திறன் பெற்றது. **DALL-E, MidJourney, Stable Diffusion** போன்ற தொழில்நுட்பங்கள் **கணினியால் உருவாக்கப்படும் படங்களை** மனிதர்களுக்கே அடையாளம் காண முடியாத அளவிற்கு உணர்வுப்பூர்வமாக மாற்றின. ChatGPT, Claude, Gemini போன்ற **உரையாடல் மாடல்கள்** தகவலை புரிந்து கொண்டு, **மனிதர்களைப் போல பதிலளிக்க** தொடங்கின.

**AI இப்போது எங்கு உள்ளது? எதிர்காலம் எப்படி இருக்கும்?**

இன்றைய AI, பல முக்கிய துறைகளில் **மிகவும் வலுவாக** முன்னேறி வருகிறது:

1. **மருத்துவ துறை (Medical AI)** – நோய்களை கண்டறிவது, மருத்துவ பரிசோதனைகளை துல்லியமாக செய்ய AI உதவுகிறது. **Cancer Detection, Drug Discovery** போன்ற முக்கியமான புலங்களில் AI பாரிய மாற்றங்களை உருவாக்கியுள்ளது.
2. **தன்னியக்க வாகனங்கள் (Autonomous Vehicles)** – **Self-Driving Cars, Drones** போன்ற துறைகள் மிக வேகமாக வளர்ந்து வருகின்றன. **Tesla, Waymo, Cruise** போன்ற நிறுவனங்கள் முழுமையாக AI மூலம் இயக்கப்படும் வாகனங்களை உருவாக்கும் முயற்சியில் உள்ளன.
3. **Generative AI** – **ChatGPT, MidJourney, DALL-E** போன்ற AI அமைப்புகள் **உரைகள், படங்கள், வீடியோக்கள், மற்றும் 3D மாதிரிகள்** போன்றவற்றை மனிதர்கள் போல் உருவாக்கி, **உருவாக்க சிந்தனை (Creative Thinking)** பரிமாணத்திலும் AI-யை முன்னேற்றியுள்ளன.
4. **Quantum AI** – **Quantum Computing**-இன் வளர்ச்சி மூலம் மிகப் பெரிய மற்றும் சிக்கலான கணக்கீடுகளை செய்யும் AI உருவாகியுள்ளது. **Google, IBM, Microsoft** போன்ற நிறுவனங்கள் **Quantum AI**-ஐ முழுமையாக வளர்த்துவருகின்றன. இது **வலைவிரித்த கணக்கீடுகள், மருந்தியல் ஆராய்ச்சி, மற்றும் சுற்றுச்சூழல் மண்டல ஆய்வுகள்** போன்ற பல பிரச்சனைகளை தீர்க்க உதவுகின்றது.
5. **மனித அறிவிற்கு இணையான செயற்கை நுண்ணறிவு (Artificial General Intelligence - AGI)** – AI இப்போது **நிபுணத்துவம் (Narrow AI) கொண்ட செயல்களை மட்டுமே செய்கிறது**. ஆனால், எதிர்காலத்தில் **மனிதர்களைப் போல பல்துறை அறிவாற்றல் கொண்ட AGI** உருவாகலாம் என்ற எதிர்பார்ப்பு உள்ளது. இது **மனிதர்களைப் போல சிந்தித்து, தன்னிச்சையாக முடிவெடுக்கும் AI-ஐ உருவாக்கும் முயற்சியில் உள்ள விஞ்ஞானிகளுக்கு மிகப்பெரிய இலக்காக உள்ளது**.

AI-யின் வளர்ச்சி தொடர்ந்து மிக வேகமாக நடைபெற்று வருகிறது. **Generative AI, Robotics, Computational Creativity, AGI** போன்ற தொழில்நுட்பங்கள் முன்னேறி வரும் நிலையில், **AI மனித வாழ்க்கையை மாற்றும் மிகப்பெரிய கண்டுபிடிப்பாக** மாறியுள்ளது.

கணிப்பொறிகள் உருவாகி 80 ஆண்டுகள் ஆகின்றன, ஆனால் AI-யின் வளர்ச்சி கடந்த 20 ஆண்டுகளில் நிகழ்ந்த மிகப் பெரிய புரட்சி. **இன்னும் பத்து ஆண்டுகளில், AI எவ்வாறு மாறும்? அது மனிதர்களுடன் இணைந்து செயல்படுமா? அல்லது, AI-யால் மனித அறிவைத் தாண்டி செல்லக்கூடிய புதிய நுண்ணறிவு உருவாகுமா?**

இது நிச்சயமாக எதிர்காலத்தில் பெரும் ஆராய்ச்சிக்கும், விவாதத்திற்கும் உரிய விஷயமாக இருக்கும்! 

இனி வரும் காலங்களில், **AI-யின் எல்லைகள் மேலும் விரிவடையும்** – அதுவே **மனிதர்களுடன் ஒருங்கிணைந்து செயல்படும் அறிவாற்றல் அமைப்பாக மாறுமா? அல்லது மனித அறிவை மிஞ்சும் நிலையை அடையுமா?** என்பதை எதிர்காலமே தீர்மானிக்க வேண்டும்! 

#####  1.2. செய்யறிவு என்றால் என்ன?

செய்யறிவு (Artificial Intelligence) கடந்த பத்தாண்டுகளில் எதிர்பாராத அளவிற்கு நுட்பமான செயல்களைப் புரிந்து வருகிறது. படத்தைப் பார்த்து அதில் இருப்பவற்றைக் கண்டறிவது தொடங்கி மொழிபெயர்ப்பு வரை பலதரப்பட்ட சிக்கலான வேலைகளைச் செம்மையுறச் செய்து காட்டியுள்ளது. அதனைப் பற்றி விரிவாக இக்கட்டுரையில் காண்போம்.

தன்னிச்சையாக செயல்படும் கணினிகளை உருவாக்கும் முயற்சியே Artificial Intelligence (AI) என்று அழைக்கலாம். AI என்பது கணினிகள் மனிதர்களைப் போல அறிவார்ந்த முடிவுகளை எடுக்க மற்றும் புதிதாக கற்றுக்கொள்ள உதவுகின்ற ஒரு முறை. 

**Artificial Intelligence - AI நிறுவுநர்களில் ஒருவரான ஜான் மெக்கார்த்தி (**John McCarthy**), AI-ஐப் பற்றி இப்படி வரையறுக்கிறார் :**

> **“[Artificial intelligence is] the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable.”**

**இந்த வரையறை எதை குறிக்கிறது?**

இந்த **AI** வரையறை மூன்று முக்கியமான அம்சங்களை கொண்டிருக்கிறது:

**Science and Engineering of Making Intelligent Machines**

- இதன் பொருள் **AI என்பது நமக்கு தேவையான தகவல்களை கற்றுக்கொண்டு**, **முடிவுகளை எடுத்து**, **பிரச்சினைகளை தீர்க்க** பயன்படுகிறது.

 **Using Computers to Understand Human Intelligence**

- AI என்பது **மனிதர்கள் எப்படி சிந்திக்கிறார்கள், முடிவெடுக்கிறார்கள்** என்பதை புரிந்து கொண்டு அதனை கணினியில் மாதிரி (model) செய்வது.

 **AI Does Not Have to Follow Biologically Observable Methods**

- AI மனிதர்களை மாத்திரம் பின்பற்றவேண்டும் என்று இல்லை; இது கணினிகளுக்கே ஏற்ற **algorithm-based intelligence** ஆக இருக்கலாம்.

##### 1.3. எதை AI என்று அழைக்கலாம்?

இன்று நாம் AI என்பதை Self-driving Cars, Chatbots, Speech Recognition, Medical Diagnosis AI போன்ற செயல்பாடுகளில் காணலாம். ஆனால், AI என்றால் கண்டிப்பாக ஒரு சுயசிந்தனை உடையது மட்டுமே ஆக வேண்டியதில்லை. இது ஒரு நிலையான if-else விதிகளால் கட்டுப்பட்டாலும் கூட, கணினி மனிதர்களின் சிந்தனையை ஒத்த மாதிரி செயல்படும் என்றால், அது AI ஆகக் கொள்ளலாம்.

இதனை புரிந்துக்கொள்ள நாம் ஒளிக்காட்சி விளையாட்டில் (Video Games) வரும் **கதாப்பாத்திரங்கள்** எப்படி செயல்படுகின்றன என்பதை உதாரணமாக கொண்டு AI அணுகுவோம்.

**ஒளிக்காட்சி விளையாட்டில் வரும் NPCs (Non-Playable Characters) AI ஆகிறதா?**

**Video Games** விளையாடும் போது, நீங்கள் எதிர்கொள்ளும் **Non-Playable Characters (NPCs)**, அதாவது **computer-controlled characters** பல முறை **AI** போல தோன்றலாம். ஆனால் அவை உண்மையான **AI அல்ல**.

உதாரணத்திற்கு, ஒரு NPC (வில்லன்) நம்மை பார்க்கும்போது **தாக்கும்**, இல்லையெனில் **நடந்து கொண்டே இருக்கும்**. இது உண்மையான **AI** ஆகாது, இது ஒரு **rule-based system -** simple if-else logic ஆகும். NPC தனது சூழ்நிலையை (context) **புரிந்துகொண்டு சுயமாக முடிவெடுக்காது**.

**NPCs எப்படி முடிவெடுக்கின்றன?**

**If-Else** என்பது ஒரு **decision-making (முடிவெடுக்கும்)** statement ஆகும். இவை **Non-Playable Character (NPC)** எப்போது **தாக்க வேண்டும்? எப்போது நடந்து கொண்டிருக்க வேண்டும்?** என்ற முடிவுகளை எடுக்க இது பயன்படும். **NPC உண்மையான AI அல்ல** - இது வெறும் **if-else** statement கொண்ட ஒரு **rule-based system** மட்டுமே! இவை **Pre-programmed logic** மட்டுமே பயன்படுத்தும்.

**Rule-Based Systems** (If-Else Statements) என்பது **முன்கூட்டியே நிரலாக்கப்பட்ட விதிகளை** பின்பற்றி செயல்படும். ஆனால், **AI** என்பது சூழ்நிலையை புரிந்து கொண்டு **தன்னிச்சையாக முடிவெடுக்க** வேண்டும்.

இவை எவ்வாறு செயல்படும் என்பதை எளிய முறையில் புரிந்துகொள்வோம்.

**காட்சி 1: If-Else Logic கொண்ட rule-based NPC**

நீங்கள் **ஷூட்டர் கேம்** விளையாடுவதாக கற்பனை செய்துக்கொள்ளுங்கள் 🎮 . நீங்கள் ஒரு **NPC வில்லனை** (enemy AI) எதிர்கொள்கிறீர்கள். NPC உங்களை பார்க்கும்போது **தாக்கும்**, இல்லையெனில் **உலாவி கொண்டிருக்கும்**.

```
if player_distance < 10:
    attack()
else:
    patrol()
```

**என்ன நடக்கிறது?**

- நீங்கள் 10 மீட்டருக்கு (meters) உள்ளே வந்தால் NPC வில்லன் உங்களை தாக்கும்.
- நீங்கள் 10 மீட்டருக்கு வெளியே இருந்தால், அது பாதுகாப்பாகச் சுற்றி வரும்.
- சூழ்நிலை எதுவானாலும் இவை கடைசிவரை **இதே விதியை மட்டுமே பின்பற்றும்**.

ஆனால் இன்று **Machine Learning மற்றும் Reinforcement Learning** கொண்டு **AI NPCகள்** உருவாக்கப்பட்டுள்ளன.

**அது எப்படி AI NPCகள் If-Else Statements ஐ தாண்டி செயல்படுகிறது?**

**காட்சி 2: AI-யை கொண்டு முடிவெடுக்கும் NPC**

வீரர் தன்னை தாக்கினால் – NPC பல சூழ்நிலையை ஆராய்ந்து முடிவெடுக்கும். அதாவது வீரரின் ஆரோக்கியம் (Player Health) அதிகமாக இருந்தால் எதிர் தாக்கும். இல்லையெனில் ஒளிந்து கொள்ளும். முன்பு வீரர் நடந்து சென்ற வழியை கற்றுக்கொண்டு அந்த வழியில் மறைத்து தாக்கும். அதுவே NPC-க்கு குறைந்த ஆரோக்கியம் இருந்தால் உங்களிடம் இருந்து தப்பித்து ஓடி ஒளிந்து கொள்ளும். வீரர் அடிக்கடி கவரேஜ் (cover) தேடி இருக்கிறாரா? NPC அதை கவனித்து, சுற்றி தாக்கலாம்.

AI NPC **சூழ்நிலையை ஆராய்ந்து முடிவெடுக்கிறது**. அதாவது, **வீரரின் ஆரோக்கியம்(player health), தன்னுடைய ஆரோக்கியம் (NPC health) மற்றும் எதிரியின் எத்தனை நேரம் தாக்காமல் இருக்கிறார் என்பதைப் பொறுத்து முடிவெடுக்கும்.**

**AI NPC** ஒரு **புதிய சூழ்நிலை உருவான பிறகு** அதற்கேற்ப **கற்றுக்கொண்டு செயல்படும்**. 

**எடுத்துக்கட்டாக ஒரு திருடன் (NPC) - காவலரை (Player) பார்த்து எப்பொழுது ஓட வேண்டும் எனப்பார்ப்போம்?**

| **திருடனின் நிலை (NPC State)**  | **காவலர் அருகில் உள்ளாரா?** | **திருடன் என்ன செய்ய வேண்டும்?** |
| ------------------------------ | ------------------------ | --------------------------- |
| அதிகபட்ச சக்தி உள்ளது (Healthy)   | இல்லை                     | அங்கேயே இருக்கும்              |
| குறைந்த சக்தி உள்ளது (Low Health) | இல்லை                     | ஒளிந்து கொள்ளும்               |
| குறைந்த சக்தி உள்ளது              | ஆம்                       | ஓடிவிடும் 🏃‍♂️                 |
| முழு சக்தி உள்ளது                | ஆம்                       | காவலரை தாக்கலாம்!             |

**AI NPC** **மனிதர்கள் போல் முடிவெடுப்பது எப்படி?**

உதாரணமாக 

**Player ஒரு இடத்தில் ஒளிந்து கொள்ள அதிக நேரம் செலவழிக்கிறார் என்றால்?**

NPC அதை கவனித்து, முன்கூட்டியே எதிர்பார்த்து அந்த இடத்தில் தாக்கலாம்.

**Player எப்போதும் ஒரு குறிப்பிட்ட வழியில் ஓடுகிறாரா?**

AI NPC அந்த வழியை மறித்து விளையாடலாம்.

**Rule-Based AI vs Learning AI (மனிதர்கள் போல் முடிவெடுக்கும் AI)**

| **ஒப்பீடு**                  | **Rule-Based NPC (If-Else Logic)**         | **AI NPC (Machine Learning)**                                |
| -------------------------- | ------------------------------------------ | ------------------------------------------------------------ |
| **முடிவெடுக்கும் விதம்**      | நிரந்தர விதிகள் (Fixed Rules)                | சூழ்நிலைக்கு ஏற்ப கற்றுக்கொண்டு முடிவெடுக்கும் (Dynamic Learning)    |
| **சூழ்நிலைக்கு ஏற்ப மாறுமா?** | முடிவெடுக்க முடியாது (Cannot Learn)         | வீரரின் செயல்பாடுகளிலிருந்து கற்றுக்கொண்டு மாறும் (Learns from Player Actions) |
| **உண்மையான உணர்வு தருமா?**   | எதிர்பார்க்கக்கூடிய செயல்பாடு (Predictable)     | மனிதர்களைப் போன்ற அனுபவம் தரும் (Feels more human-like)           |
| **உதாரண விளையாட்டுகள்**      | **Super Mario**, **Classic Shooter Games** | **Red Dead Redemption, GTA V, Open-World Games**             |

AI என்பது வெறும் விளையாட்டு NPCகளுக்கு மட்டும் அல்ல, நம் சுற்றியுள்ள அனைத்திற்கும் பயன்படுத்தப்படும் ஒரு நுண்ணறிவு முறை. ஆரம்பத்தில், if-else logic மூலம் NPCகள் நிரலாக்கப்பட்ட விதிகளை மட்டும் பின்பற்றி செயல்பட்டன, ஆனால் இன்று Machine Learning & Reinforcement Learning போன்ற நவீன AI முறைகள் சூழ்நிலைகளை புரிந்து கொண்டு தன்னிச்சையாக முடிவெடுக்கும் திறனை பெற்றுவிட்டன. AI  விளையாட்டுகளுக்கு மட்டுமல்ல, தோழமையாக பேசும் voice assistants (Siri, Alexa), சுயமாக செல்லும் Self-Driving Cars, Netflix, YouTube, Amazon போன்ற நிறுவனங்கள் AI-ஐ பயன்படுத்தி, உங்களுக்கு மிகவும் பிடிக்கக்கூடிய உள்ளடக்கங்களை பரிந்துரைக்கிறது, Chatbots மருத்துவத்தில் நோய்களை கண்டறிய, மருத்துவ பரிந்துரைகள் வழங்க மற்றும் மருந்துகளின் கண்டுபிடிப்பை விரைவுபடுத்த AI பயன்படுத்தப்படுகிறது.

**AI மனிதர்களைப் போல செயல்பட வேண்டும் என்பதல்ல அவை மனிதர்களுக்கு பயன்படும் வகையில், தரவினைப் புரிந்து கொண்டு, சூழ்நிலைக்கு ஏற்ப முடிவுகளை எடுக்க மற்றும் செயல்திறனை மேம்படுத்த மனிதர்கள் உருவாக்கி கொண்டிருக்கிற தொழில்நுட்பம். இது விளையாட்டு முதல் மருத்துவம் வரை பல்வேறு துறைகளில் நம்மை சுற்றியுள்ள தரவை பயனுள்ளதாக மாற்றி செயல்படக்கூடியதாகவும் உருவாகி வருகிறது.**

<hr class="pagebreak">

### 2. இயல் மொழி தெளிதல் - Natural Language Processing (NLP)

NLP என்பது செயற்கை நுண்ணறிவின் மிக முக்கியமான மற்றும் சவாலான துறைகளில் ஒன்றாகும். இது கணினிகளுக்கு மனித மொழியைப் புரிந்துகொள்ளவும், அதைப் பகுப்பாய்வு செய்யவும், பதிலளிக்கவும் உதவுகிறது. மனிதர்களுக்கு மொழி பயன்பாடு இயல்பான ஒன்றாக இருந்தாலும், கணினிகளுக்கு இது பல சிக்கல்களைக் கொண்ட ஒரு சிக்கலான செயல்முறையாகும்.

**மொழியின் சிக்கலான தன்மை: ஒரு ஆழமான பார்வை**

"He saw the bat." என்ற எளிய ஆங்கில வாக்கியத்தை எடுத்துக்கொள்வோம். இந்த வாக்கியத்தில் "bat" என்ற சொல்லுக்கு இரண்டு தெளிவான அர்த்தங்கள் உள்ளன:

1. விளையாட்டு மட்டை (cricket bat)
2. வௌவால் (the animal)

இந்த இருபொருள் நிலை (lexical ambiguity) NLP-யின் முக்கிய சவால்களில் ஒன்றை வெளிப்படுத்துகிறது. கணினி எவ்வாறு சரியான அர்த்தத்தைத் தேர்ந்தெடுக்கும்? இங்கே சூழல் (context) முக்கிய பங்கு வகிக்கிறது:

- "He saw the bat at the zoo." → வௌவால்
- "He saw the bat in the sports shop." → கிரிக்கெட் மட்டை

இந்த **சூழல் சார்ந்த புரிதலே (contextual understanding)** இன்று நாம் உருவாக்கும் அனைத்து முன்னேற்றமான NLP அமைப்புகளின் மையக் கருவாக மாறியுள்ளது. மொழி என்பது சிக்கலான ஒன்றாக இருக்கும்போது, அதை யூகித்து, உணர்ந்து, செயற்படுத்தும் திறன் ஒன்றே ஒரு செயல்படும் மெஷினின் நுண்ணறிவைக் குறிப்பிடுகிறது.

இதையொட்டி, அடுத்து நாம் **Tokenization**, **Stop Word Removal**, **Stemming**, **Lemmatization** போன்ற NLP-யின் அடிப்படை செயலாக்க நுட்பங்களை விரிவாக ஆராயப் போகிறோம். இந்த நுட்பங்கள் எவ்வாறு உரையைக் கணினிகளுக்கு புரியக்கூடிய வடிவத்தில் மாற்றுகின்றன என்பதைப் புரிந்துகொள்வது, NLP-யின் மேலும் மேம்பட்ட தலைப்புகளைப் புரிந்துகொள்வதற்கான அடித்தளத்தை வகுக்கும்.

##### 2.1. Tokenization  

Tokenization என்பது இயல் மொழி தெளிதளின் (NLP) முதன்மை மற்றும் மிக அத்தியாவசியமான முன்-செயலாக்க நடவடிக்கையாகும். இந்த செயல்முறையில், ஒட்டுமொத்த உரைப் பகுதி சிறிய, அர்த்தமுள்ள அலகுகளாகப் பிரிக்கப்படுகிறது - இவை வார்த்தைகள் (words), சொற்றொடர்கள் (phrases), வாக்கியங்கள் (sentences) அல்லது கூட எழுத்துகள் (characters) ஆகியவற்றை உள்ளடக்கியிருக்கலாம். இந்த டோக்கன்கள் (tokens) பின்னர் கணினியால் எளிதாகப் பகுப்பாய்வு செய்யக்கூடிய வடிவத்தில் உள்ளன.

Tokenization இல்லாமல், கணினிகளுக்கு மனித மொழியின் சிக்கலான கட்டமைப்பைப் புரிந்துகொள்வது கடினம். 

```tex
எடுத்துக்காட்டாக, "நல்வரவு! உங்கள் பெயர் என்ன?" என்ற உரையை "நல்வரவு", "!", "உங்கள்", "பெயர்", "என்ன", "?" என்று பிரிப்பதன் மூலம், ஒவ்வொரு சொல் மற்றும் குறியீட்டின் பங்கையும் தனித்தனியாக ஆய்வு செய்ய முடிகிறது.
```

இந்த அடிப்படைப் படி இல்லையென்றால், உரை வகைப்படுத்தல் (text classification), உணர்ச்சி பகுப்பாய்வு (sentiment analysis), இயந்திர மொழிபெயர்ப்பு (machine translation) போன்ற மேம்பட்ட NLP பணிகள் சாத்தியமற்றதாகிவிடும். உரையை சிறிய பகுதிகளாக பிரிப்பது, கணினிகள் உரையை பகுப்பாய்வு செய்ய உதவுகிறது.  இது **தரவு எளிமைப்படுத்தல்** மற்றும் **நுணுக்கமான பகுப்பாய்வு** போன்ற பணிகளுக்கு முன்-பாதையாக அமைந்துள்ளது.

> அடுத்ததாக, Tokenization முறைமைப் பல வகைகளில் நடைமுறைப்படுத்தப்படுகிறது. அவற்றில் முக்கியமானவை கீழே கொடுக்கப்பட்டுள்ளன:

1. **Word Tokenization:** ஒரு வாக்கியம் அல்லது பத்தியை தனித் தனியான **வார்த்தைகளாக** பிரிக்கும் செயல். இதில் ஒவ்வொரு வார்த்தையும் ஒரு டோக்கனாகக் கருதப்படுகிறது. இது மிக அடிப்படையான Tokenization முறையாகும். 
   - உரை: "I love NLP."  
   - Tokenization: ["I", "love", "NLP", "."]  

2. **Sentence Tokenization:** ஒரு பெரிய உரையை **வாக்கியங்களாக** பிரிக்கும் செயல்முறை. ஒவ்வொரு வாக்கியமும் தனி டோக்கனாக செயல்படும்.  
   - உரை: "Hello! How are you? I hope you are doing well."  
   - Tokenization: ["Hello!", "How are you?", "I hope you are doing well."]  

```python
from nltk.tokenize import word_tokenize, sent_tokenize

# உரை (Text)
text = "Hello! How are you? I hope you are doing well."

# வார்த்தைகளாக துண்டாக்கம் (Word Tokenization)
words = word_tokenize(text)
print("Words:", words)

# வாக்கியங்களாக துண்டாக்கம் (Sentence Tokenization)
sentences = sent_tokenize(text)
print("Sentences:", sentences)
```

**Output:**  
```
Words: ['Hello', '!', 'How', 'are', 'you', '?', 'I', 'hope', 'you', 'are', 'doing', 'well', '.']
Sentences: ['Hello!', 'How are you?', 'I hope you are doing well.']
```

##### 2.2. Stop Words Removal
Stop Words என்பது மொழியில் அடிக்கடி வரும் ஆனால் முக்கியமில்லாத சொற்கள். எடுத்துக்காட்டாக, "the", "is", "in", "and" போன்றவை. இவை உரையின் பொருளை பாதிக்காது, ஆனால் NLP மாதிரிகளின் செயல்திறனை குறைக்கும்.  

**எடுத்துக்காட்டு:**  
- உரை: "This is a simple example."  
- Stop Words Removal: ["This", "simple", "example", "."]  

தரவு செயலாக்கத்தை வேகமாக்குகிறது. மாதிரிகளின் துல்லியத்தை மேம்படுத்துகிறது.  

```python
from nltk.corpus import stopwords

# உரை (Text)
text = "This is a simple example of removing stop words."

# Stop words-ஐப் பெறுதல்
stop_words = set(stopwords.words('english'))

# Tokenization
words = word_tokenize(text)

# Stop words-ஐ நீக்குதல்
filtered_words = [word for word in words if word.lower() not in stop_words]
print("Filtered Words:", filtered_words)
```

**Output:**  
```
Filtered Words: ['This', 'simple', 'example', 'removing', 'stop', 'words', '.']
```

##### 2.3. Stemming (வேர்ச்சொல் பிரித்தல்)  
Stemming என்பது வார்த்தையின் மூல வடிவத்தைப் பிரிக்கும் செயல்முறை. இது சொல்லின் பொருளை மாற்றாமல், அதன் அடிப்படை வடிவத்தைக் கொடுக்கும்.  

**எடுத்துக்காட்டு:**  
- "running" -> "run"  
- "jumps" -> "jump"  

உரையில் உள்ள வார்த்தைகளை ஒரே மாதிரியாக மாற்றுகிறது. தரவு செயலாக்கத்தை எளிதாக்குகிறது.  

```python
from nltk.stem import PorterStemmer

# உரை (Text)
words = ["running", "jumps", "easily", "fairly"]

# Stemmer
stemmer = PorterStemmer()

# Stemming
stemmed_words = [stemmer.stem(word) for word in words]
print("Stemmed Words:", stemmed_words)
```

**Output:**  
```
Stemmed Words: ['run', 'jump', 'easili', 'fairli']
```

##### 2.4. Lemmatization   
Lemmatization என்பது Stemming-ஐப் போலவே, ஆனால் சொல்லின் சரியான வடிவத்தைப் பிரிக்கும். இது சொல்லின் பொருளை மாற்றாமல், அதன் அகராதி வடிவத்தைக் கொடுக்கும்.  

**எடுத்துக்காட்டு:**  

- "running" -> "run"   

  Stemming-ஐ விட துல்லியமானது. சொல்லின் பொருளை பாதுகாக்கிறது.  

```python
from nltk.stem import WordNetLemmatizer

# உரை (Text)
words = ["running", "jumps", "easily", "better"]

# Lemmatizer
lemmatizer = WordNetLemmatizer()

# Lemmatization
lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
print("Lemmatized Words:", lemmatized_words)
```

**Output:**  
```
Lemmatized Words: ['running', 'jump', 'easily', 'better']
```

##### 2.5. Part-of-Speech Tagging   
POS Tagging என்பது வார்த்தைகளின் வகையை (பெயர்ச்சொல், வினைச்சொல், உரிச்சொல்) கண்டறியும் செயல்முறை.  

**எடுத்துக்காட்டு:**  

- "I love NLP."  
- POS Tags: [('I', 'PRP'), ('love', 'VBP'), ('NLP', 'NNP'), ('.', '.')]  

உரையின் கட்டமைப்பை புரிந்து கொள்ள உதவுகிறது.  பிற NLP பணிகளுக்கு பயனுள்ளது.   

```python
from nltk import pos_tag

# உரை (Text)
text = "I love learning NLP."

# Tokenization
words = word_tokenize(text)

# POS Tagging
pos_tags = pos_tag(words)
print("POS Tags:", pos_tags)
```

**Output:**  
```
POS Tags: [('I', 'PRP'), ('love', 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP'), ('.', '.')]
```

##### 2.6. Named Entity Recognition (NER) 
NER என்பது உரையில் உள்ள முக்கியமான பெயர்களை (நபர்கள், இடங்கள், நிறுவனங்கள்) அங்கீகரிக்கும் செயல்முறை.  

**எடுத்துக்காட்டு:**  
- உரை: "Apple is located in Cupertino."  
- NER: Apple (ORG), Cupertino (LOC)  

உரையில் உள்ள முக்கிய தகவல்களை பிரித்தெடுக்க உதவுகிறது. இது தரவு பகுப்பாய்வுக்கு பயனுள்ளது.  

```python
import spacy

# spaCy மாதிரியை ஏற்றுதல்
nlp = spacy.load("en_core_web_sm")

# உரை (Text)
text = "Apple is located in Cupertino."

# NER
doc = nlp(text)
for ent in doc.ents:
    print(ent.text, ent.label_)
```

**Output:**  

```
Apple ORG
Cupertino GPE
```

##### 2.7. Sentiment Analysis 
Sentiment Analysis என்பது உரையில் உள்ள உணர்ச்சிகளைப் பகுப்பாய்வு செய்யும் செயல்முறை. இது பொதுவாக நேர்மறை, எதிர்மறை, அல்லது நடுநிலை என வகைப்படுத்தப்படுகிறது.  

**எடுத்துக்காட்டு:**  
- உரை: "I love this product!"  
- Sentiment: Positive  

Why Use Sentiment Analysis?  

- வாடிக்கையாளர் கருத்துகளை பகுப்பாய்வு செய்ய உதவுகிறது.  
- சமூக ஊடக தரவுகளை புரிந்து கொள்ள உதவுகிறது.  

**Code:**

```python
from textblob import TextBlob

# உரை (Text)
text = "I love this product!"

# Sentiment Analysis
blob = TextBlob(text)
sentiment = blob.sentiment
print("Sentiment:", sentiment)
```

**Output:**  

```
Sentiment: Sentiment(polarity=0.625, subjectivity=0.6)
```

அதாவது, **Polarity** என்பது உரையின் உணர்வை (Positive/Negative/Neutral) அளவிடும் ஒரு மதிப்பு ஆகும்.

Polarity மதிப்பு **-1 முதல் +1** வரை இருக்கும்.

**+1:** Highly Positive

**0**: Neutral

**-1:** Highly Negative

இங்கு, **Polarity = 0.625** என்பதால், இந்த உரை Positive உணர்வைக் காட்டுகிறது.

**Subjectivity** என்பது உரையில் உள்ள தனிப்பட்ட (Personal) கருத்துகள் மற்றும் உணர்வுகளின் அளவை காண்பிக்கும் ஒரு மதிப்பு ஆகும்.

Subjectivity மதிப்பு **0 முதல் 1** வரை இருக்கும்:

**0:** Completely Objective

**1:** Completely Subjective

இங்கு, **Subjectivity = 0.6** என்பதால், இந்த உரை Subjective கருத்துகளுடன் அதிகமாக இருக்கிறது. இது உரை எழுதுபவரின் தனிப்பட்ட சிந்தனை மற்றும் உணர்ச்சியை அதிகமாக பிரதிபலிக்கிறது.

Code: [Colab Notebook](https://colab.research.google.com/drive/1kjYcGSH0bqGhV7jPeZ5wx2oaXu4sCUQB?usp=sharing)

<hr class="pagebreak">

### 3. சொல்லுக்குச் சொல் புரிதல் மற்றும் உரை உருவாக்கம்

##### 3.1. Bag of Words (BoW) 

இயல் மொழி தெளிதளில் (Natural Language Processing - NLP) உரைத் தரவுகளை எந்திரங்கள் புரிந்துகொள்வதற்கான மிக அடிப்படையான மாதிரிகளின் ஒன்று  Bag of Words (BoW) ஆகும். இந்த முறை 1950களில் Zellig Harris போன்ற மொழியியல் ஆய்வாளர்களால் முன்மொழியப்பட்டது. இன்று வரை எளிய உரை பகுப்பாய்வு பணிகளுக்கு இது முக்கியமாகப் பயன்படுத்தப்படுகிறது.

BoW முறையின் முக்கிய கருத்து என்னவென்றால், ஒரு பெரிய பையில் (bag) உரையில் உள்ள அனைத்து சொற்களையும் எடுத்து வீசுவதாக எண்ணுங்கள். இங்கே சொற்களின் வரிசை, இலக்கண அமைப்பு அல்லது சொற்றொடரின் சூழல் போன்றவை முழுமையாகப் புறக்கணிக்கப்படுகின்றன. மாறாக, ஒவ்வொரு சொல்லும் எத்தனை முறை தோன்றுகிறது என்பதை மட்டுமே கணக்கில் எடுத்துக்கொள்ளப்படுகிறது. இந்த அணுகுமுறை உரைத் தரவுகளை எண்ணியல் வடிவில் (numerical representation) மாற்ற உதவுகிறது.

---

###### எப்படி செயல்படுகிறது?

Bag of Words (BoW)-ன் செயல்முறையை மூன்று முக்கிய படிகளாகப் பிரிக்கலாம்:  

**1. சொற்களைத் தொகுத்தல் (Vocabulary Creation)**  

முதலில், கொடுக்கப்பட்ட அனைத்து உரைத் தரவுகளிலும் (வாக்கியங்கள், ஆவணங்கள்) உள்ள தனித்துவமான சொற்களை (unique words) தொகுத்து ஒரு **சொல் பட்டியல் (Vocabulary)** உருவாக்குகிறோம்.  

**எடுத்துக்காட்டுடன் விளக்கம்:**  

- **வாக்கியம் 1:** "I love programming."  
- **வாக்கியம் 2:** "Programming is fun."  

இந்த இரண்டு வாக்கியங்களிலிருந்து Vocabulary உருவாக்கும் போது:  
1. **ஒவ்வொரு வாக்கியத்தையும் சொற்களாகப் பிரிக்கிறோம் (Tokenization):**  
   - "I", "love", "programming" (முதல் வாக்கியம்)  
   - "Programming", "is", "fun" (இரண்டாம் வாக்கியம்)  
2. **தனித்துவமான சொற்களை மட்டும் எடுத்துக்கொள்கிறோம்:**  
   - "I", "love", "programming", "is", "fun"  
3. **Vocabulary உருவாகிறது:**  
   ```  
   Vocabulary = ["I", "love", "programming", "is", "fun"]  
   ```

> **குறிப்பு:**  
>
> - Vocabulary-ல் உள்ள சொற்களின் வரிசை முக்கியமில்லை, ஆனால் ஒவ்வொரு வாக்கியத்தையும் இதே வரிசையில் குறியாக்கம் செய்ய வேண்டும்.  
> - பொதுவாக, stop words ("I", "is" போன்றவை) நீக்கப்படலாம், ஆனால் இங்கே எளிமைக்காக வைத்துள்ளோம்.  

**2. சொற்களின் அதிர்வெண்ணைக் கணக்கிடுதல் (Frequency Calculation)**  

Vocabulary உருவான பிறகு, ஒவ்வொரு வாக்கியத்திலும் Vocabulary-ல் உள்ள சொற்கள் எத்தனை முறை வந்துள்ளன என்பதை எண்ணி, ஒரு **எண் வெக்டர் (Numerical Vector)** உருவாக்குகிறோம்.  

**Vocabulary:** ["I", "love", "programming", "is", "fun"]  

- **வாக்கியம் 1:** "I love programming."  
  - "I" → 1 (Vocabulary-ல் முதல் இடத்தில் உள்ளது)  
  
  - "love" → 1 (இரண்டாம் இடம்)  
  
  - "programming" → 1 (மூன்றாம் இடம்)  
  
  - "is" → 0 (வாக்கியத்தில் இல்லை)  
  
  - "fun" → 0 (வாக்கியத்தில் இல்லை)  
  
    இதன் வெக்டர்: [1, 1, 1, 0, 0]  
  
- **வாக்கியம் 2:** "Programming is fun."  
  
  - "I" → 0  
  
  - "love" → 0  
  
  - "programming" → 1  
  
  - "is" → 1  
  
  - "fun" → 1  
  
    இதன் வெக்டர்: [0, 0, 1, 1, 1]  

> **குறிப்பு:**  
> - ஒரு சொல் ஒரு வாக்கியத்தில் பல முறை வந்தால், அந்த எண்ணிக்கை வெக்டரில் காட்டப்படும்.  
>
> - எடுத்துக்காட்டு: "Programming is fun. I love programming." 
>
>   ["I", "love", "programming", "is", "fun"] → [1, 1, 2, 1, 1]  ("programming" 2 முறை வந்ததால், அதன் மதிப்பு 2).  

**3. வெக்டராக மாற்றுதல் (Vectorization)**  

கடைசியாக, ஒவ்வொரு வாக்கியமும் ஒரு **வெக்டராக** (எண்களின் வரிசை) மாற்றப்படுகிறது. இந்த வெக்டர்கள் எந்திர கற்றல் (Machine Learning) மாதிரிகளுக்கு உள்ளீடாகப் பயன்படுத்தப்படுகின்றன.  

- **வாக்கியம் 1:** "I love programming." → **[1, 1, 1, 0, 0]**  
- **வாக்கியம் 2:** "Programming is fun." → **[0, 0, 1, 1, 1]**  

இந்த வெக்டர்களைப் பயன்படுத்தி, எந்திரங்கள் உரைத் தரவைப் பகுப்பாய்வு செய்ய முடியும்.  

Bag of Words-ன் முக்கியத்துவம்

1. **எளிமை:**  

   BoW முறை மிகவும் எளிமையானது மற்றும் கணக்கிட எளிதானது.  

   - **உதாரணம் :**  

     - "I love programming." → [1, 1, 1, 0, 0]  

     இந்த முறை உரையை எளிதாக எண்ணியல் வடிவத்தில் மாற்றுகிறது, இது Machine Learning மாடல்களுக்கு உள்ளீடாக பயன்படுத்தப்படுகிறது.

2. **சொற்களின் அதிர்வெண்:**  

   BoW முறை உரையில் உள்ள சொற்களின் அதிர்வெண்ணை மட்டுமே கணக்கில் எடுத்துக்கொள்கிறது.  

   "Programming" என்ற சொல் இரண்டு வாக்கியங்களிலும் 1 முறை வந்துள்ளது. இது உரையின் முக்கிய சொற்களைக் கண்டறிய உதவுகிறது.

   ###### **Bag of Words-ன் குறைபாடுகள்**

   **சூழல் பற்றிய தகவல் இல்லை:**  

   BoW முறை சொற்களின் **வரிசை** அல்லது **சூழல்** பற்றி கவலைப்படுவதில்லை.  "The child makes the dog happy" மற்றும் "The dog makes the child happy" இரண்டும் ஒரே BoW வெக்டராகக் கருதப்படும்.   இது BoW முறையின் முக்கிய குறைபாடு, ஏனெனில் இது உரையின் அர்த்தத்தை முழுமையாக பிரதிபலிக்காது.

   **அரிய சொற்களுக்கு முக்கியத்துவம் குறைவு**

   அடிக்கடி வரும் சொற்களுக்கு (Frequent Words) அதிக முக்கியத்துவம் கொடுக்கப்படுகிறது. ஆனால், அரிய சொற்கள் (Rare Words) புறக்கணிக்கப்படுகின்றன.

---

###### Bag of Words-ன் பயன்பாடுகள்

1. **உரை வகைப்படுத்துதல் (Text Classification)**  

Bag of Words மாதிரியானது, உரையைக் கணித ரீதியாகப் பிரதிநிதித்துவப்படுத்தும் ஒரு எளிய முறை. இது உரையில் உள்ள சொற்களின் அதிர்வெண்ணை (frequency) அடிப்படையாகக் கொண்டு, உரையை வெவ்வேறு வகைகளாகப் பிரிக்க உதவுகிறது.  

**பயன்பாடு :**  

- **ஸ்பேம் மெயில் கண்டறிதல் (Spam Detection):**  
  - "Free offer! Win 1 crore!" போன்ற மெயில்களில் "Free", "Win", "Offer" போன்ற சொற்கள் அடிக்கடி வரும்.  
  - BoW இந்த சொற்களின் அடிப்படையில், மெயில் **ஸ்பேம்** அல்லது **ஹேம் இல்லை (Not Spam)** என வகைப்படுத்தும்.  

**எப்படி வேலை செய்கிறது?**  
1. முதலில், உரையிலிருந்து **முக்கியமான சொற்கள்** (keywords) பிரிக்கப்படுகின்றன.  
2. ஒவ்வொரு சொல்லும் ஒரு **எண்ணியல் மதிப்பு (frequency count)** பெறுகிறது.  
3. இந்த தரவு ஒரு **மாதிரி (Model)**-க்கு உணவளிக்கப்பட்டு, பயிற்சி அளிக்கப்படுகிறது.  

**2. உணர்வு பகுப்பாய்வு (Sentiment Analysis)**  

ஒரு உரையில் வெளிப்படும் உணர்வுகளை (மகிழ்ச்சி, வருத்தம், கோபம், நடுநிலை) பகுப்பாய்வு செய்ய BoW பயன்படுகிறது.  

**உதாரணம்:**  

- **"I love this product! It’s amazing."**  
  - "love", "amazing" போன்ற நேர்மறை சொற்கள் அதிகம் இருப்பதால், இது **நேர்மறை உணர்வு (Positive Sentiment)** என வகைப்படுத்தப்படும்.  
- **"This is terrible. Worst experience."**  
  - "terrible", "worst" போன்ற சொற்கள் **எதிர்மறை உணர்வு (Negative Sentiment)** என்பதைக் காட்டும்.  

**எப்படி வேலை செய்கிறது?**  
1. உரையில் உள்ள **உணர்வுசார் சொற்கள் (Sentiment Words)** அடையாளம் காணப்படுகின்றன.  
2. ஒவ்வொரு சொல்லுக்கும் ஒரு **எடை (Weight)** கிடைக்கிறது (எ.கா: "happy" → +1, "sad" → -1).  
3. மொத்த எடையின் அடிப்படையில் உணர்வு முடிவு எடுக்கப்படுகிறது.  

**3. தகவல் மீட்பு (Information Retrieval)**  
தேடுபொறிகள் (Google, Bing) ஒரு குறிப்பிட்ட கேள்விக்கு பொருத்தமான ஆவணங்களை (Documents) தேடி எடுப்பதற்கு BoW உதவுகிறது.  

**உதாரணம்:**  

- **"Python programming tutorials"** என்று தேடினால்:  
  - "Python", "programming", "tutorials" என்ற முக்கிய சொற்களைக் கொண்ட வலைப்பக்கங்கள் முதலில் காட்டப்படும்.  

**எப்படி வேலை செய்கிறது?**  
1. தேடல் வார்த்தைகள் **டோக்கனாக்கம் (Tokenization)** செய்யப்படுகின்றன.  
2. ஒவ்வொரு ஆவணத்திலும் இந்த சொற்கள் எத்தனை முறை வந்துள்ளன என்பதைப் பொறுத்து **ஒரு ஸ்கோர் (Score)** கணக்கிடப்படுகிறது.  
3. அதிக ஸ்கோர் உள்ள ஆவணங்கள் முதலில் காட்டப்படுகின்றன.  

#####  3.2. Embedding

**Embedding** என்பது, **ஒவ்வொரு Token-ஐயும் (சொல்லை) எண்ணியல் வெக்டராக மாற்றும் செயல்முறை**. இந்த வெக்டர்கள் **Neural Network**-களால் புரிந்து கொள்ளக்கூடிய வடிவத்தில் இருக்கும். இது LLM-களுக்கு **சொற்களுக்கு இடையே உள்ள தொடர்புகளைக் கற்றுக்கொள்ள** உதவுகிறது.

###### Embedding-கள் என்றால் என்ன?

Embedding-கள் என்பது ஒரு வகையான **தரவு பிரதிநிதித்துவம் (Data Representation)**. இது உரை (text), படங்கள் (images), ஒலி (audio) போன்ற தரவுகளை எண்களாக மாற்றி, கணினிகள் புரிந்து கொள்ளும் வகையில் காட்டுகிறது. Embedding-கள் முக்கியமாக **Natural Language Processing (NLP)**-ல் பயன்படுத்தப்படுகிறது, அங்கு வார்த்தைகள், வாக்கியங்கள் அல்லது பத்திகள் எண்களாக மாற்றப்படுகின்றன.

இந்த எம்பெடிங் செயல்முறையில், ஒவ்வொரு டோக்கனும் ஒரு தனித்துவமான **தொடர்ச்சியான வெக்டர்** (continuous vector) ஆக மாற்றப்படுகிறது. இந்த வெக்டர்களின் பரிமாணங்கள் (dimensions) பொதுவாக 100 முதல் 1000 வரை அல்லது அதற்கும் மேலாக இருக்கும். எடுத்துக்காட்டாக, GPT-3 போன்ற மாடல்களில் ஒவ்வொரு டோக்கனுக்கும் **768 பரிமாணங்கள்** உள்ளன.

இந்த எம்பெடிங் வெக்டர்கள் **நியூரல் நெட்வொர்க்குகள்** (neural networks) புரிந்து கொள்ளக்கூடிய வடிவத்தில் இருக்கும். இவை சொற்களின் **சொற்பொருள் பண்புகள்** (semantic features) மற்றும் **இலக்கணப் பண்புகள்** (syntactic features) ஆகிய இரண்டையும் பிரதிபலிக்கின்றன. எம்பெடிங்ஸின் முக்கிய நோக்கம் **சொற்களுக்கிடையேயான உறவுகளை** (word relationships) கணித ரீதியாக வெளிப்படுத்துவதாகும்.

எம்பெடிங்ஸ் என்பது ஒரு வகையான **டிஸ்ட்ரிபியூட்டெட் ரிப்பிரசென்டேஷன்** (distributed representation) ஆகும், இதில் ஒவ்வொரு சொல்லின் பொருளும் அதன் வெக்டரின் பல பரிமாணங்களில் பரவிக் காணப்படுகிறது. இது **வார்த்தைத் தொகுப்புகள்** (word embeddings), **வாக்கிய எம்பெடிங்ஸ்** (sentence embeddings) மற்றும் **ஆவண எம்பெடிங்ஸ்** (document embeddings) போன்ற பல வடிவங்களில் வருகிறது.

இந்த தொழில்நுட்பம் **டீப் லர்னிங்** (deep learning) மாடல்களுக்கு உள்ளீடாகப் பயன்படுகிறது. எம்பெடிங்ஸ் மூலம் மெஷின்கள் சொற்களின் பொருள், அவற்றுக்கிடையேயான உறவுகள் மற்றும் சூழல்-சார்ந்த அர்த்தங்களைப் புரிந்து கொள்ள முடிகிறது. இது **இயந்திர மொழிபெயர்ப்பு** (machine translation), **உணர்ச்சி பகுப்பாய்வு** (sentiment analysis) மற்றும் **வினா-விடை அமைப்புகள்** (question answering systems) போன்ற பல NLP பயன்பாடுகளுக்கு அடிப்படையாக அமைகிறது.

எப்படி Embedding-கள் செயல்படுகின்றன?

**"King" என்ற வார்த்தையின் எம்பெடிங் வெக்டார் :**  

`[0.95, -0.12, 0.87, ..., 0.91]`  

இந்த எண்கள் ஒவ்வொன்றும் "King" என்ற வார்த்தையின் **குறிப்பிட்ட பண்புகளை (Features)** கணித ரீதியாக குறிக்கின்றன. முதல் எண் `0.95` என்பது "King" க்கும் ராயல்டிக்கும் உள்ள **நேர்மறை தொடர்பை** காட்டுகிறது. இரண்டாவது எண் `-0.12` என்பது "King" **ஆண்-சார்பான** வார்த்தை என்பதை குறிக்கிறது (எதிர்மறை மதிப்பு = பெண்/நடுநிலைத் தொடர்பு குறைவு).  "Queen" என்ற வார்த்தையின் இதே பண்பு `+0.15` போல் இருக்கலாம் (பெண்-சார்பு).  மூன்றாவது எண் `0.87` -ண் பண்பு *"Authority" (அதிகாரம்/ஆதிக்கம்)*  இது "King" க்கு **அதிகாரம்** உள்ளது என்பதை வலுவாக குறிக்கிறது (அதிக நேர்மறை மதிப்பு).  இதுவே "Servant" போன்ற வார்த்தைகளில் இந்த பண்பு `-0.90` ஆக இருக்கலாம்.  கடைசி எண்ணின் பண்பு "Human Entity" மனிதத் தன்மை (`0.91`)  அதாவது "King" ஒரு **மனிதர்** என்பதை குறிக்கிறது. "God" போன்ற வார்த்தைகளில் இது `0.10` ஆகவும், "Robot"ல் `-0.30` ஆகவும் இருக்கும்.  

**ஏன் இந்த எண்கள் மாறுபடுகின்றன?**  

- **நேர்மறை மதிப்பு (`0.87`):** அந்த பண்புடன் **வலுவான தொடர்பு**.  
- **எதிர்மறை மதிப்பு (`-0.12`):** அந்த பண்புடன் **எதிர் தொடர்பு**.  
- **பூஜ்யம் அருகே (`0.25`):** **மிதமான/இருப்புத் தொடர்பு**.  

இந்த வெக்டர்கள் பொதுவாக **100 முதல் 1000 வரையிலான பரிமாணங்களைக் கொண்டிருக்கும்**.  GPT-3 மாடல்களில், ஒவ்வொரு Token-க்கும் **768 பரிமாணங்கள்** உள்ளன. ஒவ்வொரு சொல்லும் 768 எண்களைக் கொண்ட ஒரு வெக்டராக மாற்றப்படுகிறது. இது அந்த சொல்லின் **சிக்கலான பண்புகளை** பிரதிபலிக்கிறது.

###### Bag of Words vs Embedding

| **Feature**       | **Bag of Words (BoW)**                 | **Embedding**                                      |
| ----------------- | -------------------------------------- | -------------------------------------------------- |
| **சொற்களின் அர்த்தம்** | சொற்களின் அதிர்வெண்ணை மட்டுமே கணக்கிடுகிறது. | சொற்களின் பொருள் மற்றும் சூழலைப் பிரதிபலிக்கிறது.         |
| **சொற்களின் வரிசை** | சொற்களின் வரிசை பற்றி கவலைப்படுவதில்லை.     | சொற்களின் வரிசை மற்றும் சூழலைக் கணக்கில் எடுத்துக்கொள்கிறது. |
| **சிக்கலான தன்மை**  | எளிமையானது மற்றும் கணக்கிட எளிதானது.      | மிகவும் சிக்கலானது மற்றும் கணக்கிட கடினமானது.           |
| **பயன்பாடு**       | எளிய NLP பணிகளுக்கு பயன்படுத்தப்படுகிறது.  | நவீன NLP பணிகளுக்கு பயன்படுத்தப்படுகிறது.               |

##### 3.3. Word2Vec:

Word2Vec என்பது **வார்த்தைகளை வெக்டர்களாக (vectors) மாற்றும் ஒரு தொழில்நுட்பம்** ஆகும். இது வார்த்தைகளுக்கு இடையேயான உறவுகளை (relationships) ஒரு வரைபடம் (graph) போன்று பிரதிநிதித்துவப்படுத்துகிறது. இந்த தொழில்நுட்பம் machine learning மற்றும் text analysis போன்ற துறைகளில் பரவலாக பயன்படுத்தப்படுகிறது.

2013-ல் Google தங்கள் தேடுபொறிக்காக (search engine) Word2Vec-ஐ அறிமுகப்படுத்தியது, மேலும் இந்த அல்காரிதத்தை பேட்டன்ட் செய்தது. இந்த தொழில்நுட்பத்தை Tomas Mikolov மற்றும் அவரது குழுவினர் உருவாக்கினர். உரை பகுப்பாய்வில், ஒரு வார்த்தையை பிரதிநிதித்துவப்படுத்த **Word Embedding** பயன்படுத்தப்படுகிறது. இது பொதுவாக ஒரு திசையன் (vector) வடிவில் இருக்கும், இது வார்த்தையின் அர்த்தத்தை குறியாக்கம் (encode) செய்கிறது. இந்த திசையன் வெளி (vector space) ஒரே மாதிரியான அர்த்தம் கொண்ட வார்த்தைகள் ஒன்றுக்கொன்று அருகில் இருக்கும்.

 Word2Vec-ல் இரண்டு முக்கியமான கற்றல் முறைகள் உள்ளன, ஒவ்வொன்றும் தனித்துவமான வழிகளில் சொற்களுக்கிடையேயான மறைந்த உறவுகளைக் கண்டறிகின்றன.

முதல் முறையான **CBOW (Continuous Bag of Words)** ஒரு வார்த்தை புதிரைத் தீர்க்கும் பழைய மனிதனைப் போல செயல்படுகிறது. சூழலில் உள்ள வார்த்தைகளைப் பார்த்து, காணாமல் போன மைய வார்த்தையை யூகிக்க முயற்சிக்கிறது. "மூன்று நாட்களாக மழை ___ பெய்து கொண்டிருக்கிறது" என்ற வாக்கியத்தில், "தொடர்ந்து" என்ற வார்த்தையை சரியாகக் கணிக்கிறது. இந்த முறை சிறிய தரவுத் தொகுப்புகளில் விரைவாகவும் திறம்படவும் வேலை செய்கிறது, குறிப்பாக அடிக்கடி பயன்படுத்தப்படும் வார்த்தைகளுக்கு சிறந்த துல்லியத்தைத் தருகிறது.

இரண்டாவது முறையான **Skip-Gram** இதற்கு நேர் எதிர்மாறாக செயல்படுகிறது. இது ஒரு கற்றுக்கொடுக்கும் ஆசிரியரைப் போன்றது, ஒரு மைய வார்த்தையிலிருந்து அதைச் சுற்றியுள்ள வார்த்தைகளைக் கற்பிக்கிறது. "கணினி" என்ற வார்த்தையைக் கொடுத்தால், "மின்னணு", "தொழில்நுட்பம்", "இணையம்" போன்ற தொடர்புடைய வார்த்தைகளை உருவாக்குகிறது. இந்த முறை பெரிய தரவுத் தொகுப்புகளில் சிறப்பாக செயல்படுகிறது, குறிப்பாக அரிதாகப் பயன்படுத்தப்படும் சிறப்பு வார்த்தைகளுக்கு துல்லியமான முடிவுகளைத் தருகிறது.

இந்த இரண்டு முறைகளுக்கும் இடையே உள்ள வேறுபாடுகள் மிகவும் சுவாரஸ்யமானவை. CBOW முறை ஒரு வார்த்தையைக் கணிக்கும் போது அதைச் சுற்றியுள்ள வார்த்தைகளின் சராசரி எம்பெடிங்கைப் பயன்படுத்துகிறது, இது ஒரு குழந்தை புதிர்களைத் தீர்க்கும் விதத்தை ஒத்திருக்கிறது. மறுபுறம், Skip-Gram முறை ஒவ்வொரு சூழல் வார்த்தைக்கும் தனித்தனியாக பயிற்சி அளிக்கிறது, இது ஒரு ஆசிரியர் ஒவ்வொரு மாணவருக்கும் தனித்துவமான கவனத்தை அளிப்பதைப் போன்றது.

நவீன Word2Vec செயலாக்கங்களில் எதிர்மறை மாதிரியாக்கம் மற்றும் படிநிலைக் குறைப்பு போன்ற மேம்பட்ட நுட்பங்கள் பயன்படுத்தப்படுகின்றன. இவை மாதிரிகளின் செயல்திறனைக் கணிசமாக மேம்படுத்துகின்றன, குறிப்பாக பெரிய சொல் களஞ்சியங்களுடன் பணிபுரியும் போது. எதிர்மறை மாதிரியாக்கம் முறை சில தவறான வார்த்தை ஜோடிகளை உருவாக்கி, மாதிரி அவற்றிலிருந்து கற்றுக்கொள்வதை உறுதி செய்கிறது. படிநிலைக் குறைப்பு முறை சொற்களை ஒரு மரவடிவில் அமைத்து, கணக்கீட்டு சிக்கலானைக் குறைக்கிறது.

இந்த முறைகள் உருவாக்கும் 300 பரிமாண எம்பெடிங்ஸ் மொழியின் சிக்கலான உறவுகளைப் பிடிக்க போதுமானவை. இவை "அரசன் - ஆண் + பெண் = அரசி" போன்ற மாயமான கணித உறவுகளை வெளிக்காட்டுகின்றன. 

**எம்பெடிங் உறவுகளை எப்படி பயன்படுத்துவது?**  

Embedding-கள் சொற்களின் பொருளைப் பிரதிபலிக்கின்றன. "King" மற்றும் "Queen" என்ற சொற்கள் ஒரே மாதிரியான Embedding-களைக் கொண்டிருக்கும், ஏனெனில் அவை இரண்டும் **அரசர்களை** குறிக்கின்றன. ஆனால், அவை வெவ்வேறு பாலினங்களைக் குறிப்பதால், அவற்றின் Embedding-கள் சிறிது வேறுபடும்.

"King" - "Man" + "Woman" ≈ "Queen"  

இந்த கணித செயல்பாடு, "King" என்ற சொல்லின் Embedding-லிருந்து "Man" என்ற சொல்லின் Embedding-ஐ கழித்து, "Woman" என்ற சொல்லின் Embedding-ஐ கூட்டினால், "Queen" என்ற சொல்லின் Embedding கிடைக்கும். இது Embedding-கள்  சொற்களுக்கு இடையே உள்ள தொடர்புகளைப் புரிந்து  கொள்வதைக் காட்டுகிறது.

இதைத் தமிழில் புரிந்துகொள்வோம்:

**"அரசன் - ஆண் + பெண் ≈ அரசி"**

`vector("அரசன்") - vector("ஆண்") + vector("பெண்") ≈ vector("அரசி")`

1. **ஒவ்வொரு சொல்லும் ஒரு எண் வரிசை (Vector):**

   - "அரசன்" = [0.8, 0.2, 0.7,...]
   - "ஆண்" = [0.9, 0.1, 0.6,...]
   - "பெண்" = [0.1, 0.9, 0.6,...]

2. **கணித செயல்பாடு:**

   ```
   [அரசன் வெக்டர்] - [ஆண் வெக்டர்] + [பெண் வெக்டர்]
   = [0.8-0.9+0.1, 0.2-0.1+0.9, 0.7-0.6+0.6,...]
   ≈ [0.0, 1.0, 0.7,...] (இது "அரசி" வெக்டருக்கு அருகில்)
   ```

3. **ஏன் இது வேலை செய்கிறது?**

   - எம்பெடிங்ஸ் **பாலினம்** (Gender) போன்ற பண்புகளை தனித்த பரிமாணங்களில் சேமிக்கிறது
   - "அரசன்" - "ஆண்" = "அரச தன்மை" (Royalty without gender)
   - "அரச தன்மை" + "பெண்" = "அரசி"

4. **செயல்பாட்டு விளக்கம்:**

   ```plaintext
   அரசன்: [அரச தன்மை + ஆண்மை]
   - ஆண்: [ஆண்மை]
   + பெண்: [பெண்மை]
   ----------------------------
   அரசி: [அரச தன்மை + பெண்மை]
   ```

Word2Vec இன் CBOW மற்றும் Skip-Gram முறைகள் இன்றைய இயல் மொழி செயலாக்க அமைப்புகளின் அடித்தளமாகத் தொடர்கின்றன, மனித மொழியின் நுணுக்கங்களை இயந்திரங்கள் புரிந்துகொள்ள உதவுகின்றன.

இங்கே உங்கள் உரையை **உரையோட்டமான**, **துல்லியமான**, மற்றும் **சூழலுடனான** வகையில் திருத்தி வழங்குகிறேன் — தொழில்நுட்பமானது நன்கு விவரிக்கப்படும் போது மொழியிலும் சீரான ஓட்டம் அமையும்.

**Word2Vec-ன் பயன்பாடுகள் மற்றும் வரம்புகள்**

Word2Vec என்பது இயற்கை மொழி செயலாக்கம் (Natural Language Processing) துறையில் ஒரு முக்கியமான முன்னேற்றமாகும். இது சொற்கள் மற்றும் அவற்றுக்கிடையிலான அர்த்த உறவுகளை எண்கள் மூலமாக நிர்வகிக்கக்கூடிய representations-ஆக மாற்றி, பல்வேறு துறைகளில் செயல்திறனை கணிசமாக மேம்படுத்தியுள்ளது.

Word2Vec-ன் முக்கியமான பயன்பாடுகளில் ஒன்று **தேடுபொறிகள் (Search Engines)** ஆகும். எடுத்துக்காட்டாக, “apple” என்ற வார்த்தையை எடுத்துக்கொண்டால், அது பழத்தைக் குறிக்கிறதா அல்லது தொழில்நுட்ப நிறுவனத்தைக் குறிக்கிறதா என்பதை அதன் **context** அடிப்படையில் Word2Vec வேறுபடுத்த முடியும். இந்த வகையான semantic precision, தேடல் முடிவுகளின் பொருத்தத்தையும் பயனருக்கு கிடைக்கும் தகவலின் தரத்தையும் அதிகரிக்கிறது.

அதேபோல், **மொழிபெயர்ப்பு (Machine Translation)** பணிகளிலும் Word2Vec முக்கிய பங்காற்றுகிறது. கூகுள் டிரான்ஸ்லேட் போன்ற நவீன மொழிபெயர்ப்பு கருவிகள், சொற்களின் semantic embeddings-ஐ பயன்படுத்தி பல்வேறு மொழிகளில் ஒரே அர்த்தத்தைக் கொண்ட சொற்களை ஒப்பிட முடிகிறது. இதனால் மொழிபெயர்ப்புகள் இன்னும் இயல்பானவையாகவும், துல்லியமாகவும் அமைகின்றன.

**வணிக அனலிட்டிக்ஸ்** துறையிலும் Word2Vec பரவலாக பயன்படுத்தப்படுகிறது. நிறுவனங்கள் வாடிக்கையாளர்களின் மதிப்புரைகள், கருத்துகள் மற்றும் சமூக ஊடக பதிவுகளைக் கொண்டு **மனநிலை பகுப்பாய்வு (Sentiment Analysis)** செய்வதற்காக இந்த மாடலை பயன்படுத்துகின்றன. இது வாடிக்கையாளர் அனுபவத்தை மேம்படுத்துவதற்கும் தயாரிப்புத் திட்டங்களை வழிநடத்துவதற்கும் பயன்படுகிறது.

மேலும், **தனிப்பயனாக்கப்பட்ட பரிந்துரை அமைப்புகள் (Recommendation Systems)**-ல் Word2Vec ஒரு முக்கிய கருவியாக செயல்படுகிறது. பயனர்களின் முந்தைய தேடல்கள், வாங்கிய பொருட்கள், அல்லது பார்த்த உள்ளடக்கங்களின் அடிப்படையில், அவற்றின் embeddings மூலம் சம்பந்தப்பட்ட மற்றும் பிடிக்கக்கூடிய பரிந்துரைகளை உருவாக்க முடிகிறது. இதற்கான முக்கிய எடுத்துக்காட்டு — Amazon-ல் “அதனை வாங்கியவர்கள் இதனையும் வாங்கினார்கள்” அல்லது Netflix-ல் “உங்களுக்கு விருப்பமான மற்றத் தொடர்கள்” போன்ற பரிந்துரைகள்.

Word2Vec-ல் சில குறிப்பிடத்தக்க வரம்புகள் உள்ளன. முதன்மையானதாக, Word2Vec **பயிற்சி தரவுத்தொகுப்பில் இல்லாத புதிய (unseen) சொற்களை** கையாள முடியாது. இந்த ‘Out-of-Vocabulary’ (OOV) பிரச்சனை, குறிப்பாக பன்மொழி மற்றும் வளர்ந்து வரும் மொழிகளில், ஒரு முக்கிய தடையாக இருக்கிறது.

இரண்டாவது, Word2Vec ஒவ்வொரு வார்த்தையையும் **ஒரு தனி அலகாக** கருதுகிறது. எனவே “run”, “runner”, “running” போன்ற வார்த்தைகளுக்கிடையிலான morphological தொடர்புகளைப் புரிந்துகொள்ள முடியாது. இது subword-level தகவல்களை (பிரிக்கக்கூடிய வேர்ச்சொல் அமைப்புகள்) புறக்கணிக்கிறது. இதற்கான பதிலாக, **FastText** போன்ற மாடல்கள் உருவாக்கப்பட்டன.

மூன்றாவது, புதிய அல்லது குறைவாக பேசப்படும் மொழிகளில் Word2Vec மாதிரியை பயிற்சி செய்ய **பெரிய மற்றும் தரமான corpus** தேவைப்படும். இது resource-poor மொழிகளில் இதை பயனுள்ளதாக உருவாக்க கடினமாக்குகிறது.

இந்த எல்லைகள் இருந்தபோதிலும், Word2Vec இன்னும் பல NLP பணிகளுக்கு ஒரு **அடித்தளமான பங்கு** வகிக்கிறது. அதன் **எளிமையும்**, **வேகமான பயிற்சித்திறனும்**, **பயனுள்ள semantic representations**-ஐ உருவாக்கும் திறனும், இதனை இன்றும் பரவலாகப் பயன்படுத்தத்தக்கதாக்குகின்றன.

**Python-ல் Word2Vec மாதிரியை பயிற்சி செய்தல்:**

```python
from gensim.models import Word2Vec

# உதாரண வாக்கியங்கள்
sentences = [
    ["I", "love", "machine", "learning"],
    ["AI", "is", "fascinating"],
    ["I", "study", "NLP"]
]

# Word2Vec மாதிரியை பயிற்சி செய்தல்
model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

# "king" என்ற வார்த்தையின் embedding-ஐ பெறுதல்
king_vector = model.wv['king']
print("ராஜா-ன் embedding:", king_vector)

# "king" என்ற வார்த்தைக்கு ஒத்த வார்த்தைகளை கண்டறிதல்
similar_words = model.wv.most_similar('king')
print("ராஜா-க்கு ஒத்த வார்த்தைகள்:", similar_words)
```

Gensim-ஐப் பயன்படுத்தி **Word2Vec** மாடல் ஒவ்வொரு வார்த்தைக்கும் ஒரு எம்பெடிங் (vector representation) உருவாக்குகிறது. மாடல் இந்த எம்பெடிங்களைக் கொண்டு வார்த்தைகளுக்கு இடையிலான தொடர்பை (semantic similarity) கண்டறிகிறது.

model.wv.most_similar('king') என்ற அழைப்பின் மூலம், **“king”** என்ற வார்த்தைக்கு ஆக்க பக்கத்தில் உள்ள தொடர்புடைய வார்த்தைகளை (similar words) கண்டறிகிறது.

```python
 [('ruler', 0.25290292501449585), ('queen', 0.1703130453824997), 
 ('are', 0.15026721358299255), 
 ('fascinating', 0.13887712359428406), 
 ('NLP', 0.10853718221187592), 
 ('love', 0.03476576507091522), 
 ('and', 0.01612497679889202), 
 ('I', 0.00450251717120409), 
 ('study', -0.005892974324524403), 
 ('is', -0.02770209312438965)]
```

('ruler', 0.2529): “ruler” என்பது **king**-க்கு மிக அண்மையான பொருள் கொண்ட வார்த்தை என மாடல் கருதுகிறது. இந்த similarity score **0.2529** என்பது **king** மற்றும் **ruler** வார்த்தைகளின் வெக்டர் இடையிலான cosine similarity அடிப்படையில் கணக்கிடப்பட்டது.

('queen', 0.1703): “queen” என்பது **king**-க்கான தொடர்புடைய மற்றொரு வார்த்தையாக இருக்கிறது. இது “ruler”-க்கு அடுத்தடுத்த பொருளுடையது, ஆனால் குறைவான ஒத்தபாடுடையது (**0.1703**).

('are', 0.1503): இது எம்பெடிங் டேட்டாவிலிருந்து, **are** என்ற வார்த்தை “king”-க்குப் பக்கத்தில் தோன்றியதால் ஒத்தவாறு தெரிகிறது.

('fascinating', 0.1389): இதுவும் **king**-க்கு தொடர்புடையதாக கண்டறியப்பட்டது, ஆனால் semantic தொடர்பு (பொருள் தொடர்பு) இல்லாமல், கற்றல் தரவின் அடிப்படையில் மட்டும் தோன்றுகிறது.

('NLP', 0.1085): **NLP** போன்ற வார்த்தை காரணமாக, மாதிரி மிகச்சிறிய data-வில் இருந்து இதுபோன்ற தவறான தொடர்புகளை வெளிப்படுத்துகிறது.

('love', 0.0347) மற்றும் பிற வார்த்தைகள்: இது மிகவும் குறைந்த ஒத்தபாடுடையது, எனவே **king**-க்கு இது பொருத்தமற்றது எனவும் கூறலாம்.

இங்கே பயிற்சி செய்த தரவுத்தொகுப்பு (sentences) மிகச் சிறியது, மற்றும் “king” வார்த்தையை சரியான “context”-இல் அதிகமில்லை. ஆகவே, பல வார்த்தைகள் அவற்றின் உண்மையான semantic தொடர்புகளைச் சரியாக பிரதிபலிக்க முடியவில்லை.

**தீர்வு**: பெரிய மற்றும் பலதரப்பட்ட dataset-ல் மாடலை train செய்ய வேண்டும். “king” போன்ற வார்த்தைகள் ஏற்ற semantic context-இல் (e.g., royalty, leadership) அடிக்கடி தோன்ற வேண்டும்.

Word2Vec என்பது உரை தரவை கணினிகள் புரிந்து கொள்ளும் வகையில் எண்களாக மாற்றும் ஒரு சக்திவாய்ந்த கருவி. இது NLP-ல் மிகவும் முக்கியமானது மற்றும் மெஷின் கற்றல் மாதிரிகளின் துல்லியத்தை மேம்படுத்துகிறது. Word2Vec-ன் இரண்டு முறைகள் (CBOW மற்றும் Skip-Gram) மூலம், வார்த்தைகளின் அர்த்தம் மற்றும் தொடர்புகளை பிரதிநிதித்துவப்படுத்த முடியும்.

##### 3.4. Sequence-to-Sequence (Seq2Seq): Seq2Seq மாடல்கள் - ஒரு அறிமுகம்

###### என்கோடர் & டிகோடர்: இயல் மொழி தெளிதலின் இரு தூண்கள்

கணினிகள் நம்மைப் போல தமிழ் பேசவோ, படிக்கவோ, புரிந்துகொள்ளவோ முடியாது. ஆனால்,  என்கோடர் மற்றும் டிகோடர் என்ற இரண்டு  சக்திவாய்ந்த கருவிகள் மூலம், தமிழ் மொழியை கணினிக்குப் புரியும்  எண்களாக மாற்றி, மீண்டும் தமிழிலேயே  பதில்களை உருவாக்க முடியும்.  என்கோடர் தமிழ் வார்த்தைகளை எண்களாக மாற்றும்; டிகோடர் அந்த எண்களை மீண்டும் தமிழ் வார்த்தைகளாக மாற்றும். இந்த தொழில்நுட்பம், இயந்திர மொழிபெயர்ப்பு,  உரை சுருக்கம்,  கேள்வி பதில் போன்ற பல  பணிகளுக்கு  உதவுகிறது.   என்கோடர் மற்றும் டிகோடர் எப்படி வேலை செய்கிறது என்பதை இந்த பதிவில் விரிவாகப் பார்க்கலாம்.

**என்கோடர் (Encoder)**

**1. டோக்கனைசேஷன் (Tokenization): வார்த்தைகளை சிறு பகுதிகளாகப் பிரித்தல்**

Encoder-ல் சங்கத்தமிழ் பாடல் வரிகளை கம்ப்யூட்டருக்குப் புரியவைக்க, முதலில் அவற்றை சிறிய பகுதிகளாகப் பிரிக்க வேண்டும். இந்த சிறிய பகுதிகள் டோக்கன்கள் (Tokens) என்று அழைக்கப்படுகின்றன. உதாரணமாக, **"அகர முதல எழுத்தெல்லாம்"** என்ற வரியை எடுத்துக் கொள்வோம். டோக்கனைசேஷன் முறையில் இதை:

["அ", "க", "ர", " ", "மு", "த", "ல", " ", "எ", "ழு", "த்", "தெ", "ல்", "லா", "ம்"]

என்று பிரிக்கலாம். இங்கு இடைவெளிகளும் (" ") டோக்கன்களாகக் கருதப்படுகின்றன.

**2. சொல்லகராதி (Vocabulary) உருவாக்குதல்: ஒவ்வொரு டோக்கனுக்கும் தனித்துவமான எண்**

டோக்கனைசேஷன் செய்த பிறகு, ஒவ்வொரு டோக்கனுக்கும் ஒரு தனித்துவமான எண்ணை ஒதுக்க வேண்டும். இது ஒரு சொல்லகராதியை (Vocabulary) உருவாக்குவதற்கு உதவுகிறது.

உதாரணமாக:

- "அ" → 31
- "க" → 43
- "ர" → 59
- " " → 2
- "மு" → 57
- "த" → 69
- "ல" → 52
- "எ" → 61
- "ழு" → 37
- "த்" → 63
- "தெ" → 77
- "ல்" → 71
- "லா" → 66
- "ம்" → 88

இந்த சொல்லகராதி, ஒவ்வொரு டோக்கனையும் கம்ப்யூட்டருக்குப் புரியும் எண்ணாக மாற்ற உதவுகிறது.

**3. எம்பெடிங் (Embedding): எண்களை வெக்டர்களாக மாற்றுதல்**

ஒவ்வொரு டோக்கனுக்கும் ஒதுக்கப்பட்ட எண்ணை, எம்பெடிங் (Embedding) செயல்முறை மூலம் வெக்டர்களாக மாற்றுகிறோம். வெக்டர்கள் என்பது பல பரிமாணங்களைக் கொண்ட எண்களின் பட்டியல்.

"அகர முதல" என்ற டோக்கன்களை எண்களாக மாற்றிய பிறகு, [31, 43, 59, 2, 57, 69, 52] என்று கிடைக்கும். ஒவ்வொரு எண்ணையும் எம்பெடிங் செயல்முறை மூலம் வெக்டர்களாக மாற்றுகிறோம்.

- 31 → [0.1, -0.5, 0.8, ...]
- 43 → [0.2, 0.3, -0.1, ...]
- 59 → [-0.4, 0.6, 0.2, ...]
- 2 → [0.9, -0.2, 0.7, ...]
- 57 → [-0.3, 0.1, 0.5, ...]
- 69 → [0.7, 0.4, -0.6, ...]
- 52 → [-0.8, 0.9, 0.3, ...]

இந்த எம்பெடிங் வெக்டர்கள், ஒவ்வொரு டோக்கனின் அர்த்தத்தையும், தொடர்பையும் கம்ப்யூட்டருக்குப் புரிய வைக்க உதவுகின்றன.

**4. ஹிட்டன் ஸ்டேட்கள் (Hidden States): சூழல் தகவலை நினைவில் கொள்ளுதல்**

எம்பெடிங் செய்யப்பட்ட வெக்டர்களை, ரிக்கரண்ட் நியூரல் நெட்வொர்க் (RNN) போன்ற தொடர்முறை நரம்பியல் நெட்வொர்க்குகளைப் பயன்படுத்தி ஹிட்டன் ஸ்டேட்களாக மாற்றுகிறோம். 

RNN-ல் ஒவ்வொரு டோக்கனும் அனுப்பப்படும்போது, அது முந்தைய ஹிட்டன் ஸ்டேட்களை கணக்கில் கொண்டு ஒரு புதிய ஹிட்டன் ஸ்டேட் உருவாக்குகிறது. இந்த ஹிட்டன் ஸ்டேட்கள், வாக்கியத்தின் சூழலுக்கேற்ப விவரங்களைச் சேமிக்கின்றன.

உதாரணமாக:

- "அ" → Hidden State 1 (ஆரம்ப நிலை)
- "க" → Hidden State 2 (Hidden State 1 + "க") → அக
- "ர" → Hidden State 3 (Hidden State 2 + "ர") → அகர
- " " → Hidden State 4 (Hidden State 3 + Space) →அகர_
- "மு" → Hidden State 5 (Hidden State 4 + "மு") → அகர _ மு
- "த" → Hidden State 6 (Hidden State 5 + "த") → அகர _ முத
- "ல" → Hidden State 7 (Hidden State 6 + "ல") →அகர _ முதல

ஒவ்வொரு ஹிட்டன் ஸ்டேட்டும் முந்தைய ஹிட்டன் ஸ்டேட்களின் தகவல்களை ஒருங்கிணைத்தே உருவாகிறது. எனவே, கடைசி ஹிட்டன் ஸ்டேட் (Hidden State 7) முழு வாக்கியத்தையும் பிரதிபலிக்கும்.

**5. கான்டெக்ஸ்ட் வெக்டர் (Context Vector): ஒட்டுமொத்த தகவலின் சுருக்கம்**

கான்டெக்ஸ்ட் வெக்டர் என்பது என்கோடரின் கடைசி ஹிட்டன் ஸ்டேட் ஆகும். இது, முழு வாக்கியத்தின் சாரத்தை சுருக்கமாக கொண்டிருக்கும்.

உதாரணமாக "அகர முதல" என்ற வாக்கியத்தின் கான்டெக்ஸ்ட் வெக்டர், Hidden State 7 ஆக இருக்கும். இது, முழு வாக்கியத்தின் அர்த்தத்தையும், சூழலையும் சுருக்கமாக கொண்டிருக்கும். இந்த கான்டெக்ஸ்ட் வெக்டர், டிகோடருக்கு முக்கியமான தகவலாகும். 

சரி, இப்போது டிகோடர் செயல்முறையை விரிவாகப் பார்ப்போம்.

**டிகோடர் (Decoder)** - எண்களை மீண்டும் சங்கத்தமிழ் பாடலாக மாற்றுதல்

டிகோடர் என்பது என்கோடரால் உருவாக்கப்பட்ட கான்டெக்ஸ்ட் வெக்டரைப் பயன்படுத்தி,  மீண்டும் சங்கத்தமிழ் பாடல் வரிகளை உருவாக்கும் செயல்முறையாகும். இதுவும் பல படிகளைக் கொண்டது.

**1. இனிஷியல் ஸ்டேட் (Initial State): தொடக்க நிலை**

டிகோடரின் தொடக்க நிலை, என்கோடரின் கடைசி ஹிட்டன் ஸ்டேட்டாக (கான்டெக்ஸ்ட் வெக்டர்) இருக்கும். இது டிகோடருக்கு, மொழிபெயர்ப்பு அல்லது பாடல் வரி உருவாக்கத்திற்கான ஆரம்ப தகவலை வழங்குகிறது.

உதாரணமாக, "அகர முதல" என்ற வாக்கியத்திற்கு, என்கோடரின் கடைசி ஹிட்டன் ஸ்டேட் (Hidden State 7) டிகோடரின் ஆரம்ப நிலையாக கருத்தில் கொள்ளும்.

**2. டோக்கன் ஜெனரேஷன் (Token Generation): வார்த்தைகளை உருவாக்குதல்**

டிகோடர், கான்டெக்ஸ்ட் வெக்டரைப் பயன்படுத்தி அடுத்தடுத்த டோக்கன்களை உருவாக்குகிறது. ஒவ்வொரு டோக்கனும், முந்தைய டோக்கன்கள் மற்றும் கான்டெக்ஸ்ட் வெக்டரின் அடிப்படையில் உருவாக்கப்படும்.

இந்த டோக்கன் ஜெனரேஷன் செயல்முறை, பெரும்பாலும் ஒரு நியூரல் நெட்வொர்க் (Neural Network) மூலம் நிகழ்த்தப்படுகிறது. இந்த நெட்வொர்க், கான்டெக்ஸ்ட் வெக்டர் மற்றும் முந்தைய டோக்கன்களை உள்ளீடாகப் பெற்று, அடுத்த டோக்கனின் நிகழ்தகவு விரவல் (Probability Distribution) வெளியீடாகக் கொடுக்கும். அடுத்த டோக்கன் என்னவாக இருக்க வாய்ப்பிருக்கிறது என்பதைக் கண்டறிந்து அதற்கேற்ப டோக்கன்களை உருவாக்கும்.

உதாரணமாக, டிகோடர் முதன்முதலில் "அ" எனத் தொடங்குவதற்கான நிகழ்தகவு அதிகமாக இருக்கலாம். எனவே முதலில் '31' என்ற எண் உருவாக்கப்பட்டு, அடுத்து வரும் நிகழ்தகவுகளை வைத்து, '43' என்ற எண் உருவாகும், அடுத்து '59', அடுத்து '2' என, எண்களின் வரிசை உருவாக்கிக் கொண்டே போகும்.

**3. அகராதியைப் பயன்படுத்தி மீண்டும் உரைக்கு மாற்றுதல்**

**டோக்கன் உருவாக்கம் எவ்வாறு நிகழ்கிறது?**

```python
itos = {2: ' ', 31: 'அ', 43: 'க', 59: 'ர', 57: 'மு', 69: 'த', 52: 'ல', 61: 'எ', 37: 'ழு', 63: 'த்', 77: 'ெ', 71: 'ல்', 66: 'ா'}
```

இப்போது, நமக்குக் கொடுக்கப்பட்ட எண்களின் பட்டியலை எடுத்துக்கொள்வோம். பட்டியலில் உள்ள ஒவ்வொரு எண்ணையும் எடுத்துக்கொண்டு, அகராதியில் அதற்குரிய எழுத்தைப் பார்ப்போம். இந்த எழுத்துக்களை ஒன்றாக இணைத்தால், நமக்கு டெக்ஸ்ட் கிடைக்கும்.

**உதாரணம்:**

`[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியலை எடுத்துக்கொள்வோம்.

- முதல் எண் 31. அகராதியில் 31 என்ற எண்ணுக்கு "அ" என்ற எழுத்து ஒதுக்கப்பட்டுள்ளது.
- இரண்டாவது எண் 43. அகராதியில் 43 என்ற எண்ணுக்கு "க" என்ற எழுத்து ஒதுக்கப்பட்டிருக்கலாம்.
- இதேபோல், மற்ற எண்களுக்கும் அகராதியில் உள்ள எழுத்துக்களை எடுத்துக்கொள்வோம்.

இறுதியில், `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியல் "அகர முதல" என்ற டெக்ஸ்ட்டாக மாறும்.

**4. டிகோடரின் செயல்பாடு**

டிகோடர், ஆட்டோரிக்ரஸிவ் (Autoregressive) முறையில் செயல்படுகிறது. அதாவது, ஒவ்வொரு டோக்கனையும் உருவாக்கிய பிறகு, அந்த டோக்கனை அடுத்த டோக்கனை உருவாக்க உள்ளீடாகப் பயன்படுத்துகிறது.

- "அ" என்ற டோக்கனை உருவாக்கிய பிறகு, "க" என்ற டோக்கனை உருவாக்க "அ" என்ற டோக்கனைப் பயன்படுத்துகிறது.
- "க" என்ற டோக்கனை உருவாக்கிய பிறகு, "ர" என்ற டோக்கனை உருவாக்க "அக" என்ற இரு டோக்கன்களையும் பயன்படுத்துகிறது.
- இந்த தொடர்ச்சியான செயல்முறை பாடல் வரி அல்லது வாக்கியம் முடியும் வரை நிகழும்.

**5. டிகோடரின் முடிவு**

டிகோடர், "EOS" (End of Sequence) என்ற சிறப்பு டோக்கனை உருவாக்கும் வரை டோக்கன்களை உருவாக்கிக் கொண்டே இருக்கும். "EOS" டோக்கன், பாடல் வரி முடிந்துவிட்டது என்பதைக் குறிக்கும்.

சுருக்கமாக டிகோடர், என்கோடரால் உருவாக்கப்பட்ட கான்டெக்ஸ்ட் வெக்டரைப் பயன்படுத்தி, சங்கத்தமிழ் பாடல் வரிகளை மீண்டும் உருவாக்குகிறது. இது, ஆட்டோரிக்ரஸிவ் முறையில் செயல்பட்டு, "EOS" டோக்கனை உருவாக்கும் வரை டோக்கன்களை உருவாக்கிக் கொண்டே இருக்கும். இந்த செயல்முறையின் மூலம், கம்ப்யூட்டர் சங்கத்தமிழ் பாடல்களைப் புரிந்துகொண்டு, அவற்றைப் பகுப்பாய்வு செய்யவும், மொழிபெயர்க்கவும், மற்ற பணிகளைச் செய்யவும் முடியும்.

என்கோடர் மற்றும் டிகோடர் இணைந்து செயல்படும் விதம், நாம் மொழியைப் புரிந்துகொண்டு பயன்படுத்தும் விதத்திற்கு ஒப்பானது. நாம் ஒரு வாக்கியத்தைப் படிக்கும்போது, அதன் அர்த்தத்தைப் புரிந்துகொண்டு, அதற்கு ஏற்றவாறு பதிலளிக்கிறோம். என்கோடர் மற்றும் டிகோடரும் இதேபோல் செயல்படுகின்றன. என்கோடர் வாக்கியத்தைப் புரிந்துகொண்டு அதை எண்களாக மாற்றுகிறது, டிகோடர் அந்த எண்களைப் பயன்படுத்தி பொருத்தமான பதிலை உருவாக்குகிறது.

###### Seq2Seq மாடல்கள் - ஒரு அறிமுகம்

செயற்கை நுண்ணறிவுத் துறையில் Seq2Seq (Sequence-to-Sequence) மாடல்கள் ஒரு முக்கியமான முன்னேற்றமாகக் கருதப்படுகின்றன. இந்த மாடல்கள் ஒரு வரிசைத் தரவை (sequence input) மற்றொரு வரிசைத் தரவாக (sequence output) மாற்றும் திறன் கொண்டவை. இவை மொழிபெயர்ப்பு, உரையாடல் அமைப்புகள், சுருக்க எடுத்தல் போன்ற பல்வேறு இயற்கை மொழி செயலாக்கப் பணிகளில் பயன்படுத்தப்படுகின்றன.

Seq2Seq மாடல்களின் செயல்பாட்டு முறையை ஒரு எளிய உதாரணத்தின் மூலம் புரிந்துகொள்ளலாம். தமிழில் "நான் இன்று சினிமாவுக்குப் போகிறேன்" என்ற வாக்கியத்தை எடுத்துக்கொண்டால், இந்த மாடல் அதை ஆங்கிலத்தில் "I am going to the cinema today" என்று துல்லியமாக மொழிபெயர்க்கும். இந்த செயல்முறை இரண்டு முக்கிய பகுதிகளைக் கொண்டுள்ளது - என்கோடர் (encoder) மற்றும் டிகோடர் (decoder). என்கோடர் உள்ளீட்டு வரிசையைப் புரிந்துகொள்கிறது, அதேநேரம் டிகோடர் வெளியீட்டு வரிசையை உருவாக்குகிறது. இந்த அத்தியாயத்தில், Seq2Seq மாடல்களின் கட்டமைப்பு, செயல்பாடு மற்றும் பயன்பாடுகள் பற்றி விரிவாக ஆராய்வோம்.

**Seq2Seq-ன் உள்ளே என்ன இருக்கிறது?**

Seq2Seq மாடல் இரண்டு முக்கியமான பகுதிகளைக் கொண்டது:

1. **என்கோடர் (Encoder)**
2. **டீகோடர் (Decoder)**

இந்த இரண்டும் சேர்ந்துதான் மொழிபெயர்ப்பு மாயத்தை நிகழ்த்துகின்றன. 

**என்கோடர் (Encoder): உள்ளீட்டைப் புரிந்துகொள்வது**

என்கோடரின் வேலை என்னவென்றால், உள்ளீட்டு வாக்கியத்தை (input sentence) எடுத்து, அதை ஒரு சிறிய "குறிப்பு" (hidden state) ஆக மாற்றுவது. இந்த hidden state-ல் தான் வாக்கியத்தின் முழு அர்த்தமும் அடங்கியிருக்கும். இது ஒரு வகையான "சுருக்கம்" (summary) போன்றது.

**உதாரணமாக,** "நான் இன்று சினிமாவுக்குப் போகிறேன்" என்ற வாக்கியத்தை என்கோடர் எடுத்துக்கொள்கிறது. இந்த வாக்கியத்தை வார்த்தை வார்த்தையாகப் பிரித்து, ஒவ்வொரு வார்த்தைக்கும் ஒரு எண்ணைக் கொடுக்கும். இதை "எம்பெடிங்" (Embedding) என்று அழைக்கிறோம்.

- நான் → 1  
- இன்று → 2  
- சினிமாவுக்கு → 3  
- போகிறேன் → 4  

இந்த எண்களை **RNN (Recurrent Neural Network)** என்ற ஒரு வகை நியூரல் நெட்வொர்க் வழியாக அனுப்பும். RNN ஒவ்வொரு வார்த்தையையும் படிக்கும்போது, அதன் அர்த்தத்தை ஒரு "hidden state" என்ற குறிப்பில் சேமிக்கும். கடைசியில், "போகிறேன்" (4) என்ற வார்த்தையைப் படித்து முடிக்கும் போது, என்கோடர் ஒரு "final hidden state" உருவாக்கும். இதில் வாக்கியத்தின் முழு அர்த்தமும் சுருக்கமாக இருக்கும்.

**டீகோடர் (Decoder): வெளியீட்டை உருவாக்குவது**

டீகோடரின் வேலை என்னவென்றால், என்கோடர் கொடுத்த hidden state-ஐப் பயன்படுத்தி, வெளியீட்டு வாக்கியத்தை (output sentence) உருவாக்குவது. இதுவும் ஒரு RNN-ஐப் பயன்படுத்தி செயல்படும்.

டீகோடர் முதலில் ஒரு சிறப்பு சொல்லான **"start"**-ஐ உருவாக்கும். இது மொழிபெயர்ப்பைத் தொடங்குவதற்கான சமிக்ஞை. பின்னர், இந்த "start" சொல்லையும், என்கோடர் கொடுத்த hidden state-ஐயும் பயன்படுத்தி, அடுத்த வார்த்தையைக் கணிக்கும்.

**உதாரணமாக,** முதலில் "I" என்ற வார்த்தையைக் கணிக்கலாம். பின்னர், "I" மற்றும் hidden state-ஐப் பயன்படுத்தி, அடுத்த வார்த்தையான "am"ஐக் கணிக்கும். இப்படியே ஒவ்வொரு வார்த்தையாகக் கணித்து, "I am going to the cinema today" என்ற முழு வாக்கியத்தையும் உருவாக்கும். கடைசியில், ஒரு சிறப்பு சொல்லான **"end"**-ஐக் கணிக்கும் போது, மொழிபெயர்ப்பு முடிந்துவிடும்.

**Seq2Seq-ன் குறைபாடுகள்:**

Seq2Seq மாடல் மிகவும் பயனுள்ளதாக இருந்தாலும், அதற்கு சில குறைபாடுகள் உள்ளன. அவற்றைப் பார்ப்போம்.

1. **நீண்ட வாக்கியங்களைக் கையாள்வது கடினம்:**  
   என்கோடர் ஒரு வாக்கியத்தின் முழு அர்த்தத்தையும் ஒரே ஒரு hidden state-ல் அடக்க வேண்டும். இது நீண்ட வாக்கியங்களுக்கு மிகவும் கடினம். உதாரணமாக, "நான் இன்று சினிமா பார்க்க போகிறேன், ஆனால் மழை பெய்தால், நான் வீட்டிலேயே இருப்பேன்" என்ற வாக்கியத்தை எடுத்துக்கொள்வோம். இதில் பல தகவல்கள் உள்ளன:
   - "நான்" யார்?  
   - "இன்று" எந்த நாள்?  
   - எந்த சினிமா?  
   - மழை பெய்யுமா?  
     இவை அனைத்தையும் ஒரே hidden state-ல் அடக்குவது கடினம்.

2. **RNN-ன் வரம்புகள்:**  
   RNN ஒவ்வொரு வார்த்தையையும் ஒன்றன் பின் ஒன்றாகச் செயலாக்கும். இது நீண்ட வாக்கியங்களுக்கு நேரம் எடுக்கும். மேலும், RNN "நீண்ட-கால நினைவகம்" (long-term memory) கொண்டிருக்காது. அதாவது, முந்தைய வார்த்தைகளின் தகவல்களை முழுமையாக நினைவில் வைத்திருக்க முடியாது.

**இந்தக் குறைபாடுகளுக்கு தீர்வு என்ன?**

இந்தக் குறைபாடுகளைத் தீர்க்க, **டிரான்ஸ்பார்மர் (Transformer)** மாடல் உருவாக்கப்பட்டது. இது **Attention Mechanism** என்ற ஒரு சிறப்பு தொழில்நுட்பத்தைப் பயன்படுத்துகிறது. Attention Mechanism-ன் மூலம், டீகோடர் ஒவ்வொரு வார்த்தையையும் மொழிபெயர்க்கும்போது, உள்ளீட்டு வாக்கியத்தின் எல்லா வார்த்தைகளையும் "கவனமாக" பார்க்கும். இதனால், மொழிபெயர்ப்பு மிகவும் துல்லியமாக இருக்கும்.

உதாரணமாக, "நான் இன்று சினிமா பார்க்க போகிறேன், ஆனால் மழை பெய்தால், நான் வீட்டிலேயே இருப்பேன்" என்ற வாக்கியத்தை மொழிபெயர்க்கும்போது, Attention Mechanism "மழை பெய்தால்" என்ற பகுதியைக் கவனத்தில் கொண்டு, அதற்கான சரியான மொழிபெயர்ப்பைத் தரும்.

<hr class="pagebreak">

### 4. Transformers – NLP-ஐ மாற்றிய அமைப்புகள் 

Natural Language Processing, NLP துறையில் **Transformers** என்பது ஒரு புரட்சிகர மாற்றத்தை ஏற்படுத்தியுள்ளது. இது 2017-ல் Google-ஆல் அறிமுகப்படுத்தப்பட்ட "Attention is All You Need" என்ற ஆராய்ச்சிக் கட்டுரையில் முன்மொழியப்பட்ட ஒரு மேம்பட்ட நரவலை (Neural Networks) கட்டமைப்பாகும். Transformers-ன் முக்கிய புதுமை என்னவென்றால், இது முன்பு பயன்படுத்தப்பட்ட RNN (Recurrent Neural Networks) மற்றும் LSTM (Long Short-Term Memory) போன்ற வரிசை-சார்ந்த மாதிரிகளை விட, **Self-Attention Mechanism**-ஐ அடிப்படையாகக் கொண்டது. இந்த மெக்கானிசம், உரையில் உள்ள சொற்களுக்கிடையேயான சார்புகளை மிகத் துல்லியமாக புரிந்துகொள்ள உதவுகிறது, மேலும் இது Parallel Processing-யை மேம்படுத்துவதன் மூலம் கணிப்புகளை வேகமாகவும் திறம்படவும் செய்கிறது.

Transformers-ன் அடிப்படையில் BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pre-trained Transformer), T5 (Text-To-Text Transfer Transformer) போன்ற மாதிரிகள் உருவாக்கப்பட்டு, NLP துறையில் பல முன்னேற்றங்களை ஏற்படுத்தியுள்ளன. இந்த மாதிரிகள் பல மொழி-சார்ந்த பணிகளில் (Language Tasks) சிறந்த செயல்திறனை வெளிப்படுத்துகின்றன, எடுத்துக்காட்டாக, மொழிபெயர்ப்பு (Translation), உரை சுருக்கம் (Text Summarization), வினா-விடை அமைப்புகள் (Question Answering), உணர்வு பகுப்பாய்வு (Sentiment Analysis) மற்றும் உரை உருவாக்கம் (Text Generation) போன்றவை. Transformers-ன் நெகிழ்வுத்தன்மை மற்றும் பல்துறைத்தன்மை காரணமாக, இது Computer Vision மற்றும் பிற AI துறைகளிலும் பயன்படுத்தப்படுகிறது.

இந்த கட்டுரையில், Transformers-ன் கட்டமைப்பு, அதன் பண்புகள், மற்றும் NLP-ல் அதன் பயன்பாடுகள் பற்றி விரிவாக பார்ப்போம். மேலும், இது எவ்வாறு NLP துறையில் புதிய தரநிலைகளை நிர்ணயித்து, AI-ன் எதிர்காலத்தை வடிவமைக்கிறது என்பதையும் ஆராய்வோம்.

##### 4.1. Transformers-ன் கட்டமைப்பு

Transformers என்பது **Encoder-Decoder** கட்டமைப்பை கொண்ட ஒரு நரவலை ஆகும். இது **Attention Mechanism**-ஐ மையமாக கொண்டு உருவாக்கப்பட்டது. இப்போது, Transformers-ன் ஒவ்வொரு பகுதியையும் விரிவாக பார்ப்போம்.

**உள்ளீட்டு பிரதிநிதித்துவம் (Input Representation)**

Transformers மாதிரிகள் உரை தரவை (Text Data) செயல்படுத்துவதற்கு முன்பு, அதை ஒரு கணித வடிவத்தில் மாற்ற வேண்டும். இந்த செயல்முறையில், உரையில் உள்ள ஒவ்வொரு வார்த்தையும் ஒரு **Embedding** என்று அழைக்கப்படும் ஒரு எண் வெக்டராக (Vector) மாற்றப்படுகிறது. இந்த வெக்டர்கள் உரையின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்தும் வகையில் வடிவமைக்கப்படுகின்றன.

**Embeddings**

- ஒரு வார்த்தை *(w)* என்பது ஒரு embedding வெக்டர் 

  $$
  ( \mathbf{e}_w \in \mathbb{R}^d)
  $$
  ஆக மாற்றப்படுகிறது. இங்கு (d) என்பது embedding பரிமாணம் (Dimension). எடுத்துக்காட்டாக,  "cat" என்ற சொல் `[0.2, -0.5, 0.7, ..., 1.2]` போன்ற ஒரு 512-எண்கள் கொண்ட வரிசையாக (512-dimensional vector) மாற்றப்படலாம்.  

- Embeddings என்பது ஒரு வார்த்தையின் அர்த்தத்தை எண்களின் வடிவில் பிரதிநிதித்துவப்படுத்தும் ஒரு முறை. இது மாதிரிக்கு உரையை புரிந்துகொள்ள உதவுகிறது.

###### 4.1.1. Positional Encoding

Transformers மாதிரிகள் **ஒரே நேரத்தில்** முழு வாக்கியத்தையும் செயலாக்குகின்றன (ஒவ்வொரு வார்த்தையையும் ஒன்றன் பின் ஒன்றாக அல்ல). ஆனால், மொழியில் வார்த்தைகளின் **வரிசை (Sequence)** மிக முக்கியமானது.

**எடுத்துக்காட்டு:**

**"குழந்தை பூனையை விரட்டியது"** vs **"பூனை குழந்தையை விரட்டியது"**
இரண்டும் ஒரே வார்த்தைகளைக் கொண்டவை, ஆனால் வரிசை மாறினால் அர்த்தம் முழுவதுமே மாறிவிடும்!

​					இதை Transformers எப்படி புரிந்துகொள்கிறது?
​							 **Positional Encoding** மூலம்!

- Positional Encoding $$(\mathbf{P} \in \mathbb{R}^{n \times d})$$ என்பது ஒரு மேட்ரிக்ஸ் (Matrix) ஆகும், இது உரையில் உள்ள ஒவ்வொரு வார்த்தையின் position-யை( நிலை) பிரதிநிதித்துவப்படுத்துகிறது.

- இது சைன் (Sine) மற்றும் கொசைன் (Cosine) செயல்பாடுகளை பயன்படுத்தி கணக்கிடப்படுகிறது. இந்த செயல்பாடுகள் வார்த்தைகளின் position-யை( நிலை) ஒரு தனித்துவமான வடிவில் குறிக்கின்றன.

Positional Encoding கணக்கிடுவதற்கான சூத்திரங்கள்:

$$
\mathbf{P}_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
$$

----

$$
\mathbf{P}_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
$$

இங்கு:

- (*pos*) என்பது வார்த்தையின் position ( நிலை) . எடுத்துக்காட்டாக, "I love cats" என்ற வாக்கியத்தில், "I" என்பது position 1, "love" என்பது position 2, மற்றும் "cats" என்பது position 3.
- (*i*) என்பது embedding பரிமாணத்தின் குறியீடு (Index). எடுத்துக்காட்டாக, embedding பரிமாணம் 512 எனில்,(*i*) என்பது 0 முதல் 255 வரை இருக்கும்.
- (*d*) என்பது embedding பரிமாணம் (Dimension).

###### 4.1.2. Embeddings + Positional Encoding

Embeddings மற்றும் Positional Encoding ஆகியவை ஒன்றாக சேர்க்கப்படுகின்றன. இதன் மூலம், மாதிரிக்கு ஒவ்வொரு வார்த்தையின் அர்த்தம் மற்றும் அதன் நிலை இரண்டும் தெரியும்.

$$
\mathbf{P}_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
$$


இங்கு:

- ( **E **) என்பது embeddings மேட்ரிக்ஸ்.
- ( **P** ) என்பது positional encoding மேட்ரிக்ஸ்.
- ( **X** ) என்பது இறுதி உள்ளீட்டு பிரதிநிதித்துவம்.

இந்த உள்ளீட்டு பிரதிநிதித்துவம் Transformers மாதிரிக்கு உரையை புரிந்துகொள்ள உதவுகிறது. இது மாதிரிக்கு உரையில் உள்ள வார்த்தைகளின் அர்த்தம் மற்றும் அவற்றின் வரிசை பற்றிய தகவலை ஒரே நேரத்தில் வழங்குகிறது.

**2. குறியாக்கி (Encoder)**

Encoder என்பது Transformers மாதிரியின் முதல் முக்கிய பகுதியாகும். இது உரை தரவை (Text Data) embeddings-ஆக மாற்றி, அதை பல layers (அடுக்குகள்) மூலம் செயலாக்குகிறது. ஒவ்வொரு Encoder layer-உம் இரண்டு முக்கிய பகுதிகளை கொண்டிருக்கிறது:

1. **Multi-Head Self-Attention**
2. **Feedforward Neural Network**

இந்த பகுதிகள் உரையில் உள்ள வார்த்தைகளுக்கிடையேயான உறவுகளை புரிந்துகொள்வதற்கும், அவற்றின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துவதற்கும் உதவுகின்றன.

**2.1 Multi-Head Self-Attention:**

- ##### **Multi-Head Self-Attention: Transformers-இன் மூளை!**  

  ஒரு வாக்கியத்தில் உள்ள **ஒவ்வொரு வார்த்தையும் மற்ற வார்த்தைகளுடன் எப்படி தொடர்பு கொள்கிறது** என்பதைப் புரிந்துகொள்வதே **Self-Attention-ன் வேலை!**  

  > **எடுத்துக்காட்டு:**  
  > *"குழந்தை பூனையை விரட்டியது"*  
  >
  > - **"விரட்டியது"** என்பது **"குழந்தை"** மற்றும் **"பூனை"** இரண்டையும் சார்ந்துள்ளது.  
  > - **Self-Attention** இந்த **தொடர்புகளை** தானாகவே கண்டுபிடிக்கும்!  

  ---

  ##### **Self-Attention எப்படி வேலை செய்கிறது?**  

  Self-Attention **4 எளிய படிகளில்** செயல்படுகிறது:  

  ##### **Query, Key, Value (கேள்வி, சாவி, மதிப்பு) - ஒவ்வொரு வார்த்தையும் 3 வேடங்களில்!**  

  | வார்த்தை        | Role (பங்கு)  | எளிய விளக்கம்                                   |
  | ------------- | ------------ | --------------------------------------------- |
  | **Query (Q)** | கேள்வி கேட்பவர் | *"என்னைப் பற்றி மற்ற வார்த்தைகளுக்கு என்ன தெரியும்?"*  |
  | **Key (K)**   | பதில் சொல்பவர்  | *"நான் மற்ற வார்த்தைகளுக்கு என்ன தகவல் தர முடியும்?"* |
  | **Value (V)** | உண்மையான தகவல் | *"நான் உண்மையில் என்ன சொல்கிறேன்?"*                 |

  - இவை **Embedding-லிருந்து** 3 தனி வெக்டர்களாக மாற்றப்படுகின்றன:  

    $$
    \mathbf{Q} = \mathbf{X} \mathbf{W}_Q, \quad \mathbf{K} = \mathbf{X} \mathbf{W}_K, \quad \mathbf{V} = \mathbf{X} \mathbf{W}_V
     
    $$
    இங்கு 
    $$
    ( \mathbf{W}_Q, \mathbf{W}_K, \mathbf{W}_V)
    $$
    என்பது trainable weights (பயிற்சி மூலம் கற்றுக்கொள்ளப்படும் எடைகள்).  

  **Attention Scores - வார்த்தைகளுக்கிடையேயான தொடர்பைக் கணக்கிடுதல்**  

  - **Query (Q)** மற்றும் **Key (K)-ஐ** பெருக்கி, ஒவ்வொரு வார்த்தை எவ்வளவு முக்கியம் என்பதைக் கணக்கிடுகிறோம்:  
    $$
    \text{Attention Score} = \frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d_k}}
    $$
    $( d_k )$ என்பது Key-ன் பரிமாணம் (Dimension). இந்த பிரிவு  $(\sqrt{d_k})$ attention scores-ஐ நிலைப்படுத்த (Stabilize) உதவுகிறது.

  > **எடுத்துக்காட்டு:**  
  >
  > - *"குழந்தை"* vs *"விரட்டியது"* → **அதிக Score** (ஏனெனில் குழந்தைதான் விரட்டியது!)  
  > - *"குழந்தை"* vs *"பூனை"* → **குறைந்த Score**  

  **Softmax - "யாருக்கு அதிக கவனம் தர வேண்டும்?"**  

  - Scores-ஐ **Softmax** மூலம் **0 முதல் 1** வரையிலான நிகழ்தகவுகளாக மாற்றுகிறோம்.  
    $$
    \text{Attention Weights} = \text{Softmax}\left(\frac{\mathbf{Q} \mathbf{K}^T}{\sqrt{d_k}}\right)
    $$
    

  > **எடுத்துக்காட்டு:**  
  >
  > - *"விரட்டியது"* என்பது *"குழந்தை"* மீது **0.9** attention-ஐயும், *"பூனை"* மீது **0.1** attention-ஐயும் கொண்டிருக்கலாம்.  

  **Weighted Sum - இறுதி பிரதிநிதித்துவத்தை உருவாக்குதல்**  

  - **Attention Weights-ஐ** **Value (V)** உடன் பெருக்கி, **ஒரு வார்த்தையின் இறுதி representation-ஐ** உருவாக்குகிறோம்:  
    $$
    [
    \text{Attention Output} = \text{Attention Weights} \cdot \mathbf{V}
    ]
    $$

  > **எடுத்துக்காட்டு:**  
  >
  > - *"விரட்டியது"* என்பது **"குழந்தை" (0.9)** மற்றும் **"பூனை" (0.1)** ஆகியவற்றின் கலவையாக இருக்கும்.  

  **Multi-Head Attention - பல தலைகள், சிறந்த புரிதல்!**  

  - **1 Self-Attention Head** → **1 கோணத்தில்** மட்டுமே உரையைப் பார்க்கிறது.  
  - **Multi-Head Attention** → **பல தலைகள் (Heads)** வெவ்வேறு கோணங்களில் உரையைப் பார்க்கின்றன!  

  **எப்படி வேலை செய்கிறது?**  

  1. **ஒவ்வொரு Head-உம்** தனி \( Q, K, V \) வெக்டர்களைக் கொண்டுள்ளது.  
  2. **ஒவ்வொரு Head-உம்** வெவ்வேறு attention patterns-ஐ கற்றுக்கொள்கிறது.  
  3. **அனைத்து Heads-ன் வெளியீடுகளும்** இணைக்கப்பட்டு, ஒரு **Linear Transformation** மூலம் இறுதி வெளியீடு கணக்கிடப்படுகிறது.  

  > **எடுத்துக்காட்டு:**  
  >
  > - **Head 1:** *"விரட்டியது"* vs *"குழந்தை"* (Actor)  
  > - **Head 2:** *"விரட்டியது"* vs *"பூனை"* (Target)  
  > - **Head 3:** *"விரட்டியது"* vs *"விரட்டியது"* (Action)  

  **பல தலைகள் = பல கோணங்களில் புரிதல் = மேம்பட்ட செயல்திறன்!**  

**2.2 Feedforward Neural Network:**

Self-Attention-ன் வெளியீட்டை மேலும் செயலாக்க, ஒரு Feedforward Neural Network (FFN) பயன்படுத்தப்படுகிறது. இது ஒரு எளிய நரம்பியல் வலைப்பின்னல் (Neural Network) ஆகும், இது Self-Attention-ன் வெளியீட்டை மேம்படுத்துகிறது. 

FFN என்பது ஒரு எளிய ஆனால் திறன்மிக்க நரம்பியல் வலைப்பின்னல் கட்டமைப்பாகும். இது ஒவ்வொரு சொல்லின் பிரதிநிதித்துவத்தையும் தனித்தனியாக செயலாக்குகிறது. 

FFN பொதுவாக இரண்டு layers-ஐ கொண்டிருக்கிறது:

1. **முதல் Layer:** Linear transformation மற்றும் activation function (ReLU போன்றது).
   - உள்ளீட்டு பரிமாணத்தை பெரிதாக்குகிறது (பொதுவாக 4 மடங்கு)
   - எடுத்துக்காட்டாக, 512 பரிமாண உள்ளீடு 2048 பரிமாணமாக விரிவாக்கப்படுகிறது
   - ReLU செயல்பாட்டைப் பயன்படுத்தி எதிர்ம மதிப்புகளை நீக்குகிறது
     - உதாரணம்: [0.5, -1.2, 0.8] → [0.5, 0, 0.8]
2. **இரண்டாவது Layer:** Linear transformation.
   - விரிவாக்கப்பட்ட பரிமாணத்தை மீண்டும் அசல் பரிமாணத்திற்கு குறைக்கிறது (2048 → 512)
   - இந்த செயல்முறை மாதிரிக்கு மிகவும் சிக்கலான பிரதிநிதித்துவங்களைக் கற்றுக்கொள்ள உதவுகிறது

உதாரணமாக, "மழை பெய்தது" என்ற வாக்கியத்தில்:

1. "மழை" என்ற சொல்லின் பிரதிநிதித்துவம் FFN-க்கு உள்ளீடாக வழங்கப்படுகிறது
2. "பெய்தது" என்ற சொல்லின் பிரதிநிதித்துவம் தனியாக FFN-க்கு வழங்கப்படுகிறது

FFN-ன் வெளியீடு Encoder layer-ன் இறுதி வெளியீடாகும். Encoder-ன் முக்கிய பணி உரையில் உள்ள வார்த்தைகளுக்கிடையேயான உறவுகளை புரிந்துகொள்வது மற்றும் அவற்றின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துவது. இது பல Encoder layers-ஐ கொண்டிருக்கலாம், ஒவ்வொரு layer-உம் Self-Attention மற்றும் FFN-ஐ பயன்படுத்தி உரையை மேம்படுத்துகிறது.

**Decoder**

Decoder என்பது Transformers மாதிரியின் இரண்டாவது முக்கிய பகுதியாகும். இது Encoder-ன் embeddings-ஐ பயன்படுத்தி, வெளியீட்டை (Output) உருவாக்குகிறது. Decoder-ன் பணி என்னவென்றால், Encoder-ல் இருந்து பெறப்பட்ட தகவல்களை பயன்படுத்தி, இலக்கு மொழியில் (Target Language) உரையை உருவாக்குவது அல்லது மொழிபெயர்ப்பது. ஒவ்வொரு Decoder layer-உம் மூன்று முக்கிய பகுதிகளை கொண்டிருக்கிறது:

1. **Masked Multi-Head Self-Attention**
2. **Encoder-Decoder Attention**
3. **Feedforward Neural Network**

**3.1 Masked Multi-Head Self-Attention:**

Decoder-ல், Self-Attention-ஐ பயன்படுத்தும் போது, ஒரு முக்கியமான வித்தியாசம் உள்ளது. Decoder-ல், **future tokens** (எதிர்கால வார்த்தைகள்) கணக்கில் எடுத்துக்கொள்ளப்படுவதில்லை. இதற்கு **Masking** என்ற ஒரு முறை பயன்படுத்தப்படுகிறது.

- **Masking என்ன?**
  - Masking என்பது ஒரு வழி, இதில் Decoder-ல் ஒரு வார்த்தை அதன் பின்னால் வரும் வார்த்தைகளை பார்க்க முடியாது. எடுத்துக்காட்டாக, "I love cats" என்ற வாக்கியத்தை உருவாக்கும் போது, "love" என்ற வார்த்தை "cats" என்ற வார்த்தையை பார்க்க முடியாது. இது மாதிரியை தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்தி, எதிர்கால வார்த்தைகளை ஊகிக்க உதவுகிறது.
  - இந்த masking செயல்முறை Self-Attention-ல் பயன்படுத்தப்படுகிறது, இதனால் Decoder தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்தி, எதிர்கால வார்த்தைகளை கணிக்க முடியும்.

- **Masked Multi-Head Attention:**
  - Encoder-ல் உள்ளதைப் போல, Decoder-லும் Multi-Head Attention பயன்படுத்தப்படுகிறது. ஆனால், இங்கு masking செயல்முறை சேர்க்கப்படுகிறது.
  - இது Decoder-க்கு தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்தி, எதிர்கால வார்த்தைகளை ஊகிக்க உதவுகிறது.

**3.2 Encoder-Decoder Attention:**

Encoder-ன் embeddings-ஐ Decoder-ல் பயன்படுத்தி, வெளியீட்டை உருவாக்குகிறது. இது Encoder மற்றும் Decoder-க்கு இடையேயான தொடர்பை ஏற்படுத்துகிறது.

- **Encoder-Decoder Attention-ன் வேலை:**
  - இந்த பகுதியில், Decoder-ல் உள்ள Query (Q) Encoder-ல் இருந்து பெறப்படும் Key (K) மற்றும் Value (V)-ஐ பயன்படுத்தி, attention scores கணக்கிடப்படுகிறது.
  - இது Decoder-க்கு Encoder-ல் இருந்து பெறப்பட்ட தகவல்களை பயன்படுத்தி, சரியான வெளியீட்டை உருவாக்க உதவுகிறது.
  - எடுத்துக்காட்டாக, மொழிபெயர்ப்பில், Encoder-ல் உள்ள உரை தகவல்களை Decoder பயன்படுத்தி, இலக்கு மொழியில் உரையை உருவாக்குகிறது.

- **Query, Key, மற்றும் Value:**
  - Query (Q) Decoder-ல் இருந்து பெறப்படுகிறது.
  - Key (K) மற்றும் Value (V) Encoder-ல் இருந்து பெறப்படுகிறது.
  - இந்த மூன்று வெக்டர்களும் attention mechanism-ஐ பயன்படுத்தி, Encoder மற்றும் Decoder-க்கு இடையேயான தொடர்பை ஏற்படுத்துகின்றன.

**3.3 Feedforward Neural Network:**

Encoder-ல் உள்ளதைப் போல, Decoder-லும் Feedforward Neural Network (FFN) பயன்படுத்தப்படுகிறது. இது Self-Attention மற்றும் Encoder-Decoder Attention-ன் வெளியீட்டை மேலும் செயலாக்குகிறது. Feedforward Neural Network-ன் வேலை. இது இரண்டு layers-ஐ கொண்டு. இது Decoder-ன் வெளியீட்டை மேம்படுத்துகிறது மற்றும் இறுதி வெளியீட்டை உருவாக்க உதவுகிறது.

Decoder-ன் முக்கிய பணி Encoder-ல் இருந்து பெறப்பட்ட தகவல்களை பயன்படுத்தி, இலக்கு மொழியில் உரையை உருவாக்குவது. இது பல Decoder layers-ஐ கொண்டிருக்கலாம், ஒவ்வொரு layer-உம் Masked Self-Attention, Encoder-Decoder Attention, மற்றும் FFN-ஐ பயன்படுத்தி உரையை மேம்படுத்துகிறது. இறுதியில், Decoder-ன் வெளியீடு இலக்கு மொழியில் உரையாக மாற்றப்படுகிறது.

---

நாம் ஒரு உதாரணத்தை பயன்படுத்தி, **Encoder** மற்றும் **Decoder**-ன் செயல்பாட்டை விரிவாக காண்போம். உதாரணத்திற்கு நாம் ஒரு எளிய மொழிபெயர்ப்பு பணியை எடுத்துக்கொள்வோம். உள்ளீடு (Input) ஆங்கிலத்தில் "I love cats" என்று இருக்கும், மற்றும் வெளியீடு (Output) தமிழில் "நான் பூனைகளை விரும்புகிறேன்" என்று இருக்கும்.

**Encoder-ன் செயல்பாடு:**

**1. உள்ளீட்டு பிரதிநிதித்துவம் (Input Representation):**

- உள்ளீடு "I love cats" என்பது முதலில் embeddings-ஆக மாற்றப்படுகிறது. ஒவ்வொரு வார்த்தையும் ஒரு வெக்டராக (Vector) மாற்றப்படுகிறது.
  - "I" → $$( \mathbf{e}_1 )$$
  - "love" → $$( \mathbf{e}_2 )$$
  - "cats" → $$( \mathbf{e}_3 )$$
- பின்னர், இந்த embeddings-களுடன் **Positional Encoding** சேர்க்கப்படுகிறது. இது வார்த்தைகளின் நிலை (Position) பற்றிய தகவலை சேமிக்கிறது.
  - "I" (Position 1) → $$( \mathbf{e}_1 + \mathbf{P}_1 )$$
  - "love" (Position 2) → $$( \mathbf{e}_2 + \mathbf{P}_2 )$$
  - "cats" (Position 3) → $$( \mathbf{e}_3 + \mathbf{P}_3 )$$

**2. Multi-Head Self-Attention:**

- Encoder-ல், Self-Attention மூலம் ஒவ்வொரு வார்த்தையும் மற்ற வார்த்தைகளுடன் எவ்வாறு தொடர்புடையது என்பதை புரிந்துகொள்கிறது.
  - எடுத்துக்காட்டாக, "love" என்ற வார்த்தை "I" மற்றும் "cats" உடன் எவ்வாறு தொடர்புடையது என்பதை கணக்கிடுகிறது.
  - இதற்கு Query (Q), Key (K), மற்றும் Value (V) வெக்டர்கள் பயன்படுத்தப்படுகின்றன.
  - Attention scores கணக்கிடப்பட்டு, softmax மூலம் நிகழ்தகவுகளாக மாற்றப்படுகின்றன.
  - இறுதியில், weighted sum மூலம் ஒவ்வொரு வார்த்தையின் புதிய பிரதிநிதித்துவம் கணக்கிடப்படுகிறது.

**3. Feedforward Neural Network:**

- Self-Attention-ன் வெளியீடு Feedforward Neural Network (FFN)-ல் செயலாக்கப்படுகிறது. இது உரையின் அர்த்தத்தை மேலும் மேம்படுத்துகிறது.
- இறுதியில், Encoder-ன் வெளியீடு ஒரு தொகுப்பு embeddings-ஆகும், இது உரையின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துகிறது.

###### 4.1.3. Decoder-ன் செயல்பாடு

**1. Masked Multi-Head Self-Attention:**

- Decoder-ல், முதலில் "நான்" என்ற வார்த்தை மட்டுமே உள்ளது. இது Self-Attention-ஐ பயன்படுத்தி, தற்போதைய வார்த்தையை மட்டுமே பார்க்கிறது (ஏனெனில் எதிர்கால வார்த்தைகள் இன்னும் உருவாக்கப்படவில்லை).
  - "நான்" → $$( \mathbf{e}_1 + \mathbf{P}_1 )$$
  - இங்கு, masking செயல்முறை "பூனைகளை" மற்றும் "விரும்புகிறேன்" போன்ற எதிர்கால வார்த்தைகளை பார்க்காமல், தற்போதைய வார்த்தையை மட்டுமே பயன்படுத்துகிறது.

**2. Encoder-Decoder Attention:**

- Decoder, Encoder-ல் இருந்து பெறப்பட்ட embeddings-ஐ பயன்படுத்தி, "நான்" என்ற வார்த்தைக்கு சரியான வெளியீட்டை உருவாக்குகிறது.
  - Query (Q) Decoder-ல் இருந்து பெறப்படுகிறது ("நான்").
  - Key (K) மற்றும் Value (V) Encoder-ல் இருந்து பெறப்படுகின்றன ("I", "love", "cats").
  - Attention scores கணக்கிடப்பட்டு, Encoder-ன் embeddings-ஐ பயன்படுத்தி, "நான்" என்ற வார்த்தைக்கு சரியான வெளியீடு உருவாக்கப்படுகிறது.

**3. Feedforward Neural Network:**

- Encoder-Decoder Attention-ன் வெளியீடு Feedforward Neural Network (FFN)-ல் செயலாக்கப்படுகிறது. இது வெளியீட்டை மேலும் மேம்படுத்துகிறது.
- இறுதியில், Decoder-ன் வெளியீடு "நான்" என்ற வார்த்தையாக உருவாகிறது.

**முழு செயல்முறை:**

1. **Encoder:**
   - உள்ளீடு "I love cats" என்பது embeddings-ஆக மாற்றப்பட்டு, Self-Attention மற்றும் FFN மூலம் செயலாக்கப்படுகிறது.
   - Encoder-ன் வெளியீடு ஒரு தொகுப்பு embeddings-ஆகும், இது உரையின் அர்த்தத்தை பிரதிநிதித்துவப்படுத்துகிறது.

2. **Decoder:**
   - Decoder முதலில் "நான்" என்ற வார்த்தையை உருவாக்குகிறது. இது Masked Self-Attention மற்றும் Encoder-Decoder Attention-ஐ பயன்படுத்தி, Encoder-ன் embeddings-ஐ பயன்படுத்துகிறது.
   - பின்னர், "பூனைகளை" மற்றும் "விரும்புகிறேன்" போன்ற வார்த்தைகளை ஒவ்வொன்றாக உருவாக்குகிறது.
   - ஒவ்வொரு வார்த்தையும் Encoder-ன் embeddings-ஐ பயன்படுத்தி, சரியான வெளியீட்டை உருவாக்குகிறது.

இந்த செயல்முறை மூலம், Transformers மாதிரி உரையை புரிந்துகொண்டு, மொழிபெயர்ப்பு போன்ற பணிகளை திறம்பட செயல்படுத்துகிறது.

**4. Output Layer**

Decoder-ன் வெளியீடு ஒரு linear transformation மற்றும் softmax செயல்பாடு மூலம்  Output Probabilities (வெளியீட்டு நிகழ்தகவுகளாக) மாற்றப்படுகிறது. இந்த செயல்முறை மாதிரியை இலக்கு மொழியில் உரையை உருவாக்க உதவுகிறது.

**வெளியீட்டு அடுக்கு செயல்முறை:**

1. **Linear Transformation:**

   - Decoder-ன் வெளியீடு $$(h)$$ (ஒரு வெக்டர்) ஒரு linear transformation-ஐ மூலம் செயலாக்கப்படுகிறது. இது ஒரு 

     weight matrix $$( \mathbf{W}_o )$$ 

     மற்றும் bias vector $$( \mathbf{b}_o )$$ பயன்படுத்தி கணக்கிடப்படுகிறது:
     $$
     \mathbf{z} = \mathbf{W}_o \mathbf{h} + \mathbf{b}_o
     $$
     இங்கு (z) என்பது linear transformation-ன் வெளியீடு.
   
2. **Softmax செயல்பாடு:**

   - Linear transformation-ன் வெளியீடு (z) softmax செயல்பாடு மூலம் நிகழ்தகவுகளாக (Probabilities) மாற்றப்படுகிறது. இது ஒவ்வொரு வார்த்தையின் நிகழ்தகவை கணக்கிடுகிறது:
     $$
     \text{Output} = \text{Softmax}(\mathbf{z})
     $$
     Softmax செயல்பாடு ஒவ்வொரு வார்த்தையின் நிகழ்தகவை 0 மற்றும் 1-க்கு இடையில் இருக்கும் வகையில் மாற்றுகிறது, மேலும் அனைத்து நிகழ்தகவுகளின் கூட்டுத்தொகை 1 ஆக இருக்கும்.
   
3. **வெளியீட்டு நிகழ்தகவுகள்:**

   - Softmax-ன் வெளியீடு ஒரு Probability Distribution (நிகழ்தகவு விநியோகம்) ஆகும். இது ஒவ்வொரு வார்த்தையின் நிகழ்தகவை குறிக்கிறது. எடுத்துக்காட்டாக, "நான்", "பூனைகளை", "விரும்புகிறேன்" போன்ற வார்த்தைகளின் நிகழ்தகவுகள் கணக்கிடப்படுகின்றன.
   - மாதிரி இந்த நிகழ்தகவுகளை பயன்படுத்தி, அடுத்த வார்த்தையை தேர்ந்தெடுக்கிறது.

**5. Layer Normalization மற்றும் Residual Connections:**

Transformers-ல், **Layer Normalization** மற்றும் **Residual Connections** பயன்படுத்தப்படுகின்றன. இவை மாதிரியின் பயிற்சியை மேம்படுத்துகின்றன மற்றும் மாதிரியின் செயல்திறனை அதிகரிக்கின்றன.

**Layer Normalization:**

Layer Normalization என்பது ஒரு நெறிமுறை (Normalization Technique) ஆகும், இது மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டையும் நெறிப்படுத்த (Normalize) உதவுகிறது. இது மாதிரியின் பயிற்சியை வேகமாகவும், நிலையாகவும் மேம்படுத்துகிறது.

- **Layer Normalization செயல்முறை:**

  - ஒரு layer-ன் வெளியீடு $$( x )$$ என்பது mean $$( \mu )$$ மற்றும் variance $$( \sigma^2 )$$ பயன்படுத்தி நெறிப்படுத்தப்படுகிறது:
    $$
    \text{LayerNorm}(x) = \gamma \cdot \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta
    $$
    இங்கு:
    
    - $$( \mu )$$ என்பது mean.
    - $$( \sigma^2 )$$ என்பது variance .
    - $$( \gamma )$$ மற்றும் $$( \beta )$$ என்பது trainable parameters (பயிற்சி மூலம் கற்றுக்கொள்ளப்படும் எடைகள்).
    - $$( \epsilon )$$ என்பது ஒரு சிறிய மதிப்பு, இது பூஜ்ஜியத்தால் வகுத்தலை தவிர்க்க உதவுகிறது.
  
- **பயன்:**

  - Layer Normalization மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டையும் நிலையான (Stable) மற்றும் சீரான (Consistent) வடிவில் வைத்திருக்க உதவுகிறது. இது மாதிரியின் பயிற்சியை வேகமாகவும், நிலையாகவும் மேம்படுத்துகிறது.

**Residual Connections:**

Residual Connections என்பது ஒரு முக்கியமான கருத்தாகும், இது மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டை அதன் உள்ளீட்டுடன் நேரடியாக சேர்க்கிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்துகிறது மற்றும் vanishing gradients (சிறிய சாய்வுகள்) பிரச்சினையை தவிர்க்க உதவுகிறது.

- **Residual Connections செயல்முறை:**

  - ஒரு layer-ன் வெளியீடு $$( x )$$ என்பது அதன் உள்ளீட்டுடன் நேரடியாக சேர்க்கப்படுகிறது:
    $$
    [
    \text{Output} = x + \text{Sublayer}(x)
    ]
    $$
    இங்கு $$( \text{Sublayer} )$$ என்பது Self-Attention அல்லது Feedforward Network.

- **பயன்:**

  - Residual Connections மாதிரியின் ஒவ்வொரு layer-ன் வெளியீட்டையும் அதன் உள்ளீட்டுடன் சேர்க்கிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்துகிறது மற்றும் vanishing gradients பிரச்சினையை தவிர்க்க உதவுகிறது.

**6. Training the Transformer:**

Transformers-ன் பயிற்சி **Cross-Entropy Loss** மூலம் செய்யப்படுகிறது. இது predicted output மற்றும் actual output-க்கு இடையேயான வித்தியாசத்தை கணக்கிடுகிறது.

**Cross-Entropy Loss:**

Cross-Entropy Loss என்பது ஒரு loss function ஆகும், இது மாதிரியின் predicted output மற்றும் actual output-க்கு இடையேயான வித்தியாசத்தை கணக்கிடுகிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்த உதவுகிறது.

- **Cross-Entropy Loss செயல்முறை:**

  - Actual output $$( y_i )$$ மற்றும் predicted output $$( \hat{y}_i)$$ பயன்படுத்தி, loss கணக்கிடப்படுகிறது:
    $$
    [
    \text{Loss} = -\sum_{i=1}^n y_i \log(\hat{y}_i)
    ]
    $$
    இங்கு:

    - $$( y_i )$$ என்பது actual output (உண்மையான வெளியீடு).
    - $$( \hat{y}_i )$$ என்பது predicted output (மாதிரியின் ஊகம்).

- **பயன்:**

  - Cross-Entropy Loss மாதிரியின் predicted output மற்றும் actual output-க்கு இடையேயான வித்தியாசத்தை கணக்கிடுகிறது. இது மாதிரியின் பயிற்சியை மேம்படுத்த உதவுகிறது.

Transformers மாதிரி உரையை புரிந்துகொண்டு, மொழிபெயர்ப்பு போன்ற பணிகளை திறம்பட செயல்படுத்துகிறது. இது Encoder, Decoder, Layer Normalization, Residual Connections, மற்றும் Cross-Entropy Loss போன்ற கருத்துகளை பயன்படுத்தி, உரையை புரிந்துகொண்டு, வெளியீட்டை உருவாக்குகிறது. இந்த கருத்துகள் Transformers மாதிரியின் செயல்திறனை மேம்படுத்துகின்றன மற்றும் அதை பல NLP பணிகளில் பயன்படுத்த உதவுகின்றன.

<div style="page-break-after: always;"></div>

##### 4.2. டிரான்ஸ்ஃபார்மர் எப்படி வேலை செய்கிறது?

இன்றைய டிஜிட்டல் யுகத்தில், கணினிகள் மனித மொழியைப் புரிந்து செயல்படுவது மிகவும் முக்கியமானதாகிவிட்டது. குறிப்பாக, குரல் கட்டளைகள், உரை பகுப்பாய்வு (Text Analysis) மற்றும் இயல் மொழி தெளிதல் (Natural Language Processing - NLP) போன்ற துறைகளில் மனித மொழியை கணினி மொழியாக மாற்றுவது ஒரு முக்கிய படியாகும். இந்த மாற்றத்தில், வார்த்தைகளை எண்களாக மாற்றுவது ஒரு முக்கியமான செயல்முறை. 

முதலில், நாம் பயன்படுத்தும் வார்த்தைகளின் தொகுப்பை வரையறுக்க வேண்டும். இதை சொற்களஞ்சியம் (Vocabulary) என்று அழைக்கிறோம். எடுத்துக்காட்டாக, தமிழில் **"நான் தண்ணீர் குடிக்கலாமா"** என்ற வாக்கியத்தை எடுத்துக்கொள்வோம். இந்த வார்த்தைகளை ஒரு சொற்களஞ்சியமாக வரையறுப்போம். இப்போது ஒவ்வொரு வார்த்தைக்கும் ஒரு தனிப்பட்ட எண்ணை ஒதுக்கலாம்.
- தண்ணீர் = 1  
- குடிக்கலாமா = 2  
- நான் = 3  

இப்போது, **"நான் தண்ணீர் குடிக்கலாமா"** என்ற வாக்கியத்தை எண்களாக மாற்றினால், அது **[3, 1, 2]** என்ற எண் வரிசையாக மாறும். இது ஒரு எளிய முறை. ஆனால், கணினிகள் இதை மேலும் திறம்பட செயல்படுத்த, ஒன்-ஹாட் என்கோடிங் என்ற முறை பயன்படுத்தப்படுகிறது. ஒன்-ஹாட் என்கோடிங் என்பது ஒவ்வொரு வார்த்தையையும் ஒரு வெக்டர் (Vector) ஆக மாற்றும் முறை. இந்த வெக்டரின் நீளம் சொற்களஞ்சியத்தின் அளவுக்கு சமமாக இருக்கும். இந்த வெக்டரில், ஒரே ஒரு உறுப்பு மட்டும் **1** ஆகவும், மற்ற எல்லா உறுப்புகளும் **0** ஆகவும் இருக்கும்.  

**இது எப்படி செயல்படுகிறது?**  

மேலே உள்ள சொற்களஞ்சியத்தை எடுத்துக்கொள்வோம்:  
- தண்ணீர் = [1, 0, 0]  
- குடிக்கலாமா = [0, 1, 0]  
- நான் = [0, 0, 1]  

இப்போது, **"நான் தண்ணீர் குடிக்கலாமா"** என்ற வாக்கியத்தை ஒன்-ஹாட் என்கோடிங் மூலம் மாற்றினால், அது பின்வரும் மேட்ரிக்ஸாக (Matrix) மாறும்:  
```
[ [0, 0, 1],  
  [1, 0, 0],  
  [0, 1, 0] ]  
```
இங்கே, ஒவ்வொரு வரியும் ஒரு வார்த்தையைக் குறிக்கிறது. இந்த வார்த்தை எண் வடிவங்களைப் பயன்படுத்தி, கணினிகள் பல்வேறு கணித செயல்பாடுகளை செய்ய முடியும். அவற்றில் ஒரு முக்கியமான செயல்பாடு **டாட் ப்ராடக்ட் (Dot Product)** ஆகும். ஒன்-ஹாட் என்கோடிங்கில் டாட் ப்ராடக்ட் எப்படி பயன்படுத்தப்படுகிறது என்பதைப் பார்ப்போம்.  

டாட் ப்ராடக்ட் என்பது இரண்டு வெக்டர்களை (Vectors) எடுத்துக்கொண்டு, அவற்றின் ஒத்த உறுப்புகளைப் பெருக்கி, பின்னர் அந்த பெருக்கல்களின் கூட்டுத்தொகையைக் கண்டுபிடிக்கும் ஒரு கணித செயல்பாடு. இதை **இன்னர் ப்ராடக்ட் (Inner Product)** அல்லது **ஸ்கேலார் ப்ராடக்ட் (Scalar Product)** என்றும் அழைப்பார்கள்.  

**டாட் ப்ராடக்ட் கணக்கிடும் முறை:**  

இரண்டு வெக்டர்கள் **A** மற்றும் **B** கொடுக்கப்பட்டால், அவற்றின் டாட் ப்ராடக்ட் பின்வருமாறு கணக்கிடப்படும்:  
```
A = [a1, a2, a3]  
B = [b1, b2, b3]  
A.B = (a1 * b1) + (a2 * b2) + (a3 * b3)  
```

ஒன்-ஹாட் என்கோடிங்கில், ஒவ்வொரு வார்த்தையும் ஒரு வெக்டராக குறிப்பிடப்படுகிறது. இந்த வெக்டர்களுக்கு இடையேயான தொடர்பைப் புரிந்துகொள்ள, டாட் ப்ராடக்ட் பயன்படுத்தப்படுகிறது.  

ஒரு வெக்டரை அதே வெக்டருடன் டாட் ப்ராடக்ட் செய்தால், முடிவு **1** கிடைக்கும். இது அந்த வெக்டர் தனித்துவமானது என்பதைக் காட்டுகிறது.  

**உதாரணம்:**  
"பூனை" என்ற வார்த்தையின் ஒன்-ஹாட் வெக்டர் **[1, 0, 0]** என்று வைத்துக்கொள்வோம். இதை அதே  வெக்டருடன் டாட் ப்ராடக்ட் செய்தால்:  

```
[1, 0, 0] . [1, 0, 0] = (1 * 1) + (0 * 0) + (0 * 0) = 1  
```
இதன் மூலம், ஒரு குறிப்பிட்ட வார்த்தை ஒரு வாக்கியத்தில் அல்லது தொகுப்பில் இருக்கிறதா என்பதை கண்டறியலாம்.  

ஒரு வெக்டரை வேறு ஒரு வெக்டருடன் டாட் ப்ராடக்ட் செய்தால், முடிவு **0** கிடைக்கும். இது அந்த இரண்டு வெக்டர்களும் வேறுபட்டவை என்பதைக் காட்டுகிறது.  

**உதாரணம்:**  
"பூனை" என்ற வார்த்தையின் ஒன்-ஹாட் வெக்டர் **[1, 0, 0]** என்றும், "நாய்" என்ற வார்த்தையின் ஒன்-ஹாட் வெக்டர் **[0, 1, 0]** என்றும் வைத்துக்கொள்வோம். 

இவ்விரண்டையும் டாட் ப்ராடக்ட் செய்தால்:  

```
[1, 0, 0] . [0, 1, 0] = (1 * 0) + (0 * 1) + (0 * 0) = 0  
```
இதன் மூலம், இரண்டு வார்த்தைகளும் வேறுபட்டவை என்பதை உறுதி செய்யலாம். ஒன்-ஹாட் என்கோடிங் முறையில், ஒத்த வார்த்தைகளுக்கு இடையேயான தொடர்பை நேரடியாக அளவிட முடியாது. ஏனெனில், ஒவ்வொரு வார்த்தையும் தனித்தனி வெக்டராக குறிப்பிடப்படுகிறது.  

**உதாரணம்:**  
"மகிழ்ச்சி", "சந்தோஷம்", "நகைச்சுவை" போன்ற வார்த்தைகள் ஒன்றுக்கொன்று தொடர்புடையவை. ஆனால், ஒன்-ஹாட் என்கோடிங்கில், இவை தனித்தனி வெக்டர்களாக குறிப்பிடப்படுவதால், இவற்றுக்கு இடையேயான தொடர்பை டாட் ப்ராடக்ட் மூலம் கண்டறிய முடியாது. ஒத்த வார்த்தைகளின் தொடர்பை அளவிட, வேர்ட் எம்பெடிங்ஸ் போன்ற மேம்பட்ட முறைகள் தேவைப்படுகின்றன.  **வேர்ட் எம்பெடிங்ஸ் (Word Embeddings)**, வார்த்தைகள் தொடர்ச்சியான வெக்டர் வெளியில் (Continuous Vector Space) குறிப்பிடப்படுகின்றன. இதன் மூலம், ஒத்த வார்த்தைகள் ஒன்றுக்கொன்று அருகில் இருக்கும்.  

**மேட்ரிக்ஸ் என்றால் என்ன?**  

மேட்ரிக்ஸ் என்பது எண்களை வரிசைகள் (Rows) மற்றும் நெடுவரிசைகளாக (Columns) அடுக்கி வைக்கும் ஒரு அமைப்பு. இதை ஒரு அட்டவணை போல கற்பனை செய்து கொள்ளலாம்.  

**உதாரணம்:**  
ஒரு கடையில் இருக்கும் பழங்களின் விலை பட்டியலை ஒரு மேட்ரிக்ஸாக குறிப்பிடலாம்:  

| பழம்      | விலை (கிலோ) |
| -------- | ----------- |
| ஆப்பிள்    | 200         |
| ஆரஞ்சு    | 100         |
| வாழைப்பழம் | 50          |

இதை மேட்ரிக்ஸ் வடிவில் எழுதினால்:  
```
A = [[200, 100, 50]]
```

**மேட்ரிக்ஸ் பெருக்கல் எப்படி செயல்படுகிறது?**  

இரண்டு மேட்ரிக்ஸ்களை பெருக்குவதற்கு, முதல் மேட்ரிக்ஸின் நெடுவரிசைகளின் எண்ணிக்கையும், இரண்டாவது மேட்ரிக்ஸின் வரிசைகளின் எண்ணிக்கையும் சமமாக இருக்க வேண்டும்.  

மேட்ரிக்ஸ் பெருக்கல் செய்யும்போது, முதல் மேட்ரிக்ஸின் ஒவ்வொரு வரிசையையும், இரண்டாவது மேட்ரிக்ஸின் ஒவ்வொரு நெடுவரிசையையும் எடுத்துக்கொண்டு, அவற்றின் ஒத்த உறுப்புகளை பெருக்கி, கூட்டுத்தொகையை கண்டுபிடிக்க வேண்டும்.  

**உதாரணம்: பழங்களின் விலை கணக்கீடு**  

மேலே குறிப்பிட்ட பழங்களின் விலை பட்டியல் மேட்ரிக்ஸை (**A**) மற்றும் நாம் வாங்க விரும்பும் பழங்களின் அளவை குறிப்பிடும் மற்றொரு மேட்ரிக்ஸை (**B**) பெருக்கினால், நாம் செலுத்த வேண்டிய மொத்த தொகையை கணக்கிடலாம்.  

**மேட்ரிக்ஸ் A:**  

```
A = [
  [200, 100, 50]  // ஆப்பிள், ஆரஞ்சு, வாழைப்பழம் விலை
]
```

**மேட்ரிக்ஸ் B:**  
```
B = [
  [2],  // 2 கிலோ ஆப்பிள்
  [3],  // 3 கிலோ ஆரஞ்சு
  [4]   // 4 கிலோ வாழைப்பழம்
]
```

**மேட்ரிக்ஸ் பெருக்கல்:**  
```
A . B = [
  [ (200 * 2) + (100 * 3) + (50 * 4) ]
]
= [
  [ 400 + 300 + 200 ]
]
= [
  [ 900 ]
]
```

எனவே, நாம் செலுத்த வேண்டிய மொத்த தொகை **900 ரூபாய்**.  

இயல் மொழி தெளிதல் (Natural Language Processing - NLP) என்பது கணினிகள் மனித மொழியைப் புரிந்துகொள்ளவும், செயல்படவும் உதவும் ஒரு துறையாகும். இந்தத் துறையில், **முதல் வரிசை தொடர் மாதிரி (First Order Sequence Model)** ஒரு முக்கியமான கருவியாகப் பயன்படுத்தப்படுகிறது. இந்த மாதிரி, வார்த்தைகளின் வரிசையை கணிக்க உதவுகிறது.  

**சொற்களஞ்சியம் (Vocabulary)**  

முதலில், நாம் பயன்படுத்தும் வார்த்தைகளின் தொகுப்பை வரையறுக்க வேண்டும். இதை **சொற்களஞ்சியம் (Vocabulary)** என்று அழைக்கிறோம்.  

**உதாரணம்:**  
நாம் மூன்று கட்டளைகளை மட்டும் கையாள விரும்புகிறோம் என்று வைத்துக்கொள்வோம்:  

1. "எனது கோப்புகளைத் திற." ("Open my files.")  
2. "எனது இசையை இயக்கு." ("Play my music.")  
3. "எனது புகைப்படங்களைக் காட்டு." ("Show my photos.")  

இந்த கட்டளைகளில் உள்ள வார்த்தைகளை வைத்து நமது சொற்களஞ்சியத்தை உருவாக்கலாம்:  

```
{எனது, கோப்புகள், திற, இசை, இயக்கு, புகைப்படங்கள், காட்டு}  
```

**Transition Model**

இந்த வார்த்தைகளின் வரிசையை கணிக்க, ஒரு **Transition Model** பயன்படுத்தலாம். இந்த மாதிரி, ஒவ்வொரு வார்த்தைக்கும் அடுத்ததாக வரக்கூடிய வார்த்தையின் நிகழ்தகவை (Probability) காட்டும்.  

**உதாரணம்:**  
"எனது" என்ற வார்த்தைக்கு பிறகு, "கோப்புகள்" வரும் நிகழ்தகவு **0.4** என்றும், "இசை" வரும் நிகழ்தகவு **0.3** என்றும், "புகைப்படங்கள்" வரும் நிகழ்தகவு **0.3** என்றும் வைத்துக்கொள்வோம்.  

இந்த மாற்றம் மாதிரி, ஒரு **மார்கோவ் சங்கிலி (Markov Chain)** என்று அழைக்கப்படுகிறது. ஏனெனில் இவை சங்கிலி போன்று இணைக்கப்பட்டிருக்கும்; அடுத்த வார்த்தையின் நிகழ்தகவு தற்போதைய வார்த்தையை மட்டுமே சார்ந்ததாக இருக்கும். இதை **முதல் வரிசை மார்கோவ் மாதிரி (First Order Markov Model)** என்றும் அழைக்கிறோம்.  

**மேட்ரிக்ஸ் வடிவில் குறிப்பிடுதல்**  

இந்த மார்கோவ் சங்கிலியை, ஒரு மேட்ரிக்ஸ் (Matrix) வடிவில் குறிப்பிடலாம். மேட்ரிக்ஸின் ஒவ்வொரு வரிசையும் (Row) மற்றும் நெடுவரிசையும் (Column) சொற்களஞ்சியத்தில் உள்ள ஒரு வார்த்தையை குறிக்கும். மேட்ரிக்ஸில் உள்ள ஒவ்வொரு உறுப்பும் (Element), அந்த வரிசையில் உள்ள வார்த்தைக்கு அடுத்ததாக நெடுவரிசையில் உள்ள வார்த்தை வரும் நிகழ்தகவை குறிக்கும்.  

**உதாரணம்:**  

இப்போது, இந்த வார்த்தைகளுக்கான மாற்றம் மாதிரியை (Transition Model) மேட்ரிக்ஸ் வடிவில் குறிப்பிடலாம். இந்த மேட்ரிக்ஸில், ஒவ்வொரு வரிசையும் ஒரு வார்த்தையைக் குறிக்கும், மற்றும் ஒவ்வொரு நெடுவரிசையும் அந்த வார்த்தைக்கு அடுத்ததாக வரக்கூடிய வார்த்தையின் நிகழ்தகவைக் குறிக்கும்.

**மேட்ரிக்ஸ் வடிவில் குறிப்பிடுதல்:**

|                | எனது | கோப்புகள் | திற  | இசை  | இயக்கு | புகைப்படங்கள் | காட்டு |
| -------------- | ---- | ------- | ---- | ---- | ----- | ---------- | ----- |
| **எனது**       | 0.0  | 0.4     | 0.0  | 0.3  | 0.0   | 0.3        | 0.0   |
| **கோப்புகள்**    | 0.0  | 0.0     | 1.0  | 0.0  | 0.0   | 0.0        | 0.0   |
| **திற**        | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 0.0   |
| **இசை**        | 0.0  | 0.0     | 0.0  | 0.0  | 1.0   | 0.0        | 0.0   |
| **இயக்கு**      | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 0.0   |
| **புகைப்படங்கள்** | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 1.0   |
| **காட்டு**      | 0.0  | 0.0     | 0.0  | 0.0  | 0.0   | 0.0        | 0.0   |

**விளக்கம்:**

- "எனது" என்ற வார்த்தைக்கு பிறகு, "கோப்புகள்" வரும் நிகழ்தகவு **0.4**, "இசை" வரும் நிகழ்தகவு **0.3**, மற்றும் "புகைப்படங்கள்" வரும் நிகழ்தகவு **0.3**.
- "கோப்புகள்" என்ற வார்த்தைக்கு பிறகு, "திற" வரும் நிகழ்தகவு **1.0** (ஏனெனில் "கோப்புகளைத் திற" என்ற கட்டளையில் இது நிகழ்கிறது).
- "இசை" என்ற வார்த்தைக்கு பிறகு, "இயக்கு" வரும் நிகழ்தகவு **1.0** (ஏனெனில் "இசையை இயக்கு" என்ற கட்டளையில் இது நிகழ்கிறது).
- "புகைப்படங்கள்" என்ற வார்த்தைக்கு பிறகு, "காட்டு" வரும் நிகழ்தகவு **1.0** (ஏனெனில் "புகைப்படங்களைக் காட்டு" என்ற கட்டளையில் இது நிகழ்கிறது).

இந்த மேட்ரிக்ஸ், மார்கோவ் சங்கிலியின் மாற்றம் மாதிரியை குறிக்கிறது மற்றும் இது ஒரு முதல் வரிசை மார்கோவ் மாதிரி (First Order Markov Model) ஆகும். இந்த மாதிரியைப் பயன்படுத்தி, வார்த்தைகளின் வரிசையை கணிக்க முடியும்.

**இரண்டாம் வரிசை மார்கோவ் மாதிரி (Second Order Markov Model)**  

முந்தைய வார்த்தையை மட்டும் பார்த்து அடுத்த வார்த்தையை கணிப்பது போதுமானதாக இல்லை. இது ஒரு பாடலின் முதல் சுரத்தை (note) மட்டும் கேட்டு, முழு பாடலையும் ஊகிப்பது போன்றது. ஆனால், குறைந்தது இரண்டு சுரங்கள் (notes) இருந்தால், நம்முடைய ஊகம் மிகவும் துல்லியமாக இருக்கும்.  

இதைப் புரிந்துகொள்ள, தமிழில் உள்ள ஒரு எளிய மொழி மாதிரியை (toy language model) பார்க்கலாம். இந்த மாதிரியில் இரண்டு வாக்கியங்கள் மட்டுமே உள்ளன, மேலும் அவை 40/60 விகிதத்தில் உள்ளன என்று வைத்துக்கொள்வோம்:  

1. "எனது புத்தகத்தை எடு."  
2. "எனது பேனாவை எடு."  

இந்த வாக்கியங்களுக்கு ஒரு முதல் வரிசை மார்கோவ் சங்கிலி (First Order Markov Chain) உருவாக்கினால், அது ஒவ்வொரு வார்த்தையையும் அதற்கு முந்தைய ஒரு வார்த்தையை மட்டும் பார்த்து கணிக்கும். ஆனால், இந்த மாதிரியில் சில நிச்சயமற்ற தருணங்கள் (uncertainty) இருக்கும். எடுத்துக்காட்டாக, "எனது" என்ற வார்த்தைக்குப் பிறகு "புத்தகத்தை" அல்லது "பேனாவை" வரலாம்.  

இதைச் சரிசெய்ய, நமது மாதிரி ஒரு வார்த்தையை மட்டும் பார்க்காமல், இரண்டு வார்த்தைகளைப் பார்த்தால், அது மிகவும் துல்லியமாக செயல்படும். எடுத்துக்காட்டாக, "எனது புத்தகத்தை" என்ற இரண்டு வார்த்தைகளைப் பார்த்தால், அடுத்த வார்த்தை "எடு" என்பது தெளிவாகத் தெரியும். அதேபோல், "எனது பேனாவை" என்ற இரண்டு வார்த்தைகளைப் பார்த்தால், அடுத்த வார்த்தை "எடு" என்பது தெளிவாகத் தெரியும். இதன் மூலம், மாதிரியில் உள்ள கிளைத்தல் (branching) குறைந்து, நிச்சயமற்ற தன்மை (uncertainty) குறைகிறது.  

இரண்டு வார்த்தைகளைப் பார்ப்பதன் மூலம், இது ஒரு **இரண்டாம் வரிசை மார்கோவ் மாதிரி (Second Order Markov Model)** ஆக மாறுகிறது. இது அடுத்த வார்த்தையை கணிக்க அதிகமான சூழலை (context) வழங்குகிறது.  

**முதல் வரிசை vs இரண்டாம் வரிசை மாற்றம் மேட்ரிக்ஸ்**  

முதல் வரிசை மார்கோவ் மாதிரியில், ஒவ்வொரு வார்த்தைக்கும் அடுத்து வரக்கூடிய வார்த்தைகளின் நிகழ்தகவுகள் மட்டுமே உள்ளன. ஆனால், இரண்டாம் வரிசை மார்கோவ் மாதிரியில், ஒவ்வொரு **இரண்டு வார்த்தைகளின் கலவைக்கும்** (combination) அடுத்து வரக்கூடிய வார்த்தைகளின் நிகழ்தகவுகள் உள்ளன.  

**முதல் வரிசை மாற்றம் மேட்ரிக்ஸ்:**  
இந்த மேட்ரிக்ஸில், ஒவ்வொரு வரிசையும் ஒரு வார்த்தையைக் குறிக்கும், மற்றும் ஒவ்வொரு நெடுவரிசையும் அந்த வார்த்தைக்கு அடுத்து வரக்கூடிய வார்த்தையின் நிகழ்தகவைக் குறிக்கும்.  

**இரண்டாம் வரிசை மாற்றம் மேட்ரிக்ஸ்:**  
இந்த மேட்ரிக்ஸில், ஒவ்வொரு வரிசையும் **இரண்டு வார்த்தைகளின் கலவையை** (combination) குறிக்கும், மற்றும் ஒவ்வொரு நெடுவரிசையும் அந்த இரண்டு வார்த்தைகளுக்கு அடுத்து வரக்கூடிய வார்த்தையின் நிகழ்தகவைக் குறிக்கும்.  

எடுத்துக்காட்டாக, "எனது புத்தகத்தை" என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து "எடு" வரும் நிகழ்தகவு **1.0** ஆகும். அதேபோல், "எனது பேனாவை" என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து "எடு" வரும் நிகழ்தகவு **1.0** ஆகும்.  

```
{எனது, புத்தகத்தை, எடு, பேனாவை}
```

இரண்டாம் வரிசை மார்கோவ் மாதிரியில், ஒவ்வொரு இரண்டு வார்த்தைகளின் கலவைக்கும் அடுத்து வரக்கூடிய வார்த்தையின் நிகழ்தகவுகள் கணக்கிடப்படுகின்றன. இதை ஒரு மேட்ரிக்ஸ் வடிவில் குறிப்பிடலாம்.  

| இரண்டு வார்த்தைகள் (Combination) | அடுத்த வார்த்தை | நிகழ்தகவு (Probability) |
| ---------------------------- | ------------ | ---------------------- |
| எனது புத்தகத்தை                | எடு          | 1.0                    |
| எனது பேனாவை                  | எடு          | 1.0                    |
| புத்தகத்தை எடு                 | -            | 0.0                    |
| பேனாவை எடு                   | -            | 0.0                    |

விளக்கம்:  

1. **"எனது புத்தகத்தை"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"எடு"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
2. **"எனது பேனாவை"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"எடு"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
3. **"புத்தகத்தை எடு"** மற்றும் **"பேனாவை எடு"** போன்ற கலவைகளுக்கு அடுத்து எந்த வார்த்தையும் வராது, எனவே நிகழ்தகவு **0.0** ஆகும்.  

இரண்டாம் வரிசை மாற்றம் மேட்ரிக்ஸில், வரிசைகளின் எண்ணிக்கை மிகவும் அதிகமாக இருக்கும். ஏனெனில், ஒவ்வொரு இரண்டு வார்த்தைகளின் கலவைக்கும் ஒரு வரிசை தேவைப்படுகிறது. எனவே, சொற்களஞ்சியத்தில் (vocabulary) \(N\) வார்த்தைகள் இருந்தால், மேட்ரிக்ஸில் \(N^2\) வரிசைகள் இருக்கும்.  

**இரண்டாம் வரிசை மாதிரியின் நன்மைகள்**  

இரண்டாம் வரிசை மார்கோவ் மாதிரியின் முக்கிய நன்மை என்னவென்றால், அது அதிக நிச்சயத்தன்மையை (confidence) வழங்குகிறது. இந்த மாதிரியில், மேட்ரிக்ஸில் அதிகமான ஒன்றுகள் (1) மற்றும் குறைவான பின்னங்கள் (fractions) இருக்கும். எடுத்துக்காட்டாக, மேலே உள்ள எடுத்துக்காட்டில், ஒரே ஒரு வரிசையில் மட்டுமே பின்னங்கள் உள்ளன (அதாவது, "எனது"க்குப் பிறகு "புத்தகத்தை" அல்லது "பேனாவை" வரும் நிகழ்தகவுகள்).  

இரண்டு வார்த்தைகளைப் பார்ப்பதன் மூலம், அடுத்த வார்த்தையை கணிக்க அதிகமான சூழல் (context) கிடைக்கிறது. இது மொழி மாதிரிகளில் (language models) மிகவும் பயனுள்ளதாக இருக்கிறது, ஏனெனில் இது மொழியின் கட்டமைப்பை (structure) மிகவும் துல்லியமாக பிரதிபலிக்கிறது.  

இரண்டாம் வரிசை மார்கோவ் மாதிரிகள் சவாலானவையாக இருக்கலாம், ஆனால் அவை மொழி மாதிரிகளின் துல்லியத்தை மேம்படுத்துவதற்கு ஒரு சக்திவாய்ந்த கருவியாகும்.

**இரண்டாம் வரிசை மாதிரி மற்றும் ஸ்கிப்ஸ் (Second Order Model with Skips)**  

இரண்டாம் வரிசை மார்கோவ் மாதிரி (Second Order Markov Model) இரண்டு முந்தைய வார்த்தைகளைப் பார்த்து அடுத்த வார்த்தையை கணிக்கிறது. ஆனால், சில சந்தர்ப்பங்களில், அடுத்த வார்த்தையை கணிக்க நாம் இரண்டுக்கும் மேற்பட்ட முந்தைய வார்த்தைகளைப் பார்க்க வேண்டியிருக்கும். 

எடுத்துக்காட்டாக, இரண்டு வாக்கியங்களை எடுத்துக்கொள்வோம்:  

1. "நிமலன் பள்ளிக்குச் சென்றான், பாடங்களைக் கற்றான், வீட்டிற்குத் திரும்பினான்."  
2. "நிமலன் பூங்காவிற்குச் சென்றான், பூக்களைப் பார்த்தான், வீட்டிற்குத் திரும்பினான்."  

இந்த வாக்கியங்களில், "வீட்டிற்குத்" என்ற வார்த்தைக்குப் பிறகு " திரும்பினான்" வரும் என்பதை தீர்மானிக்க, நாம் முந்தைய பல வார்த்தைகளைப் பார்க்க வேண்டும்.  

இதுபோன்ற நீண்ட தூர சார்புகளை (long-range dependencies) கையாள, நாம் மூன்றாம் அல்லது அதற்கு மேற்பட்ட வரிசை மாதிரிகளை (higher-order models) பயன்படுத்தலாம். ஆனால், சொற்களஞ்சியம் (vocabulary) பெரியதாக இருந்தால், இது கணக்கிட மிகவும் சிக்கலானதாக இருக்கும். எடுத்துக்காட்டாக, எட்டாம் வரிசை மாதிரியில் ($N^8$) வரிசைகள் இருக்கும், இது மிகவும் அதிகமான எண்ணிக்கையாகும்.  

இதற்கு பதிலாக, நாம் ஒரு சாமார்த்தியமான முறையைப் பயன்படுத்தலாம்: **இரண்டாம் வரிசை மாதிரியைப் பயன்படுத்தி, முந்தைய வார்த்தைகளின் கலவைகளைக் கருத்தில் கொள்ளலாம்**. இந்த மாதிரியில், நாம் இரண்டு வார்த்தைகளை மட்டும் பார்க்கிறோம், ஆனால் அவற்றில் ஒன்று மிக சமீபத்திய வார்த்தையாகவும், மற்றொன்று முந்தைய எந்தவொரு வார்த்தையாகவும் இருக்கலாம். இது நீண்ட தூர சார்புகளைப் பிடிக்க உதவுகிறது.  

இதை ஒரு மேட்ரிக்ஸ் வடிவில் குறிப்பிடலாம்.  இந்த எடுத்துக்காட்டில், "வீட்டிற்குத்" என்ற வார்த்தைக்குப் பிறகு "திரும்பினான்" வரும் என்பதை தீர்மானிக்க, நாம் முந்தைய இரண்டு வார்த்தைகளின் கலவையைப் பார்க்கிறோம்.  

| இரண்டு வார்த்தைகள் (Combination) | அடுத்த வார்த்தை | நிகழ்தகவு (Probability) |
| ---------------------------- | ------------ | ---------------------- |
| பள்ளிக்குச் சென்றான், வீட்டிற்குத்    | திரும்பினான்   | 0.0                    |
| பூங்காவிற்குச் சென்றான், வீட்டிற்குத் | திரும்பினான்   | 0.0                    |
| பாடங்களைக் கற்றான், வீட்டிற்குத்     | திரும்பினான்   | 1.0                    |
| பூக்களைப் பார்த்தான், வீட்டிற்குத்    | திரும்பினான்   | 1.0                    |

விளக்கம்:  

1. **"பாடங்களைக் கற்றான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
2. **"பூக்களைப் பார்த்தான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
3. **"பள்ளிக்குச் சென்றான், வீட்டிற்குத்"** மற்றும் **"பூங்காவிற்குச் சென்றான், வீட்டிற்குத்"** போன்ற கலவைகளுக்கு அடுத்து எந்த வார்த்தையும் வராது, எனவே நிகழ்தகவு **0.0** ஆகும்.  

இந்த மேட்ரிக்ஸ், இரண்டாம் வரிசை மார்கோவ் மாதிரியின் அமைப்பைக் காட்டுகிறது. இது முந்தைய இரண்டு வார்த்தைகளைப் பார்த்து, அடுத்த வார்த்தையை கணிக்க உதவுகிறது.

**மாஸ்கிங் (Masking)**  

முந்தைய மாதிரியில், "வீட்டிற்குத்" என்ற வார்த்தைக்குப் பிறகு "திரும்பினான்" வரும் என்பதை கணிக்க, நாம் பல வார்த்தைகளின் கலவைகளைப் பார்த்தோம். ஆனால், இந்த மாதிரியில் பெரும்பாலான கலவைகள் பயனற்றவையாக இருந்தன. எடுத்துக்காட்டாக, "பள்ளிக்குச் சென்றான், வீட்டிற்குத்" மற்றும் "பூங்காவிற்குச் சென்றான், வீட்டிற்குத்" போன்ற கலவைகள் எந்த தகவலையும் வழங்கவில்லை. இதை மேம்படுத்த, நாம் **மாஸ்கிங் (Masking)** என்ற முறையைப் பயன்படுத்தலாம். இந்த முறையில், பயனற்ற கலவைகளை மறைத்து, முக்கியமான கலவைகளை மட்டும் கணக்கில் எடுத்துக்கொள்கிறோம்.  

**மாஸ்கிங் முறை:**  

மாஸ்கிங் முறையில், நாம் ஒரு **மாஸ்க் வெக்டர் (Mask Vector)** உருவாக்குகிறோம். இந்த வெக்டரில், முக்கியமான கலவைகளுக்கு **1** மதிப்பும், பயனற்ற கலவைகளுக்கு **0** மதிப்பும் இருக்கும்.  

**மாஸ்க் வெக்டர்:**  

```
[பள்ளிக்குச் சென்றான், வீட்டிற்குத்: 0,  
 பூங்காவிற்குச் சென்றான், வீட்டிற்குத்: 0,  
 பாடங்களைக் கற்றான், வீட்டிற்குத்: 1,  
 பூக்களைப் பார்த்தான், வீட்டிற்குத்: 1]
```

இந்த மாஸ்க் வெக்டரை, மாற்றம் மேட்ரிக்ஸுடன் (Transition Matrix) பெருக்கினால், பயனற்ற கலவைகள் மறைக்கப்படும்.  

**மாஸ்க்டு மாற்றம் மேட்ரிக்ஸ் (Masked Transition Matrix**)  

| இரண்டு வார்த்தைகள் (Combination) | அடுத்த வார்த்தை | நிகழ்தகவு (Probability) |
| ---------------------------- | ------------ | ---------------------- |
| பள்ளிக்குச் சென்றான், வீட்டிற்குத்    | திரும்பினான்   | 0.0                    |
| பூங்காவிற்குச் சென்றான், வீட்டிற்குத் | திரும்பினான்   | 0.0                    |
| பாடங்களைக் கற்றான், வீட்டிற்குத்     | திரும்பினான்   | 1.0                    |
| பூக்களைப் பார்த்தான், வீட்டிற்குத்    | திரும்பினான்   | 1.0                    |

விளக்கம்:  

1. **"பாடங்களைக் கற்றான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
2. **"பூக்களைப் பார்த்தான், வீட்டிற்குத்"** என்ற இரண்டு வார்த்தைகளுக்கு அடுத்து **"திரும்பினான்"** வரும் நிகழ்தகவு **1.0** ஆகும்.  
3. **"பள்ளிக்குச் சென்றான், வீட்டிற்குத்"** மற்றும் **"பூங்காவிற்குச் சென்றான், வீட்டிற்குத்"** போன்ற கலவைகள் மாஸ்க் செய்யப்பட்டு, அவற்றின் நிகழ்தகவு **0.0** ஆகும்.  

மாஸ்கிங் முறை, மொழி மாதிரிகளில் (language models) மிகவும் பயனுள்ளதாக இருக்கிறது. இது முக்கியமான தகவல்களை மட்டும் கணக்கில் எடுத்துக்கொண்டு, பயனற்ற தகவல்களை வடிகட்டுகிறது. இது மாதிரியின் செயல்திறனை மேம்படுத்துகிறது மற்றும் துல்லியமான கணிப்புகளை வழங்குகிறது. மாஸ்கிங் முறையின் முக்கிய நன்மை என்னவென்றால், அது மாதிரியின் நம்பகத்தன்மையை (confidence) அதிகரிக்கிறது. பயனற்ற கலவைகளை மறைப்பதன் மூலம், மாதிரி மிகவும் துல்லியமான கணிப்புகளைச் செய்கிறது.  

<hr class="pagebreak">

### 5. பெரிய மொழி மாதிரிகள் (Large Language Models - LLMs)

Transformers கட்டமைப்பின் தோற்றம் இயற்கை மொழி செயலாக்கம் (Natural Language Processing - NLP) துறையில் ஒரு பெரும் புரட்சியை ஏற்படுத்தியது. ஆனால் அதன் உண்மையான சக்தி, பில்லியன் கணக்கான அளவுருக்கள் கொண்ட **பெரிய மொழி மாதிரிகள் (Large Language Models - LLMs)** மூலம் வெளிப்பட்டது.

GPT (Generative Pretrained Transformer), BERT (Bidirectional Encoder Representations from Transformers) போன்ற மாதிரிகள், Attention மற்றும் Self-Attention என்ற நுண்ணிய கோட்பாடுகளை அடிப்படையாகக் கொண்டு உருவாக்கப்பட்டு, மனிதரைப் போலவே மொழியைக் கற்றுக்கொண்டு, அதை அனுபவத்துடன் செயலாக்கும் திறனைக் கொண்டுள்ளன.

இந்த அத்தியாயத்தில், LLM-கள் எப்படி உருவாக்கப்படுகின்றன, அவை எப்படி பயிற்சி பெறுகின்றன, எவ்வாறு நுணுக்கமான பதில்களை வழங்குகின்றன, மற்றும் அவற்றின் பயன்பாடுகள் என்னென்ன என்பதை விரிவாக ஆய்வுப்போல் பார்ப்போம்.

------

##### 5.1. கடைக்கால் மாதிரிகள் (Foundation Models)

**Foundation Models** என்பது, பல்வேறு செயற்கை நுண்ணறிவு (AI) பயன்பாடுகளுக்கு அடித்தளமாக விளங்கும் சக்திவாய்ந்த பொதுவான (general-purpose) மாதிரிகள். இவை ஒரு குறிப்பிட்ட பணிக்காக உருவாக்கப்படாதிருந்தாலும், அதற்கு fine-tune செய்யக்கூடியவை. பொதுவாக, இவை மிகப்பெரிய தரவுத்தொகுப்புகளில் முன்னிலைப் பயிற்சி (Pretraining) பெறும், பின்னர் domain-specific fine-tuning மூலம் தேவைக்கேற்ப தனிப்பயனாக்கப்படுகின்றன.

Foundation Models-ஐ உருவாக்கும் செயல்முறை:

1. **பெரிய அளவிலான தரவுகள் (Large-scale Data):** இணையம், புத்தகங்கள், கட்டுரைகள், விக்கிப்பீடியா போன்றவை.
2. **மிகுந்த கணிப்பொறி வளம் (Compute Power):** பெரும் அளவிலான GPU/TPU கிளஸ்டர்கள் பயன்படுத்தப்படுகின்றன.
3. **அளவுருக்கள் (Parameters):** மாடலின் அளவு பில்லியன் அளவுருக்களாக இருக்கலாம் (e.g., GPT-3 – 175B).
4. **விரிவான கட்டமைப்புகள் (Architectures):** Transformers மற்றும் attention-based deep neural networks.

Foundation Models உருவாக்கம் ஏன் முக்கியம்?

- இவை பலதரப்பட்ட பணிகளை ஒரே மாதிரி செய்யக்கூடியவை.
- உரை மொழிபெயர்ப்பு, உரை சுருக்கம், கேள்வி-பதில் அமைப்பு, chatbots, sentiment analysis போன்ற பல NLP பணிகளில் பயன்படுத்தப்படுகின்றன.
- ஒரே மாடலை, தேவைப்படும் துறைக்கேற்ப fine-tune செய்வதன் மூலம் விரைவில் பயிற்சி செய்து பயன்படுத்த முடிகிறது.

**உதாரணம்:** GPT-3 போன்ற Foundation Model-ஐ எடுத்துக் கொள்ளுங்கள். இது ஒரே மாதிரி, கேள்விகளுக்கு பதில் அளிக்கும் bot ஆகவும், கட்டுரைகள் எழுதும் உதவியாளராகவும், Python நிரல்களை எழுதும் கோடிங் அசிஸ்டன்டாகவும் செயல்பட முடிகிறது.

இந்த மாதிரிகளை நாம் ஒரு *அடித்தள அறிவைக் கொண்ட நபராக* பார்க்கலாம். அவருக்கு எந்தத் துறையில் வேலை செய்ய வேண்டுமென நீங்கள் சொல்லினால், அதற்கேற்ப சிறப்புப் பயிற்சி கொடுத்தால், அவர் அந்தத் துறையில் சிறந்த செயல்திறனைக் காண்பிப்பார். இதுவே Foundation Model-ஐ Fine-tune செய்வதன் நோக்கமாகும்.

Foundation Model உருவாக்கம் பொதுவாக மூன்று முக்கிய அம்சங்களைக் கொண்டு மதிப்பீடு செய்யப்படுகிறது:

1. **பயிற்சித் தரவுகள் (Training Data):** தரவின் தரமும் பரப்பும்.
2. **மாதிரி கட்டமைப்பு (Architecture):** Transformer layers, attention heads, hidden sizes போன்றவைகள்.
3. **மனிதம் சார்ந்த ஒழுங்குபடுத்தல் (Post-training / Human Feedback):** RLHF, human annotation, filter-based scoring போன்றவைகள்.

##### 5.2. முன்னிலைப் பயிற்சி (Pretraining)

பெரிய மொழி மாதிரிகளை (LLMs) உருவாக்குவதில் முதற்கட்டமாகச் நடைபெறும் செயல்முறைதான் **முன்னிலைப் பயிற்சி** அல்லது **Pretraining**. இது எந்த ஒரு குறிப்பிட்ட பணிக்காக அல்ல, பொதுவான மொழி அறிவைப் பெறுவதற்காக நடைபெறும்.

இது மனிதனுக்கு பள்ளிக்குச் செல்லும் முன் கற்றுக் கொள்ளும் அடிப்படை அறிவைப் போன்றது. எழுத்து, சொற்கள், வாக்கிய அமைப்புகள், புணர்ச்சிப் பொருள் போன்றவற்றைச் சராசரியாகப் புரிந்து கொள்வது போல, LLM-களும் மொழியின் இலக்கணம் மற்றும் சொற்கள் இடையிலான உறவுகளை இந்த கட்டத்தில் கற்றுக்கொள்கின்றன.

###### 5.2.1 பயிற்சி தரவுகளின் தன்மை

Pretraining நடக்கும் தரவுகள் பொதுவாக மிகப்பெரிய அளவிலான, தன்னிச்சையான மற்றும் வெவ்வேறு துறைகளிலிருந்து பெறப்பட்ட உள்ளடக்கங்களை கொண்டிருக்கும். இதில் பொதுவாக பின்வரும் தரவுத்தொகுப்புகள் அடங்கும்:

- **Wikipedia**: தகவல் மற்றும் பொதுவான அறிவைப் பெற உதவும்.
- **BooksCorpus**: இலக்கியம் மற்றும் கதைகளை உள்ளடக்கியது.
- **Common Crawl**: இணையத்தில் உள்ள பல்லாயிரக்கணக்கான இணையதளங்களில் இருந்து சேகரிக்கப்பட்ட திறந்த தரவுகள்.
- **OpenWebText**: Reddit போன்ற சமூக வலைத்தளங்களில் பரிந்துரைக்கப்படும் தரமான இணையப்பக்கங்கள்.
- **Project Gutenberg**: புத்தகங்கள், சிறுகதைகள் போன்ற மரபு இலக்கியத் தொகுப்புகள்.

இந்த தரவுகள் அனைத்தும், மாடலுக்கு பன்மொழி, பல்துறை மற்றும் பல்லாயிரக்கணக்கான மொழி நடைகளைப் பற்றிய புரிதலை வழங்குகின்றன. சில தரவுகள் பிழைகள் கொண்டிருந்தாலும், அவை பெரிய அளவில் படிக்கப்படுவதால், மாடலுக்கு ஒரு பரந்த மொழி அறிவைப் கட்டியெழுப்ப உதவுகின்றன.

###### 5.2.2 பயிற்சியின் விதிகள் – Masking மற்றும் Autoregression

Pretraining பல்வேறு பயிற்சி நுட்பங்களைக் கொண்டுள்ளது. அதில் முக்கியமானவை இரண்டு:

**1. Masked Language Modeling (MLM)**

இது BERT போன்ற Encoder-based மாதிரிகளால் பயன்படுத்தப்படும் முறை.

- ஒரு வாக்கியத்தில் சில சொற்கள் **மறைக்கப்பட்டு (masked)** விடப்படும்.
- மாடல், அந்த இடத்தில் எந்த சொல் வரும் என கணிக்கக் கற்றுக்கொள்ளும்.
- இது மாடலுக்கு வாக்கியத்தின் முழு சூழ்நிலையை (context) புரிந்துகொள்ள உதவுகிறது.

**உதாரணம்**:

“தமிழ் ஒரு மிகப் பழமையான [MASK] ஆகும்.”

மாடல், அதன் முன்னும் பின்னும் உள்ள சொற்களை பார்த்து, ‘மொழி’ என்பதை எடுக்கும்.

**2. Causal Language Modeling (Autoregressive)**

இது GPT மாதிரிகளின் பயிற்சி முறை. இதில், ஒரு சொல் வருவதற்கு முன் வந்த சொற்கள் மட்டுமே பார்க்க அனுமதிக்கப்படுகிறது.

- மாடல், வாக்கியத்தை இடதிலிருந்து வலது நோக்கி படிப்பதுபோல் பயிற்சி பெறுகிறது.
- ஒவ்வொரு கட்டத்திலும், பிந்தைய சொல் என்னவாக இருக்கலாம் எனக் கணிக்கின்றது.

**உதாரணம்**:

“தமிழ் ஒரு மிகப் பழமையான …” → அடுத்த சொல்லை ‘மொழி’ என கணிக்க முயற்சி செய்கிறது.

இந்த இரண்டு பயிற்சி முறைகளும் மாடலுக்கு:

- சொற்களின் இடமாற்றங்களை (word associations)
- வாக்கிய கட்டமைப்பை (sentence structure)
- சூழ்நிலைப் பொருத்தத்தை (semantic context)

புரிந்து கொள்ளும் திறனை அளிக்கின்றன.

###### 5.2.3 Pretraining எதற்காக?

Pretraining என்பது, ஒரு LLM-ஐ மனித மொழியில் **பொதுவான அறிவு** மற்றும் **நுண்ணறிவு தொடர்புகள்** கொண்டது போல் உருவாக்குவதற்காகவே.

- இது domain-specific அறிவு இல்லாமல் இருந்தாலும், மொழியின் இயல்பை (linguistic intuition) கற்றுக்கொள்கிறது.
- பரந்த அளவிலான உரை தரவுகளை வாசிப்பதன் மூலம், synonyms, grammar rules, idiomatic expressions போன்றவை பற்றி புரிந்து கொள்கிறது.
- இது **zero-shot** அல்லது **few-shot** learning-க்கு வழிவகுக்கும் – அதாவது, ஒரு புதிய வேலைக்காக மிகக் குறைந்த data-விலேயே பயன்படுத்தக்கூடிய அளவுக்கு general knowledge உருவாகிறது.

###### 5.2.4 திறன்கள் மற்றும் வரம்புகள்

Pretraining மாடலுக்கு பல திறன்களைத் தருகின்றது, ஆனால் சில வரம்புகளும் உள்ளன.

**திறன்கள்**:

- பொதுவான உரை புரிதல் மற்றும் பதிலளித்தல்
- வினா-விலக்குகள், சுருக்கம், மொழிபெயர்ப்பு, creative writing
- பன்மொழி புரிதல் (Multilingual understanding), குறிப்பாக multilingual datasets-ஐ பயன்படுத்தினால்

**வரம்புகள்**:

- மாடலுக்கு task-specific விளக்கம் அல்லது domain-specific knowledge இல்லை
- Data Bias – பயிற்சி தரவுகள் இருந்த இடைச்செருக்குகள், சமூக முன்னேற்பாடுகள் அல்லது தவறான தகவல்களால் மாடல் பயிற்சி பெறலாம்
- hallucination – உண்மையில்லாத, ஆனால் நம்பத்தக்கதாகத் தோன்றும் தகவல்களை உருவாக்கும் சிக்கல்

###### 5.2.5 பயிற்சி செலவுகள் மற்றும் கணிப்பொறி ஆதாரம்

Pretraining என்பது மிகப் பெரிய கணினி வளங்களை (compute resources) தேவைப்படுத்தும். இது பொதுவாக Google TPU, NVIDIA A100 GPU போன்ற மென்மையான hardware-ஐ நாடும்.

- GPT-3 போன்ற மாடலை பயிற்சி செய்ய நூற்றுக்கணக்கான GPU-கள், வெகுநாட்கள் தேவைப்படும்.
- Pretraining செலவு **மில்லியன் டாலர்** வரையில் இருக்கலாம் (பண்புத்தன்மை, தரவளவு, iteration எண்ணிக்கை போன்றவற்றைப் பொருத்து).

இந்த Pretraining கட்டத்தில், ஒரு LLM-க்கு ஒரு பொதுவான மொழி அறிவுத் தளமுறை உருவாக்கப்படுகிறது. இது, இத்துடன் Fine-tuning மற்றும் Post-training ஆகிய செயல்முறைகள் வந்தால், அந்த மாடல் ஒரு சிறந்த தொழில்நுட்ப உதவியாளராக, அல்லது நிபுணத் துறையில் பேசக்கூடிய language model-ஆக மாறும்.

##### 5.3. நுண்-பயிற்சி (Fine-Tuning) — விரிவான விளக்கம்

மிகப்பெரிய தரவுத்தொகுப்புகளை வைத்து Pretraining செய்யப்பட்ட ஒரு LLM, மனித மொழியை ஒரு அளவிற்கு பொதுவாகப் புரிந்துகொள்ளும். ஆனால், நாம் அதை ஒரு **குறிப்பிட்ட செயற்கை நுண்ணறிவு பணிக்கோ, ஒரு தொழில்நுட்பம் சார்ந்த சூழலுக்கோ, அல்லது ஒரு துறைமுகமாக செயல்படுத்த** விரும்பினால், நாம் அதை Fine-Tune செய்யவேண்டும்.

இந்த Fine-Tuning என்பது, மாடலை ஒரு வழக்கமான **பொதுவான அறிவு உள்ள நபர்** என எடுத்துக்கொள்வதுபோல். அந்த நபரை நீங்கள் மருத்துவராக்க விரும்பினால், அவருக்கு மருத்துவப் பாடங்கள் சொல்லித் தர வேண்டும். அதேபோல், LLM-ஐ மருத்துவ நோக்கத்துக்குப் பயன்படுத்த, அதை **medical datasets** மூலம் fine-tune செய்ய வேண்டும்.

**வாழ்க்கைசார்ந்த உதாரணம்:**

ஒரு சிறந்த சமையல்கலை நிபுணரை நினைத்துப் பாருங்கள். அவர் இந்தியா முழுக்க பயணம் செய்து பல்வேறு வகையான உணவுகளை சுவைத்திருக்கிறார் (Pretraining). ஆனால், நீங்கள் அவரை ஒரே நிகர் மட்டமான ஹைதராபாத் பிரியாணி சமையல்காரராகக் உருவாக்க விரும்பினால், அவர் **ஹைதராபாத் சமையல் வழிமுறைகளை மட்டும் பயில வேண்டும்** (Fine-Tuning).

**உதாரணம் 1: மருத்துவம்**

Pretrained LLM, “புற்றுநோய் என்றால் என்ன?” என்ற கேள்விக்கு பொதுவான பதிலை வழங்கும்.

> **பொதுவான பதில்:**

> “புற்றுநோய் என்பது ஒரு உயிரணுக்களின் கட்டுப்பாடற்ற பெருக்கம், இது உடலின் பல பகுதிகளில் பாதிப்புகளை ஏற்படுத்தும்.”

ஆனால் நீங்கள் அதே LLM-ஐ, PubMed கட்டுரைகள், நோயாளி விவரங்கள், மருந்து தொடர்பான குறிப்புகள், மருத்துவ வழிகாட்டிகள் போன்றவை மூலம் Fine-Tune செய்தால், அது மேலும் விபரமாகவும், நிலைத்த பதில்களையும் வழங்கும்:

> **Fine-Tuned பதில்:**

> “புற்றுநோய் என்பது ஒரு neoplastic condition ஆகும், இதில் abnormal cells G1/S phase-ல் cell cycle checkpoints-ஐ மீறி பெருகுகின்றன. அதனாலேயே metastasis ஏற்படுகிறது.”

இது ஒரு நோயாளிக்கு மருந்து பரிந்துரை செய்யும் Clinical Decision Support System (CDSS)-இல் நேரடியாக பயன்படுத்தலாம்.

**உதாரணம் 2: சட்டத் துறை (Legal AI)**

நீங்கள் ஒரு LLM-ஐ சட்டம் தொடர்பான வேலைக்குப் பயன்படுத்த விரும்பினால், அதை Indian Penal Code (IPC), Supreme Court judgments, contracts, legal memos போன்றவற்றுடன் fine-tune செய்யலாம்.

- Fine-Tuning இல்லாமல்: “ஒரு ஒப்பந்தம் என்ன?” என்றால், பொதுவான பதில்தான் வரும்.
- Fine-Tuned LLM: Section 10, Indian Contract Act 1872-ஐ மேற்கோள்களுடன் விவரிக்கும்.

> **“ஒரு ஒப்பந்தம் சட்டரீதியாகச் செல்லத்தக்கதா என்பதை Article 299(1) of the Constitution மற்றும் Section 23, 24 of the Indian Contract Act இன் அடிப்படையில் மதிப்பீடு செய்ய வேண்டும்”** என்று பதிலளிக்க முடியும்.

**உதாரணம் 3: வணிகம் மற்றும் வாடிக்கையாளர் சேவை**

நீங்கள் ஒரு SaaS நிறுவனத்திற்கு FAQ bot உருவாக்க விரும்புகிறீர்கள் என்றால், அதற்காக அந்த நிறுவனம் வைத்திருக்கும்:

- வாடிக்கையாளர் support chat logs
- Troubleshooting articles
- Onboarding guides

போன்றவற்றை fine-tune செய்யலாம்.

> **Generic LLM பதில்:** “இந்த மென்பொருளைப் பயன்படுத்த நீங்கள் login செய்ய வேண்டும்.”

> **Fine-Tuned LLM பதில்:** “Click on ‘My Account’ in the top-right corner, then choose ‘Manage Subscription’ to view your active usage limits and billing plan.”

இதுபோன்ற deep product awareness பதில்கள், only fine-tuning மூலமே பெறக்கூடியவை.

**Fine-Tuning வகைகள் மற்றும் modern techniques**

| **Fine-Tuning முறை**       | **விளக்கம்**                                                   | **நன்மை**                  |
| -------------------------- | ------------------------------------------------------------ | ------------------------- |
| Full Fine-Tuning           | முழு மாடலையும் மீண்டும் train செய்வது                             | பயிற்சிக் கட்டுப்பாடு அதிகம்   |
| Adapter Layers             | மாடலுக்கு இடையே சிறிய layers சேர்த்து, அவை மட்டுமே update செய்யும் | மெமரி இடம் குறைவு          |
| LoRA (Low Rank Adaptation) | Matrix decomposition மூலம் fine-tune                          | resource-efficient        |
| Prompt Tuning              | Prompt vectors-ஐ மட்டுமே update செய்வது                        | மெகா LLM-களுக்கேற்ப சிறந்தது |

**Bias handling during Fine-Tuning**

Fine-Tuning தரவுகள் தவறாக curate செய்யப்பட்டிருந்தால், அது bias-ஐ உருவாக்கலாம்.

**உதாரணம்:**

ஒரு customer support LLM-ஐ fine-tune செய்யும் போது, training dataset-இல் அனைத்தும் *angry customers* ஆக இருந்தால், அதுவே மாடலின் சுயநிலையை உருவாக்கிவிடும் – பயனர் எதையாவது கேட்டால், அது “மன்னிக்கவும், இது உங்கள் தவறே!” என்று பதிலளிக்கும் அபாயம் உள்ளது.

அதனால், fine-tuning dataset-ஐ தொடர்ந்து validate செய்வது முக்கியம்.

**Fine-Tuning with Human-in-the-Loop (HITL)**

இன்று அதிகமான AI நிறுவனங்கள் Fine-Tuning-ஐ மனித பார்வையுடன் இணைத்துப் பணியாற்றுகின்றன:

- **மனித annotators**, model-generated response-ஐ score செய்கின்றனர் (better/worse)
- இவை reward function ஆகும்
- Reinforcement Learning with Human Feedback (RLHF) மூலமாக policy gradients update செய்யப்படும்

**GPT-4, ChatGPT போன்றவை இதைத்தான் பயன்படுத்துகின்றன.**

இவ்வறு, Fine-Tuning என்பது ஒரு LLM-ஐ முழுமையான பொதுத்திறமையிலிருந்து, **நுட்பமான பணிக்குச் சீரமைக்கும்** முக்கிய அடிக்கோலாகும். அது இல்லாமல், LLM பொதுவான, ஆனால் மேற்பரப்பான பதில்களை மட்டுமே வழங்கும்.

மிகவும் சரி. இப்போது நீங்கள் கேட்டதுபோல், **Post-training மற்றும் Human Feedback** பற்றி மேலும் ஆழமாகவும், நூல்வகைத் தரம் கொண்ட தருணச்சிந்தனையுடனும் விரிவாக்குகிறேன். இவை LLM-களின் மனிதர்களுடன் ஏற்கத்தக்க முறையில் செயல்படும் திறனை உருவாக்குவதற்கான அறியமான கட்டமாகும்.



##### 5.4. பிந்தைய பயிற்சி (Post-training) மற்றும் மனிதப் பின்னூட்டம் (Human Feedback)

பெரிய மொழி மாதிரிகள் (LLMs) இயற்கை மொழியைப் புரிந்துகொள்வதிலும், தரவுகளில் இருந்து பொதுவான மற்றும் துறையறிந்த அறிவைப் பெற்றுக்கொள்வதிலும் திறமை பெறுகின்றன. ஆனால், இவை **மனிதர்களின் எதிர்பார்ப்பு**, **நாகரிக கட்டுப்பாடுகள்**, **மதிப்பீடு மற்றும் ஒழுங்குமுறைகள்** போன்றவற்றுக்கு ஒத்திசைவாக செயல்பட வேண்டுமானால், இன்னும் ஒரு மேலதிக பயிற்சி கட்டம் தேவைப்படுகிறது. அதுவே **Post-training** எனப்படும்.

இந்த Post-training கட்டத்தில், LLM-கள் தொடர்ந்து மொழியை நிர்வாகிக்கின்றன. ஆனால் அவை இப்போது **மனிதர்களுடன் உரையாடல்களில் ஏற்படக்கூடிய நுண்ணிய சூழ்நிலைகளை** புரிந்துகொள்வதற்கும், அதன் அடிப்படையில் பதில்களை உருவாக்குவதற்கும் முயற்சிக்கின்றன.

###### 5.4.1 Post-training: நோக்கம் மற்றும் தேவை

ஒரு pretrained மற்றும் fine-tuned LLM, ஒரு கேள்விக்குத் தரமான பதிலை அளிக்கத் தயாராக இருக்கலாம். இருப்பினும், அவற்றின் பதில்கள்:

- பயனாளியின் உணர்வுகளை புறக்கணிக்கக்கூடியது,
- சமூக நெறிமுறைகளுக்கு எதிரானதாக இருக்கக்கூடியது,
- தவறான/பொதுவாகச் சங்கடமுறையாக்கும் தகவல்களை வழங்கக்கூடியது

எனும் சிக்கல்களை ஏற்படுத்தலாம்.

இதனைத் தவிர்க்க, LLM-களில் மனிதர்களின் மதிப்பீடு மற்றும் விருப்பங்களை அடிப்படையாகக் கொண்டு உருவாக்கப்படும் **“alignment”** என்பது ஒரு முக்கிய அம்சமாக செயல்படுகிறது. Post-training என்பது alignment-ஐ மேம்படுத்தும் பயிற்சியாகும்.

###### 5.4.2 Reinforcement Learning with Human Feedback (RLHF)

Post-training ல் பயன்படுத்தப்படும் முக்கிய நுட்பம், **மனிதப் பின்னூட்டத்துடன் கூடிய பலப்படுத்தும் கற்றல்** (Reinforcement Learning with Human Feedback - RLHF) ஆகும். இது மூன்று அடுக்குகளில் செயல்படுகிறது:

**1. மேற்பார்வையுடன் கூடிய நுட்ப பயிற்சி (Supervised Fine-Tuning - SFT)**

முன்கூறிய human-like response-கள் கொண்ட தரவுகளை கொண்டு, மாடல் ஒரு conversation அல்லது task-க்கு ஏற்ற பதில்கள் அளிக்க கற்றுக்கொள்கிறது.

உதாரணமாக, StackExchange, Reddit போன்ற இணைய சமூகங்களில் இருந்து தொலைக்காட்சி உரையாடல்கள் மற்றும் உத்தரவு-பதில்கள் (instruction-response pairs) எடுக்கப்படும்.

**2. விருப்பம் அடிப்படையிலான மதிப்பீட்டு மாதிரி (Reward Model Training)**

மாடல் இரண்டு அல்லது மூன்று பதில்களை வழங்கும். பின்னர், **மனித மதிப்பீட்டாளர்கள்** (human annotators) அவற்றில் எது சிறந்தது என்று தேர்வு செய்கின்றனர்.

இதில் உருவாகும் தரவுகள் ஒரு **reward model** உருவாக்குவதற்காக பயன் படுத்தப்படும். இந்த reward function என்பது “இந்த பதில் நல்லதா, தீமையா?” என்பதற்கான மதிப்பீடு அளவுகோலாகும்.

**3. கொள்கை மேம்பாடு (Policy Optimization)**

இந்த reward model-ஐ பயன்படுத்தி, Reinforcement Learning மூலம் LLM-ஐ மாற்றுகின்றனர். Proximal Policy Optimization (PPO) என்ற ஒரு ஆல்கொரிதம் பயன்படும். இதன் மூலம், LLM புதிய பதில்களை உருவாக்கும்போது, அந்த reward மாடலின் விருப்பங்களை பூர்த்தி செய்யும் வண்ணம் செயல்படும்.

###### 5.4.3 RLHF பயிற்சி முறை: செயல்முறை சுழற்சி

1. ஒரு கேள்வி அல்லது உத்தரவு வழங்கப்படுகிறது.
2. LLM இரண்டு அல்லது அதற்கு மேற்பட்ட பதில்களை உருவாக்குகிறது.
3. மனித annotators அவற்றை மதிப்பீடு செய்து ஒரு பதிலை மேலாக மதிப்பீடுகிறார்கள்.
4. இந்த human-preference தரவுகள் மூலம் reward model பயிற்சி பெறுகிறது.
5. அந்த reward-ஐ அதிகபட்சமாகச் செய்யும் (maximize) வகையில், LLM அதன் பதில்களை மாற்றிக்கொள்கிறது.

இந்த செயல்முறை தொடர்ந்து மேற்கொள்ளப்படுவதால், LLM மெதுவாக **மனிதர்களின் நுண்ணிய எண்ணங்களுக்கும், ஒழுங்குப்பாடுகளுக்கும் ஒத்திசைவாக** செயல்படுகிறது.



###### 5.4.4 RLHF மூலம் ஏற்படும் செயல்மாற்றங்கள்

| **Pretraining + Fine-tuning வரை**                         | **RLHF/ Post-training பின்**                                  |
| --------------------------------------------------------- | ------------------------------------------------------------ |
| பதில்கள் factually சரியாக இருக்கலாம், ஆனால் தொடர்பற்றது          | பாத்திரம், நுண்மை, சூழ்நிலை ஆகியவற்றுடன் பதில்கள்                    |
| சமூகமையற்ற, சில சமயம் அசிங்கமாகக் கேட்கும் பதில்கள்               | மனித நாகரிக ஒழுக்க விதிகளுக்கு ஏற்ப பதில்கள்                      |
| hallucination இருக்கக்கூடும், ஆனால் பகுத்தறிவு குறைவாக இருக்கும் | உருவாக்கப்படும் தகவல்களில் நிலைத்த நுண்மை ஏற்படும்                    |
| Prompt sensitivity குறைவாக இருக்கும்                        | Prompt-இன் பாணி, எழுத்தியல் சிற்றுணர்வுகள் மற்றும் பயன்பாட்டு வழிமுறைகளை அனுசரிக்கும் |

###### 5.4.5 Bias Alignment மற்றும் Value Steering

முன்னிலைப் பயிற்சியில் bias உள்ள இடங்களை RLHF மூலமாக சீராக்க முடியும். உதாரணமாக, ஒரு pretrained LLM ‘engineer’ என்ற சொல்லை வலுவாக ‘he/his’ என்ற pronoun-களுடன் தொடர்புபடுத்தலாம். ஆனால் human feedback மூலம், அது **gender-neutral** பதில்களாக மாறும்.

மேலும், ஒன்று மிக முக்கியம்: RLHF-ஐ human values, ethics, emotional sensitivity மற்றும் legal constraints-க்கு ஒத்திசைக்கும் விதமாக அமைக்க முடியும். இதுவே “value steering” எனப்படும்.



###### 5.4.6 Post-training பயன்பாடுகள்

Post-training இல்லாமல் ஒரு LLM ஒரு **தொழில்நுட்ப கையேடாக** மட்டுமே இருக்கும். ஆனால் Post-training பின், அது:

- **வாடிக்கையாளர் உதவித் திட்டங்களில்**, நடுத்தரமான, பயனுள்ள பதில்கள் அளிக்கிறது
- **கல்வியில்**, மாணவர் உணர்வுகளைக் கவனித்துப் பதிலளிக்கிறது
- **உணர்வுப் பகுப்பாய்வு**, **mentorship**, **therapeutic response** ஆகியவற்றில் மனித உணர்வுகளை பரிசீலிக்கிறது
- **பொதுத்தகவல் பரிமாற்றம்**, **உண்மை தவறான செய்தி மீதான தடுப்பு**, **சமூக ஒழுக்க மரபுகள்** ஆகியவற்றை பின்பற்றுகிறது



###### 5.4.7 தனி மனித பாணி மற்றும் கேள்வி உணர்திறன் (Prompt Sensitivity)

Post-training செய்த LLM-கள் prompts-இன் பாணியும் கற்பனையும் வாசிக்கக்கூடிய நிலைக்கு உயர்கின்றன.

**“தலைவாசி என்றால் என்ன?”** என்பது போன்ற கேள்விக்கு ஒரு பொதுவான பதில் தரும் LLM, Post-training பின், “தலைவாசி என்றால் என்ன? அதில் உள்ள மருத்துவ விளக்கங்களை உணர்த்தவும்” என்ற வழிகாட்டல் prompt-ஐக் கொண்டு **துல்லியமான, செயல்படக்கூடிய** பதில்களை வழங்கும்.

###### 5.4.8 முடிவுகள்

Post-training என்பது ஒரு LLM-ஐ:

- வெறும் தரவுப் பிணைவுகளை அள்ளும் statistical engine-இலிருந்து
- மனித மொழியின் அழகு, நாகரிகம், உணர்வுப் பாங்கு ஆகியவற்றுக்கு ஒத்திசையும் ஒரு **மனிதநேயம் வாய்ந்த உரையாடல் செயற்கை நுண்ணறிவு அமைப்பாக** மாற்றும் வகை பயிற்சி கட்டம் ஆகும்.

இந்த கட்டத்துடன் முடியும் போது தான், LLM ஒரு **நம்பகமான, பாதுகாப்பான, நுண்ணிய மற்றும் விழிப்புணர்வுடைய சிந்தனையாளர்** ஆக செயல்படத் துவங்குகிறது.



மிக நன்றாக. இப்போது நாம் **5.5. பதில்கள் உருவாக்கும் நடைமுறைகள் (Sampling Techniques), Prompt Engineering மற்றும் Context Handling** ஆகியவற்றை விரிவாகப் பார்ப்போம். இது LLM-களின் செயற்கை நுண்ணறிவு உள்கட்டமைப்பின் செயல்பாடுகளை, மனிதர்களுக்குப் போல் மொழியை உளவியல் மற்றும் சூழ்நிலை அடிப்படையில் உருவாக்கும் திறனை விளக்கும் ஒரு மைய அத்தியாயம்.

##### 5.5. பதில்கள் உருவாக்கும் நுணுக்கங்கள் (Sampling, Prompting, Context)

Pretraining, Fine-Tuning மற்றும் Post-training ஆகிய மூன்று பயிற்சி கட்டங்களின் முடிவில், LLM ஒன்று **மனிதர்களைப் போல உரையாடல்களில் கலந்துகொள்ளும்**, கேள்விகளுக்கு பதிலளிக்கும், மற்றும் ஆழமான புரிதலைக் காட்டும் திறனுடன் வெளிப்படுகிறது. ஆனால், இவ்வாறு ஒரு பதிலை உருவாக்கும் போது LLM எவ்வாறு சொற்களைத் தேர்ந்தெடுக்கிறது என்பது குறித்த சரியான புரிதல் இல்லையெனில், நாம் அதன் உள்ளார்ந்த செயல்பாட்டை சரியாகக் கவனிக்க முடியாது.

இந்த அத்தியாயத்தில், LLM-கள் **ஒரு வாக்கியத்தை உருவாக்கும் போது என்னை அடிப்படையாக வைத்து** செயல்படுகின்றன, மற்றும் எப்படி **prompt-களின் வடிவமைப்பு** மற்றும் **context-இன் சீர்திருத்தம்** முடிவுகளை மாற்றும் என்பதை விவாதிப்போம்.

###### 5.5.1 பதில்கள் உருவாக்கும் திசைகள்: ஒரு நிலைப்பாடு

Transformer அடிப்படையிலான LLM-கள், உரையை வாக்கியங்களாக அல்லாது **tokens** எனப்படும் சிறு அலகுகளாகப் பிரிக்கின்றன. ஒவ்வொரு நிலைப்பதிலும், மாடல்:

- “அடுத்த token என்னவாக இருக்கக்கூடும்?” என்பதைப் probabilistically கணிக்கின்றது.
- அது **softmax** செயல்முறையின் மூலம், அனைத்து சாத்தியமான சொற்களுக்கும் நிகழ்தகவு (probability) மதிப்புகளை அளிக்கின்றது.
- அதன் பிறகு ஒரு **sampling strategy** அல்லது **decoding method** மூலம், அந்த எண்ணிக்கை வாய்ப்பு பட்டியலில் இருந்து ஒரு token தேர்ந்தெடுக்கப்படுகிறது.

###### 5.5.2 Deterministic vs. Stochastic Generation

பதிலை உருவாக்கும் இரண்டு முக்கிய முறைகள் உள்ளன:

1. **Deterministic** (உருதியான) – ஒவ்வொரு கட்டத்திலும் மிக அதிக வாய்ப்பு கொண்ட token-ஐ மட்டும் தேர்ந்தெடுக்கின்றது.
   - இதில் **greedy decoding** அல்லது **beam search** போன்ற முறைகள் பயன்படும்.
   - Output ஒன்று மட்டுமே, எப்போதும் ஒரே மாதிரியாக இருக்கும்.
2. **Stochastic** (வாய்ப்பான அடிப்படை) – probability-யை அடிப்படையாகக் கொண்டு சற்று randomness கொண்ட தேர்வைச் செய்யும்.
   - இதில் **Top-k**, **Top-p (nucleus sampling)** மற்றும் **Temperature-based sampling** போன்றவை அடங்கும்.
   - Output ஒவ்வொரு முறையும் மாறக்கூடும்; ஆனால் இதில் **படைப்பாற்றல்** அதிகம்.

##### 5.5.3 முக்கிய Sampling முறைகள்

**A. Temperature Sampling**

- Temperature என்பது ஒரு **அளவீட்டு அளவுரு**; அது randomness-ஐ கட்டுப்படுத்துகிறது.
- Temperature = 0 → மிகக் குறைந்த randomness; எப்போதும் probability-யில் முதலிடம் வகிக்கும் token மட்டுமே தேர்ந்தெடுக்கப்படும்.
- Temperature = 0.1 - 0.8 → probability படி தேர்வு நடைபெறும்.
- Temperature = 1 → மிகவும் படைப்பாற்றலான, ஆனால் அதிக வழுக்கல்கள் உள்ள பதில்கள்.

**உதாரணம்:**

Prompt: “தமிழ் மொழி என்பது…”

- Temperature 0: “தமிழ் மொழி என்பது ஒரு மிகப் பழமையான மொழியாகும்.”
- Temperature 1: “தமிழ் மொழி என்பது தமிழர்களின் பண்பாட்டு சிந்தனையின் உயிரெழுத்தாகக் கருதப்படுகிறது.”

**B.Top-k Sampling**

- Softmax மூலம் வரும் vocabulary-யில் இருந்து **k மிக உயர் probability-யை** கொண்ட tokens மட்டும் shortlist செய்யப்படும்.
- அதன் பிறகு, அந்த k token-களில் இருந்து ஒரு token சிறிது randomness உடன் தேர்ந்தெடுக்கப்படும்.

**உதாரணம்:**

k = 50 என்றால், vocabulary-யில் இருந்து மிக உயர்ந்த 50 tokens மட்டும் பயன்படுத்தப்படும்.

**C.Top-p Sampling (Nucleus Sampling)**

- இதுவும் Top-k போன்றது, ஆனால் **cumulative probability ≥ p** (பொதுவாக p = 0.9) என்ற அளவின் கீழ் tokens சேர்க்கப்படும்.
- இதனால் மிக அதிக probability உள்ள tokens மட்டும் பயன்படுத்தப்படுகின்றன.

Top-p என்பது **dynamic shortlist** உருவாக்குகிறது, ஆனால் Top-k என்பது **fixed shortlist**.

###### 5.5.4 Prompt Engineering

LLM-கள் மிகவும் **prompt-sensitive**. அதாவது, ஒரு கேள்வி எப்படி உருவாக்கப்படுகிறது என்பதற்கேற்ப, பதில் கணிசமாக மாறிவிடும்.

**உதாரணம் 1:**

- Prompt A: “எனக்கு சளி இருக்கு. என்ன மருந்து சாப்பிடலாம்?”
- Prompt B: “ஒரு மருத்துவராக, ஒரு வயதான நபர் சளியால் அவதிப்படுகிறார் என்றால், நீங்கள் என்ன பரிந்துரை செய்வீர்கள்?”

Prompt B-க்கு வரும் பதில் **clinical tone** உடன் இருக்கும். A-க்கு வரும் பதில் சாதாரண consumer-level ஆவியாக இருக்கும்.

**உதாரணம் 2:**

- Prompt: “ஒரு 100 வார்த்தைகளுக்குள் ‘இயற்கை’ பற்றி ஒரு கட்டுரை எழுதவும்.”
- Prompt: “இயற்கை என்றால் என்ன?”

முன்னைய prompt எழுத்து அளவு, பாணி ஆகியவற்றை கட்டுப்படுத்தும். LLM-ஐ ஒரு எழுத்தாளனாக அமைக்கும்.

###### 5.5.5 Prompt Design Strategies

Prompt Engineering இப்போது ஒரு தனி துறையாக வளர்ந்து வருகிறது. இதில் பின்வரும் உத்திகள் முக்கியமானவை:

- **Instructional Prompting**: “Translate this to French”, “Summarize this paragraph” போன்றவை.

- **Chain-of-Thought Prompting**: ஒரு தீர்வு எவ்வாறு அடையப்படுகிறது என்பதை reasoning வழியாக கூறும்.

- **Few-shot Prompting**: ஒரு கேள்விக்கு முன் 2-3 உதாரணங்களை கொடுத்து, மாடலை அதை புரிந்து பதிலளிக்கச் செய்வது.

- **Zero-shot Prompting**: context இல்லாமல், ஒரு instruction மட்டுமே.

  

###### 5.5.6 Context Window மற்றும் Memory Limitations

LLM-களுக்கு **context window** எனப்படும் ஒரு வரம்பு உள்ளது. இது பொதுவாக 2,000 tokens முதல் 128,000 tokens வரை (GPT-4, Claude 2.1 போன்ற மாடல்களில்).

- ஒரு conversation அல்லது document-ல் ஒரு LLM context-ஐ வைத்துக்கொண்டு reasoning செய்ய முடியும் என்பது அதன் limitations-க்கு உட்பட்டது.
- Context overflow-ஆனால் பழைய விவரங்கள் “தொலைந்து” போகலாம்.
- Context-aware prompting-ஐ optimize செய்வதன் மூலம், தேவையான history மட்டுமே மாடலுக்கு feed செய்யப்படுகிறது.

###### 5.5.7 Practical Case: தமிழ் புத்தக சுருக்கம்

Prompt:

“தெனாலிராமனின் சிறுகதை தொகுப்பில் உள்ள மூன்றாவது கதையை சுருக்கமாக, 5 வரிகளில் சொல்லவும்.”

இந்த prompt:

- Story retrieval

- Logical condensation

- Cultural tone alignment

  என மூன்றையும் பொருத்தப்படுத்த வேண்டிய ஒரு sample task ஆகும்.

LLM, இதற்குள் reasoning செய்து:

- கதை யார் பற்றி

- முக்கிய conflict என்ன

- தீர்வு என்ன

  இவற்றை பட்டியலிட்டு, ஒரு அட்டவணையை மனதிற்குள் கட்டமைத்துப் பதிலளிக்கும்.

###### 5.5.8 சாராம்சம்

- LLM ஒரு பதிலை உருவாக்கும் போது, அது **வாய்ப்பு அடிப்படையில்** சொற்களை தேர்ந்தெடுக்கும்.
- இந்த தேர்வில் randomness-ஐ கட்டுப்படுத்த Sampling Techniques முக்கிய பங்கு வகிக்கின்றன.
- Prompt-ஐ எந்த வார்த்தைகளில், எந்த அமைப்பில் தருகிறோம் என்பதைப் பொருத்து பதில்கள் மாறுகின்றன.
- Context window வரம்புகள் உள்ளன; ஆனால் அவற்றை முறையாக நிர்வகித்தால் தரமான உரையாடல்கள் உருவாக்கலாம்.

மிகச் சிறப்பு. இப்போது நாம் **5.6: LLM-களின் பயன்பாடுகள், சவால்கள் மற்றும் தமிழ் போன்ற மொழிகளில் அமலாக்கம்** என்ற பகுதிக்குச் செல்வோம். இது LLM-களின் செயல்திறன் எவ்வாறு நவீன தொழில்நுட்பங்களில் பல்வகையாக பயன்படுகிறது, மற்றும் குறைவான மூலங்களுடன் (low-resource settings) இந்த மாதிரிகளை உருவாக்குவதற்கான நுட்பங்களை ஆராயும்.



##### 5.6. பயன்பாடுகள், சவால்கள் மற்றும் தமிழ் போன்ற மொழிகளில் LLM வளர்ச்சி

பெரிய மொழி மாதிரிகள் (LLMs) இன்று வெறும் ஆராய்ச்சி லாபங்களிலேயே நின்றுவிடவில்லை. அவை பன்முகப் பயன்களுடனும், பல்துறை பயன்பாடுகளுடனும் உலகளாவிய மாற்றங்களை ஏற்படுத்தி வருகின்றன. ஆனால் இவ்வளவு வலிமையுள்ள தொழில்நுட்பத்தை **தமிழ் போன்ற குறைவான மூலமுள்ள (low-resource) மொழிகளில்** கொண்டு வருவதற்கு பல சவால்களும், அதனை மீறிச் செல்லக்கூடிய புதிய முயற்சிகளும் உள்ளன.

###### 5.6.1 LLM-களின் முக்கிய பயன்பாடுகள்

LLM-கள் இன்று பல்வேறு துறைகளில் வலுவான செயல்திறனைக் காண்பிக்கின்றன:

**1. கல்வி:**

- மாணவர்கள் கேட்கும் கேள்விகளுக்கான விளக்கங்களை தருவது

- கட்டுரை எழுத்து, பதிலளிப்பு, மொழிபெயர்ப்பு

- ஆசிரியர்கள் பாடநெறிகளை வடிவமைப்பதில் உதவி


**2. மருத்துவம்:**

- நோயாளியின் அறிகுறிகளை வைத்து நோய்க்களங்களை சுட்டிக்காட்டுவது
- மருந்து தொடர்பான வினாக்களுக்கு அறிவுப்பூர்வமான பதில்கள்
- மருத்துவ ஆவணங்களை சுருக்கம் செய்தல் (Clinical Summarization)

**3. வணிகம் மற்றும் வாடிக்கையாளர் சேவை:**

- Chatbot ஆக வாடிக்கையாளர்களுக்கு பதிலளித்தல்
- தயாரிப்பு பற்றிய தகவல் வழங்கல்
- விற்பனை, சந்தைப்படுத்தல் மற்றும் பயனர் ஆதரவு

**4. சட்டம் மற்றும் சட்ட ஆலோசனை:**

- சட்ட பத்திகளை விளக்குதல்
- நீதிமன்ற தீர்ப்புகளை தெளிவுபடுத்துதல்
- சட்ட வழிகாட்டி உதவிகள்

**5. பொருளாதாரம் மற்றும் பங்கு சந்தை:**

- பங்கு சந்தை மாற்றங்களை பகுப்பாய்வு செய்தல்
- காலாண்டு அறிக்கைகள், விளக்கப்படுத்தல்
- புள்ளிவிவர தரவுகளை மொழிபெயர்க்கின்ற அறிவு உதவியாளர்

**6. உள்ளமைப்பு மேலாண்மை (Infrastructure Management):**

- நிரல் உதவி (e.g., code autocomplete)
- டாகுமென்டேஷன் உருவாக்கம்
- API design/validation

###### 5.6.2 தமிழ் போன்ற குறைவான மூலமுள்ள மொழிகளுக்கான சவால்கள்

**Low-resource languages** எனப்படும் மொழிகள் (தமிழ், மலையாளம், கன்னடம், சிங்களம், ஹவுசா, சோமாலி போன்றவை) LLM-களால் குறைவாக சேவை செய்யப்படுகின்றன. இதற்குப் பின்னே சில முக்கிய காரணங்கள் உள்ளன:

**1. தரவின் அளவு குறைவு:**

- Wikipedia, Common Crawl போன்ற இடங்களில் தமிழ் போன்ற மொழிகளில் உள்ள உரைத் தொகுப்பு மிகக் குறைவாக உள்ளது.
- நூல்கள், செய்தித்தாள்கள், வலைப்பதிவுகள் போன்ற தரவுகள் மொத்தமாகவும் குறைவாக சேகரிக்கப்பட்டுள்ளன.

**2. தரவின் தரம்:**

- தமிழில் காணப்படும் பல இணையதள தரவுகள் பிழைகள் நிறைந்தவை, அல்லது conversational tone-ல் இல்லை.
- கிராமிய மொழி நுணுக்கங்கள், பன்மொழி கலப்புகள் உள்ளன.

**3. Unicode & Encoding சிக்கல்கள்:**

- தமிழ் எழுத்துக்குறிகள் Unicode-ல் சீர்படுத்தப்படாமல், பன்முக சிக்கல்கள் ஏற்படுகின்றன.
- எழுத்துப்பிழைகள், font mismatch, transliteration usage என அனேக encoding சிக்கல்கள் இருக்கின்றன.

**4. Annotation பணியின் விலை:**

- தமிழ் போன்ற மொழிகளில் பணம் செலவழித்து data curators/annotators வைத்துக்கொள்வது பெரும்பாலான opensource குழுக்களுக்கு சாத்தியமில்லை.

###### 5.6.3 தொழில்நுட்ப நோக்கில் செய்திச் சுருக்கங்கள்

**1. Transfer Learning**

- English மற்றும் high-resource மொழிகளில் பயிற்சி பெற்ற LLM-ஐ, குறைவான தமிழ் தரவுகளுடன் fine-tune செய்வது.
- multilingual transformers (e.g., mBERT, XLM-R) பயன்படுகின்றன.

**2. Backtranslation & Data Augmentation**

- உரையை தமிழில் மொழிபெயர்த்து, அதை மாற்றியமைத்த உரையாக சேகரித்து data volume அதிகரிக்கும்.
- GPT + T5 போன்ற பயிற்சி செயற்கைகள் பயன்படுத்தப்படும்.

**3. Tokenization மேலாண்மை**

- Byte-level tokenizers (e.g., SentencePiece, Byte-Pair Encoding) தமிழ் எழுத்துக்களுக்கு மேம்பட்ட coverage தருகின்றன.
- Custom tokenization: Tamil letters & grammar-based segmentation models.

**4. LoRA / Adapter Fine-Tuning**

- Resource constraint-உள்ள சூழலில் சிறிய LLM மாதிரிகள் (e.g., Alpaca, TinyLlama) – தமிழ் உரை தரவுகளில் Adapter layers வைத்து fine-tune செய்ய முடியும்.

###### 5.6.4 தமிழில் LLM உருவாக்கத் தகுந்த கட்டமைப்புகள்

| **கூறு**     | **விளக்கம்**                                         |
| ------------ | -------------------------------------------------- |
| Tokenizer    | IndicNLP, Byte-BPE                                 |
| Datasets     | Tamil Wikipedia, Common Crawl-Ta, OpenSubtitles-Ta |
| Architecture | DistilGPT-2, LLaMA, Falcon, Mistral                |
| Fine-tuning  | Instruction Tuning using Tamil dialogues           |
| Evaluation   | BLEU, ROUGE, perplexity for Tamil corpora          |

###### 5.6.5 எதிர்காலம்

தமிழில் LLM உருவாக்கம் என்பது வெறும் மொழிக்காக அல்ல, அது ஒரு **மாற்றுத்திறன் வாய்ந்த சமூக நியாயமாக** மாறியுள்ளது.

- மருத்துவ chatbot-கள் கிராமப்புற மக்களுக்காக தமிழில் பேசும்
- பள்ளி மாணவர்களுக்கு ஊக்கமளிக்கும் தமிழ் ஆசிரியர் avatars
- தமிழ்ப் பழமொழிகளை பயன்பாடுகளுக்குத் தந்திடும் இலக்கிய-நுண்ணறிவு LLM-கள்

எல்லாம் விரைவில் நம்மை நோக்கி வருகின்றன.

- LLM-கள் பல்துறை பயன்பாடுகளை உருவாக்குகின்றன – கல்வி முதல் மருத்துவம் வரை.
- தமிழ் மொழி உள்ளிட்ட low-resource setting-இல் உள்ள மொழிகள், தரவுக்குறைவால் பின்தங்கியுள்ளன.
- Opensource இயக்கங்கள், transfer learning, tokenization மற்றும் adapter tuning ஆகியவையின் மூலம் LLM-ஐக் கொண்டு வர முடிகிறது.
- இது வெறும் தொழில்நுட்ப நடவடிக்கையாக அல்ல; ஒரு மொழி நாகரிகத்தை தாங்கும் ஒரு புதுவழி.

##### 5.7 எதிர்காலப் பரிமாணங்கள் மற்றும் நாகரிகக் கேள்விகள் (Ethical and Societal Implications)

பெரிய மொழி மாதிரிகள் (LLMs) மனிதர்களின் மொழி, அறிவு, தர்க்கம், மற்றும் சமூக நடைமுறைகளை உருவாக்கி பயன்படுத்தும் ஒரு நுண்ணறிவு சீரமைப்பாக வளர்ந்துள்ளன. ஆனால், இவை ஒரு நன்மைதரும் தொழில்நுட்பமாக மட்டுமல்ல, **சமூகப் பொறுப்பு**, **ஊழியம்**, மற்றும் **மனித அடையாளங்களுக்குள் நுழையும் ஆபத்தான வழிகளையும்** கொண்டுள்ளன. இதனால்தான், LLM-களைப் பொறுப்புடன் உருவாக்கும் மற்றும் பயன்படுத்தும் பண்பாட்டியலில் நம்மை நாம் முன்வைக்க வேண்டும்.

###### 5.7.1 விஸ்தாரமான தாக்கங்கள்

LLM-கள் இன்று மக்கள் வாழ்க்கையின் அனைத்துத் துறைகளிலும் இடம்பிடிக்கின்றன: கல்வி, சட்டம், ஊடகம், அரசியல், மருத்துவம், வேலைவாய்ப்பு. ஆனால் இந்த இடம்பிடிப்பு **பழைய மனித-மனித இடைமுகங்களை இடிக்கக்கூடிய, அல்லது மீண்டும் பிணைக்கும்** இருவழி பாதையாக இருக்க முடியும்.

**தாக்கங்கள்:**

- கல்வித் துறையில் மனித ஆசிரியர்களின் பணிபலனை மாறும்.
- வேலைவாய்ப்பு நிலைகளில் பலவகை ஆட்கள், குறிப்பாக எழுத்தாளர், மொழிபெயர்ப்பாளர், data analyst போன்ற பணிகள் மாறும்.
- பொது அறிவுத் தளங்களில் misinformation மற்றும் hallucination அதிகரிக்கக்கூடியது.
- மொழி சமத்துவம் சீரழியக்கூடியது — குறைந்த ஆதாரமுள்ள மொழிகள் புறக்கணிக்கப்படலாம்.

###### 5.7.2 நாகரிகப் பொறுப்புகள்

LLM-கள் **மனிதர்களைப் போல பதிலளிக்கக்கூடியவை** என்பதால், அவை சுயமாகத் தவறான அல்லது கேலிகூத்தான தகவல்களையும் வழங்கக்கூடும். இதனால், அவை பின்வரும் நாகரிகக் கேள்விகளை எழுப்புகின்றன:

1. **பொறுப்புமிக்க பதில்:**

   - தவறான தகவலால் பாதிப்பு ஏற்படும்போது, பதிலுக்குப் பொறுப்பானவர் யார்?

     மென்பொருள் உருவாக்குநரா, பயனாளரா, அல்லது மாடலா?

2. **முன்னெச்சரிக்கை வடிவமைப்பு (Safety by Design):**

   - ஒரு LLM கற்றுக்கொள்ளும் தரவுகளில் இருந்து தீவிரவாதம், பாகுபாடு, அடக்குமுறை சார்ந்த சொற்பிரயோகங்களை எவ்வாறு தவிர்க்க முடியும்?

3. **பட்டயமற்ற சிகிச்சை (Unlicensed Advice):**

   - மருத்துவம், சட்டம் போன்ற துறைகளில், ஒரு LLM தவறாக வழங்கும் தீர்வு ஒரு மனிதரின் வாழ்வை மாற்றக்கூடியதாய் இருக்கலாம். இவ்வாறான நிலைகளில் LLM-ஐ முறையாக **சார்பு கூறுவதற்கான சட்டக்கட்டுப்பாடுகள்** தேவைப்படுகிறது.

###### 5.7.3 பாகுபாடும் (Bias), புறக்கணிப்பும் (Exclusion)

LLM-கள் கற்றுக்கொள்ளும் அனைத்து தரவுகளும் ஒரு சமூகத்தைக் பிரதிபலிக்கின்றன. ஆனால் அவை அதே சமயம்:

- குறிப்பிட்ட மொழிகள், சமூகங்கள், பாலினங்கள், அல்லது கலாசாரங்களை புறக்கணிக்கக்கூடும்.
- தோற்றம், மதம், இனம், பாலின அடையாளம் போன்ற பிரிவுகளில் **bias-ஐ அதிகரிக்கும் அபாயம்** உள்ளது.

**உதாரணம்:**

ஒரு LLM “CEO” என்ற சொல்லுக்கு 90% male context-இல் பதிலளிக்கலாம், ஏனெனில் கற்ற தரவுகளில் அதுவே அதிகம்.

###### 5.7.4 தனியுரிமை மற்றும் தரவு உரிமைகள்

- Open datasets இல் இருக்கும் தரவுகள் பெரும்பாலும் copyright அல்லது தனிப்பட்ட தகவல்களைக் கொண்டிருக்கக்கூடும்.
- ஒரு LLM, பயிற்சி தரவிலிருந்தே பழைய email, சொந்த பெயர்கள், தொடர்புகள் போன்றவற்றை நினைவில் வைத்திருக்கக்கூடும் — இது ஒரு **தனியுரிமை மீறல்** ஆகும்.
- தொழில்துறையின் தரவுகள் (confidential documents, chat logs) கூட கேட்கப்படும் query-க்கேற்ப ஒரு LLM-ஐ influence செய்யக்கூடியது.

இந்தநிலையில், தரவு உரிமைகள் மற்றும் GDPR போன்ற சட்டங்கள் LLM-களுக்கு **அளவிடப்பட்ட learning boundary**-ஐ கட்டுப்படுத்த வேண்டும்.

###### 5.7.5 Regulating LLMs — ஒரு நாகரிக வாதம்

உலகளாவிய அளவில், LLM-களுக்கு உரிய சட்டங்களை அமைக்கிறது என்பது **சுருக்கப்பட்ட நாகரிக ஆணையம்** உருவாக்குவது போல.

- European Union: **AI Act** மூலமாக LLM-களை regulate செய்ய முயற்சிக்கிறது.
- UNESCO மற்றும் OECD: AI-இல் **Ethics Guidelines** வெளியிட்டுள்ளன.
- India மற்றும் Tamil Nadu போன்ற மாநில அளவிலான governing body-கள், LLM-களின் பயிற்சி தரவுகள், பயன்பாட்டு எல்லைகள் குறித்த தங்களது கருத்துகளை உருவாக்க வேண்டிய அவசியம் உள்ளது.

###### 5.7.6 தமிழ் மொழியில் நாகரிக ஒழுங்குகள்

- தமிழில் LLM-கள் உருவாக்கும் போது, **இலக்கிய மரபுகளையும், நுண்ணிய கலாசாரப் பிம்பங்களையும்** சரியாகக் கையாள வேண்டியது மிக முக்கியம்.

- ‘பெரியார்’, ‘திருவள்ளுவர்’, ‘சங்க இலக்கியம்’ போன்ற வரலாற்று சம்பந்தப்பட்ட பிரச்னைகளில் தவறான பதில்கள் **பொது நலத்துக்கு ஆபத்தாக** இருக்கக்கூடும்.

- அதனால், தமிழ்நாடு அரசும், தமிழ் பல்கலைக்கழகங்களும் சேர்ந்து **மொழி, கலாசார செம்மை** என்பதை அடிப்படையாகக் கொண்டு LLM alignment-ஐ வடிவமைக்க வேண்டியது அவசியம்.


###### 5.7.7 முடிவுரை

பெரிய மொழி மாதிரிகள் (LLMs) ஒரு தொழில்நுட்ப புரட்சியைத் தூண்டியிருக்கலாம். ஆனால், அவை **மனித சமூகத்தின் தத்துவச் சூழலுக்குள்** நுழைந்துவிட்டன. இதனால்:

- இது ஒரு algorithmic achievement மட்டுமல்ல, ஒரு **நாகரிகப் பொறுப்பு**.
- இது ஒரு செயற்கை நுண்ணறிவு சாதனை மட்டுமல்ல, ஒரு **மனித பன்முகம் தரும் ஒப்புதல்**.
- இது மொழி உருவாக்கம் மட்டுமல்ல, **அருவணக்கத்தின் ஒரு தளமாக** மாறுகிறது.

எனவே, LLM-களைப் புரிந்து கொள்வது என்பது **மொழியையும், சமூகத்தையும், நீதியையும், எதிர்காலத்தையும்** ஒரே நேரத்தில் நோக்கிப் பார்க்கும் ஒரு முயற்சியாகும்.

<hr class="pagebreak">

# செயல் மூலம் பயிற்சி

### 6. இயல் மொழி தெளிதல் : எளிய சாட்பாட்(Chatbot) உருவாக்குதல்  

இந்த பயிற்சியில், Python-ஐப் பயன்படுத்தி ஒரு எளிய சாட்பாட்டை உருவாக்குவோம். இந்த சாட்பாட் பயனரின் உரையைப் புரிந்து கொண்டு, பொருத்தமான பதில்களை வழங்கும். இது **Rule-Based Chatbot** என்று அழைக்கப்படுகிறது, ஏனெனில் இது முன்-வரையறுக்கப்பட்ட விதிகளைப் பயன்படுத்தி பதில்களை வழங்குகிறது.  

---

###### 6.1. சாட்பாட் என்றால் என்ன?  

சாட்பாட் என்பது ஒரு மென்பொருள் பயன்பாடு ஆகும், இது மனிதர்களுடன் உரையாடுவதற்காக வடிவமைக்கப்பட்டுள்ளது. இது பயனரின் உரையைப் புரிந்து கொண்டு, பொருத்தமான பதில்களை வழங்குகிறது. சாட்பாட்கள் பொதுவாக **Rule-Based** அல்லது **AI-Based** (Machine Learning/Deep Learning) ஆக இருக்கலாம்.  

**Rule-Based சாட்பாட்கள்** என்பவை முன்னரே வரையறுக்கப்பட்ட விதிகள் மற்றும் வடிவங்களின் அடிப்படையில் செயல்படுகின்றன. இவை எளிய மற்றும் குறிப்பிட்ட பணிகளுக்கு ஏற்றவையாக உள்ளன, ஆனால் சிக்கலான அல்லது மாறுபட்ட உரையாடல்களில் திறன்பெறுவது கடினம்.  

**AI-Based சாட்பாட்கள்** என்பவை இயல் மொழி தெளிதல் (NLP - Natural Language Processing), இயந்திரக் கற்றல் (Machine Learning), மற்றும் ஆழ்ந்த கற்றல் (Deep Learning) போன்ற முறைகளைப் பயன்படுத்தி உரையைப் புரிந்து கொண்டு, மனிதர்களைப் போன்று பதிலளிக்கும் திறனைக் கொண்டுள்ளன. இவை மிகவும் மேம்பட்டவை மற்றும் சிக்கலான உரையாடல்களைக் கையாளும் திறன் கொண்டவை.  

சாட்பாட்கள் பல்வேறு துறைகளில் பயன்படுத்தப்படுகின்றன, உதாரணமாக, வாடிக்கையாளர் சேவை, உதவி மையங்கள், மருத்துவ ஆலோசனை, கல்வி, மற்றும் தனிப்பயனாக்கப்பட்ட பரிந்துரைகள் போன்றவை. இவை மனிதர்களின் பணியை எளிதாக்கவும், நேரத்தை மிச்சப்படுத்தவும், மற்றும் பயனர் அனுபவத்தை மேம்படுத்தவும் உதவுகின்றன.  

மேலும், சாட்பாட்கள் தொடர்ந்து மேம்படுத்தப்பட்டு வருகின்றன, மேலும் அவை மனிதர்களுடன் மிகவும் இயல்பான மற்றும் புரிந்துணரும் வகையில் உரையாடும் திறனைப் பெறுவதற்காக தொடர்ந்து மேம்படுத்தப்படுகின்றன.

**இந்த பயிற்சியில், நாம் Rule-Based Chatbot-ஐ உருவாக்குவோம்.**  

###### 6.2. தேவையான நூலகங்களை நிறுவுதல்  

நாம் `nltk` (Natural Language Toolkit) நூலகத்தைப் பயன்படுத்துவோம். இது NLP பணிகளுக்கு பயனுள்ளதாக இருக்கும்.  

```bash
pip install nltk
```

**Import Libraries**  

```python
import nltk
from nltk.chat.util import Chat, reflections
```

###### 6.3. விதிகளை வரையறுத்தல்  

Rule-Based Chatbot-இல், நாம் பயனரின் உரையைப் பொறுத்து பதில்களை வழங்கும் விதிகளை வரையறுக்க வேண்டும். இந்த விதிகள் **Regular Expressions (Regex)** மூலம் உரையைப் பொருத்தி, பொருத்தமான பதில்களைத் தேர்ந்தெடுக்கும்.  

```python
pairs = [
    [
        r"hi|hello|hey",
        ["Hello! How can I help you?", "Hi there! What can I do for you?"]
    ],
    [
        r"how are you",
        ["I'm good, thank you! How about you?", "I'm doing well. How can I assist you?"]
    ],
    [
        r"what is your name",
        ["I'm a simple chatbot. You can call me ChatBot!", "I don't have a name, but you can call me ChatBot."]
    ],
    [
        r"bye|goodbye",
        ["Goodbye! Have a great day!", "Bye! Take care!"]
    ],
    [
        r"thank you|thanks",
        ["You're welcome!", "No problem!"]
    ],
    [
        r"(.*) your name (.*)",
        ["I'm just a chatbot. I don't have a name!", "You can call me ChatBot."]
    ],
    [
        r"(.*) help (.*)",
        ["Sure, I can help you. What do you need?", "How can I assist you?"]
    ],
    [
        r"(.*) (age|old) (.*)",
        ["I'm just a program, so I don't have an age!", "I'm ageless!"]
    ],
    [
        r"i am good|i'm good",
        ["That's great to hear!", "Good to know you're doing well!"]
    ],
    [
        r"(.*)",  # Fallback rule
        ["I'm not sure how to respond to that.", "Can you please rephrase?"]
    ]
]

```

---

###### 6.4. சாட்பாட்டை உருவாக்குதல்  

இப்போது, நாம் வரையறுத்த விதிகளைப் பயன்படுத்தி சாட்பாட்டை உருவாக்கலாம்.  

```python
# சாட்பாட்டை உருவாக்குதல்
chatbot = Chat(pairs, reflections)

# சாட்பாட்டை இயக்குதல்
def start_chat():
    print("Hello! I'm a simple chatbot. Type 'quit' to exit.")
    while True:
        user_input = input("You: ")  # பயனரின் உரை
        if user_input.lower() == "quit":
            print("ChatBot: Goodbye!")
            break
        response = chatbot.respond(user_input)  # சாட்பாட்டின் பதில்
        print("ChatBot:", response)


```

**சாட்பாட்டை இயக்குதல்**  

```python
# சாட்பாட்டைத் தொடங்குதல்
start_chat()
```

இந்த குறியீட்டை இயக்கினால், சாட்பாட் பயனருடன் உரையாடத் தொடங்கும்.  

**உரையாடல் எடுத்துக்காட்டு:**  

```
You: Hi  
ChatBot: Hello! How can I help you?  

You: What is your name?  
ChatBot: I'm a simple chatbot. You can call me ChatBot!  

You: How are you?  
ChatBot: I'm good, thank you! How about you?  

You: Bye  
ChatBot: Goodbye! Have a great day!  
```

இந்த சாட்பாட் **Rule-Based** ஆக இருப்பதால், இதற்கு சில வரம்புகள் உள்ளன.

இந்த சாட்பாட் முன்-வரையறுக்கப்பட்ட விதிகளை மட்டுமே புரிந்து கொள்ளும். புதிய உரைகளைப் புரிந்து கொள்ள இயலாது.  இது உரையின் சூழலைப் புரிந்து கொள்ளாது. எடுத்துக்காட்டாக, "How old are you?" மற்றும் "What is your age?" இரண்டும் ஒரே கேள்வியாக இருந்தாலும், இது இரண்டிற்கும் தனித்தனியாக விதிகளை வரையறுக்க வேண்டும்.  

இந்த சாட்பாட் உணர்ச்சிகளைப் புரிந்து கொள்ளாது. எடுத்துக்காட்டாக, "I'm feeling sad" என்ற உரைக்கு பொருத்தமான பதிலை வழங்க இயலாது.  சாட்பாட்க்கு  புதிய தரவுகளைக் கற்றுக்கொள்ளும் திறன் இல்லை. இது முன்-வரையறுக்கப்பட்ட விதிகளை மட்டுமே பின்பற்றும்.   

<hr class="pagebreak">

### 7. தமிழ் GPT: சங்கத்தமிழ் பாடல்களை உருவாக்கும் ஒரு AI கவிஞர்

 நாம் இன்று டீப் லேர்னிங் (Deep Learning) தொழில்நுட்பத்தைப் பயன்படுத்தி ஒரு AI கவிஞரை எப்படி உருவாக்கலாம் என்று விரிவாகக் காண்போம். இந்த AI கவிஞர், சங்கத்தமிழ் பாணியில் புதிய பாடல்களை இயற்றக்கூடிய திறன் கொண்டவர்! பைத்தான் (Python) மொழியில் உருவாக்கப்பட்ட இந்த டீப் லேர்னிங் மாடல், சங்கத்தமிழ் இலக்கியத்திலிருந்து கற்றுக்கொண்டு புதிய பாடல்களை உருவாக்கும்.

தேவையானவை PyTorch இது டீப் லேர்னிங் மாடல்களை உருவாக்க உதவும் ஒரு பைத்தான் நூலகம் (library). சங்கத்தமிழ் தரவு - Project Madurai போன்ற இணையதளங்களில் இருந்து சங்கத்தமிழ் பாடல்களைப் பதிவிறக்கம் செய்து கொள்ளலாம். இதனை `input.txt` என்ற கோப்பில் சேமித்து வைக்கவும்.

கம்ப்யூட்டரால் நேரடியாக டெக்ஸ்ட்டைப் புரிந்து கொள்ள முடியாது. டெக்ஸ்ட்டை எண்களாக மாற்றும் "encoding" செயல்முறை அவசியம். சங்கத்தமிழ் பாடல்களை கம்ப்யூட்டருக்குப் புரியும் வகையில் மாற்ற, முதலில் பாடல்களில் உள்ள தனித்துவமான எழுத்துக்களை அடையாளம் கண்டு சொல்லகராதி உருவாக்க வேண்டும். இந்த சொல்லகராதி, ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண்ணை ஒதுக்கும். பின்னர், இந்த எண்களைப் பயன்படுத்தி பாடல்களை கம்ப்யூட்டர் புரிந்துகொள்ளும் வகையில் மாற்றலாம். உதாரணமாக, "ம" என்ற எழுத்துக்கு 57, "லை" என்ற எழுத்துக்கு 61, 73 எண்களை ஒதுக்கலாம். இதன் மூலம், **"மலை" என்ற வார்த்தையை 57, 61, 73**  என்ற எண்களாக மாற்றலாம். இந்த எண்களை கம்ப்யூட்டர் பல்வேறு வழிகளில் பயன்படுத்தலாம்.  உதாரணமாக, மொழிபெயர்ப்பு, உரை பகுப்பாய்வு,  உணர்வு பகுப்பாய்வு போன்ற பணிகளுக்கு இந்த  எண்கள் பயன்படும்.

ஏன் தனித்துவமான எழுத்துக்கள்?

கம்ப்யூட்டருக்குத் தமிழ் எழுத்துக்களைப் பற்றி எதுவும் தெரியாது. நாம் ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண்ணைக் கொடுக்க வேண்டும். நமது மாடல் பயன்படுத்தும் மொத்த எழுத்துக்களின் தொகுப்பு தான் சொல்லகராதி. இந்த சொல்லகராதியில் உள்ள ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண் குறியீடு இருக்கும்.

எப்படி தனித்துவமான எழுத்துக்களைக் கண்டுபிடிப்பது?

1. **பாடல்களைப் படித்தல்:** `input.txt` கோப்பில் உள்ள சங்கத்தமிழ் பாடல்களைப் படிக்கவும்.
2. **எழுத்துக்களைச் சேகரித்தல்:** பாடல்களில் உள்ள ஒவ்வொரு எழுத்தையும் ஒரு "set"-ல் சேர்க்கவும். "set"-ல் ஒரே எழுத்து பலமுறை வந்தாலும், ஒரே முறை தான் சேமிக்கப்படும்.
3. **வரிசைப்படுத்துதல்:** "set"-ல் உள்ள எழுத்துக்களை அகர வரிசையில் வரிசைப்படுத்தவும்.

**உதாரணம்:**

`input.txt` கோப்பில் "அகர முதல" என்று இருந்தால்,

- படிக்கப்பட்ட எழுத்துக்கள்: அ, க, ர, மு, த, ல
- "set"-ல் சேர்க்கப்பட்ட எழுத்துக்கள்: {அ, க, ர, மு, த, ல}
- வரிசைப்படுத்தப்பட்ட எழுத்துக்கள்: [அ, க, ங, ச, ட, த, ந, ப, ம, ய, ர, ல, வ, ழ, ள, ற, ன] (இது ஒரு உதாரணம் மட்டுமே, உங்கள் கோப்பில் உள்ள எழுத்துக்கள் வேறுபடலாம்)

```python
chars = sorted(list(set(text)))
vocab_size = len(chars)
```

- `text`: `input.txt` கோப்பில் உள்ள பாடல்களின் டெக்ஸ்ட்.
- `set(text)`: டெக்ஸ்டில் உள்ள தனித்துவமான எழுத்துக்களைக் கொண்ட ஒரு "set"-ஐ உருவாக்குகிறது.
- `list(set(text))`: "set"-ஐ ஒரு "list"-ஆக மாற்றுகிறது.
- `sorted(list(set(text)))`: "list"-ஐ அகர வரிசையில் வரிசைப்படுத்துகிறது.
- `chars`: வரிசைப்படுத்தப்பட்ட தனித்துவமான எழுத்துக்களின் "list".
- `vocab_size`: தனித்துவமான எழுத்துக்களின் எண்ணிக்கை (சொல்லகராதியின் அளவு).

இந்த தனித்துவமான எழுத்துக்களைக் கண்டுபிடிக்கும் செயல்முறை, நமது மொழி மாதிரியின் முதல் படியாகும். இந்த எழுத்துக்கள் தான் மாடல் புரிந்து கொள்ளும் அடிப்படை கூறுகள். ஒவ்வொரு எழுத்துக்கும் ஒரு தனித்துவமான எண்ணை (integer) கொடுக்க வேண்டும். இதை ஒரு அகராதியாக (dictionary) சேமித்து வைப்போம். 

```python
stoi = {' ': 2,'அ': 31,'க': 43,'ர': 59,'மு': 57,'த': 69,'ல': 52,'எ': 61,'ழு': 37,'த்': 63, 'ெ': 77,'ல்': 71, 'ா': 66}
```

இந்த அகராதியைப் பயன்படுத்தி, "அகர முதல" என்ற டெக்ஸ்ட்டை எண்களாக மாற்றும்போது, நமக்கு `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியல் கிடைக்கும். முதல் எழுத்து "அ". `stoi` அகராதியில், "அ" என்ற எழுத்துக்கு 31 என்ற எண் ஒதுக்கப்பட்டுள்ளது. எனவே, முதல் எண் 31. இரண்டாவது எழுத்து "க". `stoi` அகராதியில், "க" என்ற எழுத்துக்கு 43 என்ற எண் ஒதுக்கப்பட்டுள்ளது. எனவே, இரண்டாவது எண் 43. இதேபோல், மற்ற எழுத்துக்களுக்கும் `stoi` அகராதியில் உள்ள எண்களை எடுத்துக்கொள்வோம். இறுதியில், "அகர முதல" என்ற டெக்ஸ்ட் `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியலாக மாறும்.

**குறிப்பு:**
உங்கள் `stoi` அகராதியில் உள்ள எண்கள், நீங்கள் பயன்படுத்தும் டேட்டா மற்றும் encoding முறையைப் பொறுத்து மாறுபடலாம்.

**Decoding**

"Decoding" என்பது "encoding"-க்கு எதிர்மாறான செயல்முறை. அதாவது, எண்களின் பட்டியலை எடுத்துக்கொண்டு, அதை டெக்ஸ்ட்டாக மாற்றுவது. "Encoding"-ல் பயன்படுத்திய அகராதியைத் தலைகீழாக மாற்ற வேண்டும். அதாவது, எண்கள் "key"-ஆகவும், எழுத்துக்களை "value"-ஆகவும் கொண்ட ஒரு அகராதி:

```python
itos = {2: ' ', 31: 'அ', 43: 'க', 59: 'ர', 57: 'மு', 69: 'த', 52: 'ல', 61: 'எ', 37: 'ழு', 63: 'த்', 77: 'ெ', 71: 'ல்', 66: 'ா'}
```

**எழுத்துக்களாக மாற்றுதல் (Conversion to Characters)**

இப்போது, நமக்குக் கொடுக்கப்பட்ட எண்களின் பட்டியலை எடுத்துக்கொள்வோம். பட்டியலில் உள்ள ஒவ்வொரு எண்ணையும் எடுத்துக்கொண்டு, அகராதியில் அதற்குரிய எழுத்தைப் பார்ப்போம். இந்த எழுத்துக்களை ஒன்றாக இணைத்தால், நமக்கு டெக்ஸ்ட் கிடைக்கும்.

**உதாரணம்:**

`[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியலை எடுத்துக்கொள்வோம்.

- முதல் எண் 31. அகராதியில் 31 என்ற எண்ணுக்கு "அ" என்ற எழுத்து ஒதுக்கப்பட்டுள்ளது.
- இரண்டாவது எண் 43. அகராதியில் 43 என்ற எண்ணுக்கு "க" என்ற எழுத்து ஒதுக்கப்பட்டிருக்கலாம்.
- இதேபோல், மற்ற எண்களுக்கும் அகராதியில் உள்ள எழுத்துக்களை எடுத்துக்கொள்வோம்.

இறுதியில், `[31, 43, 59, 2, 57, 69, 52, 61]` என்ற எண்களின் பட்டியல் "அகர முதல" என்ற டெக்ஸ்ட்டாக மாறும்.

சுருக்கமாக

- Encoding: டெக்ஸ்ட்டை எண்களாக மாற்றுதல்.
- Decoding: எண்களை டெக்ஸ்ட்டாக மாற்றுதல்.

இந்த இரண்டு செயல்முறைகளும், டெக்ஸ்ட் டேட்டாவை கம்ப்யூட்டர் புரிந்து கொள்ளும் வகையில் மாற்ற உதவுகின்றன. இதன் மூலம், டெக்ஸ்ட் டேட்டாவைப் பயன்படுத்தி டீப் லேர்னிங் மாடல்களை உருவாக்க முடியும்.

இப்பொழுது நாம் கற்றவற்றை பைதானில் செய்து பார்ப்போம் 

###### 7.1. Libraries & Hyperparameters

```python
import torch
import torch.nn as nn
from torch.nn import functional as F

# Hyperparameters
batch_size = 16     # எத்தனை பாடல்களை ஒரே நேரத்தில் process செய்ய வேண்டும்
block_size = 32    # எத்தனை எழுத்துக்களை மாதிரி கணக்கில் எடுத்துக்கொள்ள வேண்டும்
max_iters = 5000   # எத்தனை முறை train செய்ய வேண்டும்
eval_interval = 100  # எத்தனை iterations-க்கு ஒரு முறை loss-ஐ calculate செய்ய வேண்டும்
learning_rate = 1e-3 # மாதிரி கற்கும் வேகம்
device = 'cuda' if torch.cuda.is_available() else 'cpu' # GPU இருந்தால் அதை பயன்படுத்தும்
eval_iters = 200
n_embd = 64
n_head = 4
n_layer = 4
dropout = 0.0

torch.manual_seed(1337)
```

**விளக்கம்:**

- **Libraries:**
  - `import torch`: PyTorch-ன் core functionalities-ஐ import செய்கிறது. Tensor operations, dynamic computation graphs போன்ற வசதிகளை பயன்படுத்துவதற்கு இது அவசியம்.
  - `import torch.nn as nn`: Neural network modules-ஐ உருவாக்க உதவுகிறது.  இங்குதான் நாம் நமது மாடலின் layers-களை define செய்வோம்.
  - `from torch.nn import functional as F`: Activation functions (எ.கா: ReLU, softmax), loss functions (எ.கா: cross_entropy) போன்ற  utils-களை import செய்கிறது.
- **Hyperparameters:** இவை நமது டீப் லேர்னிங் மாடலின் training process-ஐ control செய்யும் மாறிகள் (variables).  இவற்றின் சரியான தேர்வு, மாடல் எவ்வளவு நன்றாக கற்றுக்கொள்கிறது என்பதைப் பொறுத்தது.
  - `batch_size = 16`:  ஒரு முறை training செய்யும் போது எத்தனை பாடல்களை (sequences)  மாடலுக்குக் கொடுக்க வேண்டும் என்பது.  பெரிய `batch_size` வேகமாக training செய்ய உதவும், ஆனால் அதிக memory தேவைப்படும்.
  - `block_size = 32`:  ஒரு பாடலில் (sequence) எத்தனை எழுத்துக்களை ஒரு நேரத்தில் process செய்ய வேண்டும் என்பது.  இது context window size போன்றது.  அதாவது, மாடல் ஒரு எழுத்தைக் கணிக்க, முந்தைய `block_size` எழுத்துக்களைப் பார்க்கும்.
  - `max_iters = 5000`:  மொத்த training iterations எண்ணிக்கை.  அதிக iterations-ல் மாடல் நன்றாக கற்றுக்கொள்ள வாய்ப்புள்ளது, ஆனால் overfitting ஆகவும் வாய்ப்புள்ளது.
  - `eval_interval = 100`:  Training progress-ஐ monitor செய்ய, எத்தனை iterations-க்கு ஒரு முறை validation loss-ஐ கணக்கிட வேண்டும் என்பது.
  - `learning_rate = 1e-3`:  மாடல் weights-ஐ எவ்வளவு வேகமாக adjust செய்ய வேண்டும் என்பது.  சிறிய `learning_rate` மெதுவாக கற்கும், ஆனால் stable-ஆக கற்கும்.  பெரிய `learning_rate` வேகமாக கற்கும், ஆனால் unstable-ஆக இருக்கலாம்.
  - `device = 'cuda' if torch.cuda.is_available() else 'cpu'`:  GPU இருந்தால் training-ஐ GPU-வில் செய்யும்.  GPU இருந்தால் training வேகமாக நடக்கும்.  GPU இல்லை என்றால் CPU-வில் நடக்கும்.
  - `eval_iters = 200`: Evaluation-க்காக எத்தனை iterations செய்ய வேண்டும் என்பது.
  - `n_embd = 64`:  Embedding dimension.  ஒவ்வொரு எழுத்தையும் ஒரு vector-ஆக மாற்றும்போது, அந்த vector-ன் அளவு.
  - `n_head = 4`:  Transformer-ல் எத்தனை attention heads இருக்க வேண்டும் என்பது.
  - `n_layer = 4`:  Transformer-ல் எத்தனை layers இருக்க வேண்டும் என்பது.
  - `dropout = 0.0`:  Dropout rate.  Overfitting-ஐ குறைக்க உதவுகிறது.
- `torch.manual_seed(1337)`:  Random seed-ஐ set செய்கிறோம்.  இதனால், ஒவ்வொரு முறை program-ஐ run செய்தாலும், ஒரே மாதிரியான output கிடைக்கும்.  இது debugging மற்றும் experiments-ஐ reproduce செய்ய உதவுகிறது.

இந்த hyperparameters-ஐ மாற்றி, model-ன் performance-ஐ மேம்படுத்தலாம்.  இவை machine learning-ல் முக்கியமான tuning parameters.  இப்பொழுது, ஏன் இந்த values-களை தேர்ந்தெடுத்தோம் என்பது உங்களுக்கு புரிந்திருக்கும் என்று நினைக்கிறேன். அடுத்த பாகத்தில், data loading மற்றும் preprocessing பற்றி விரிவாகக் காண்போம்.

###### 7.2. Data Loading & Preprocessing

```python
# டேட்டாவை படித்தல்
with open('input.txt', 'r', encoding='utf-8') as f:
    text = f.read()

# தனித்துவமான எழுத்துக்களை கண்டுபிடித்தல்
chars = sorted(list(set(text)))
vocab_size = len(chars)

# எழுத்துக்களை எண்களாக மாற்றுதல் (Encoding)
stoi = { ch:i for i,ch in enumerate(chars) }
itos = { i:ch for i,ch in enumerate(chars) }
encode = lambda s: [stoi[c] for c in s] 
decode = lambda l: ''.join([itos[i] for i in l]) 

# டேட்டாவை train மற்றும் validation என பிரித்தல்
data = torch.tensor(encode(text), dtype=torch.long)
n = int(0.9*len(data)) 
train_data = data[:n]
val_data = data[n:]
```

**விளக்கம்:**

1. **டேட்டாவைப் படித்தல் (`input.txt` கோப்பிலிருந்து):**

   Python

   ```python
   with open('input.txt', 'r', encoding='utf-8') as f:
       text = f.read()
   ```

   - `with open(...)`:  `input.txt` கோப்பை படிக்க திறக்கிறது. `encoding='utf-8'` என்பது தமிழ் எழுத்துக்களைச் சரியாகப் படிக்க உதவுகிறது.  UTF-8 encoding பெரும்பாலான தமிழ் எழுத்துக்களை உள்ளடக்கியது.
   - `f.read()`: கோப்பிலுள்ள அனைத்து உள்ளடக்கத்தையும் ஒரு string-ஆக `text` மாறியில் சேமிக்கிறது.

2. **தனித்துவமான எழுத்துக்களைக் கண்டுபிடித்தல்:**

   Python

   ```python
   chars = sorted(list(set(text)))
   vocab_size = len(chars)
   ```

   - `set(text)`: `text` string-ல் உள்ள **தனித்துவமான** எழுத்துக்களைக் கொண்ட ஒரு set-ஐ உருவாக்குகிறது.  ஒரு set-ல், எந்த ஒரு உறுப்பும் இரண்டு முறை வராது.  இதனால், எல்லா தனித்துவமான எழுத்துக்களும் கிடைக்கும்.
   - `list(set(text))`: set-ஐ ஒரு list-ஆக மாற்றுகிறது.  set-ல் உள்ள உறுப்புகளுக்கு ஒரு குறிப்பிட்ட வரிசை இல்லை.  list-ஆக மாற்றும்போது, உறுப்புகளுக்கு ஒரு வரிசை கிடைக்கிறது.
   - `sorted(...)`: list-ஐ அகர வரிசையில் வரிசைப்படுத்துகிறது.  வரிசைப்படுத்துவதால், எழுத்துக்களுக்கு ஒரு நிலையான குறியீடு (index) கொடுக்க முடியும்.
   - `chars`: வரிசைப்படுத்தப்பட்ட தனித்துவமான எழுத்துக்களின் list.
   - `vocab_size`: தனித்துவமான எழுத்துக்களின் எண்ணிக்கை (நமது சொல்லகராதியின் அளவு).

3. **எழுத்துக்களை எண்களாக மாற்றுதல் (Encoding):**

   Python

   ```python
   stoi = { ch:i for i,ch in enumerate(chars) }
   itos = { i:ch for i,ch in enumerate(chars) }
   encode = lambda s: [stoi[c] for c in s] 
   decode = lambda l: ''.join([itos[i] for i in l]) 
   ```

   - `stoi`:  **s**tring **t**o **i**nteger என்ற dictionary.  ஒவ்வொரு எழுத்துக்கும் ஒரு unique integer mapping-ஐ உருவாக்குகிறது.  இந்த mapping-ஐப் பயன்படுத்தி,  டெக்ஸ்டை எண்களாக மாற்றலாம்.
   - `itos`:  **i**nteger **t**o **s**tring என்ற dictionary.  `stoi`-க்கு நேர் எதிரானது.  எண்களை எழுத்துக்களாக மாற்ற உதவுகிறது.
   - `encode(s)`:  ஒரு string `s`-ஐ எடுத்து, `stoi` dictionary-ஐப் பயன்படுத்தி, அதில் உள்ள ஒவ்வொரு எழுத்தையும் அதற்குரிய எண்ணாக மாற்றி, ஒரு list-ஐ  (எண்களின் list)  திரும்ப  அளிக்கிறது.
   - `decode(l)`:  ஒரு list `l` (எண்களின் list) -ஐ எடுத்து, `itos` dictionary-ஐப் பயன்படுத்தி, அதில் உள்ள ஒவ்வொரு எண்ணையும் அதற்குரிய எழுத்தாக மாற்றி,  string-ஐ  திரும்ப  அளிக்கிறது.

4. **டேட்டாவை train மற்றும் validation என பிரித்தல்:**

   Python

   ```python
   data = torch.tensor(encode(text), dtype=torch.long)
   n = int(0.9*len(data)) 
   train_data = data[:n]
   val_data = data[n:]
   ```

   - `encode(text)`:  முழு `text`-ஐ `encode` function-ஐப் பயன்படுத்தி எண்களாக மாற்றுகிறது.
   - `torch.tensor(...)`:  `encode(text)`-ன் வெளியீட்டை  PyTorch tensor-ஆக மாற்றுகிறது.  `dtype=torch.long` என்பது  integers-ஐக் குறிக்கிறது.  Tensorகள் தான் PyTorch-ல்  data-வை  manipulate  செய்ய  பயன்படுத்தப்படும்  datastructure.
   - `n = int(0.9*len(data))`:  மொத்த data-வில் 90%  train data-க்காகவும், 10%  validation data-க்காகவும்  பிரிக்கும்  வகையில்  `n`  மதிப்பை  கணக்கிடுகிறது.
   - `train_data`:  முதல் `n`  எழுத்துக்கள்  train data-வாக  சேமிக்கப்படுகிறது.
   - `val_data`:  மீதமுள்ள  எழுத்துக்கள்  validation data-வாக  சேமிக்கப்படுகிறது.  Validation data, model-ன்  performance-ஐ  train  செய்யும்  போதே  பார்க்க  உதவும்.

இந்த  நான்கு  படிகளின்  மூலம்,  சங்கத்  தமிழ்  பாடல்களைக்  கொண்ட  தரவை  டீப்  லேர்னிங்  மாடலுக்குத்  தேவையான  வடிவத்தில்  மாற்றுகிறோம்.  இனி,  மாடலை  உருவாக்குதல்  மற்றும்  train  செய்தல்  பற்றி  பார்ப்போம்.

###### 7.3. Batching

 நாம் தயாரித்த தரவை டீப் லேர்னிங் மாடலுக்குப் பயிற்சியளிக்க ஏற்ற batches ஆக எப்படிப் பிரிக்கலாம் என்று விரிவாகக் காண்போம்.

```python
# டேட்டாவை batches ஆக பிரித்தல்
def get_batch(split):
    data = train_data if split == 'train' else val_data
    ix = torch.randint(len(data) - block_size, (batch_size,))
    x = torch.stack([data[i:i+block_size] for i in ix])
    y = torch.stack([data[i+1:i+block_size+1] for i in ix])
    x, y = x.to(device), y.to(device)
    return x, y
```

**விளக்கம்:**

`get_batch(split)` என்ற function, `train` அல்லது `validation` data-வில் இருந்து ஒரு batch டேட்டாவை எடுத்துத் தருகிறது.  ஒவ்வொரு batch-லும் `batch_size` எண்ணிக்கையிலான பாடல்கள் இருக்கும்.

1. **டேட்டா தேர்வு:**

   Python

   ```python
   data = train_data if split == 'train' else val_data
   ```

   `split`  என்ற  மாறியின்  மதிப்பை  பொறுத்து,  `train_data`  அல்லது  `val_data`  தேர்ந்தெடுக்கப்படுகிறது.  `split`  'train'  ஆக  இருந்தால்  `train_data`வும்,  இல்லையென்றால்  `val_data`வும்  பயன்படுத்தப்படும்.

2. **சீரற்ற  indices  உருவாக்குதல்:**

   Python

   ```python
   ix = torch.randint(len(data) - block_size, (batch_size,))
   ```

   `torch.randint`  function-ஐப்  பயன்படுத்தி,  0  முதல்  `len(data) - block_size`  வரை  இடைப்பட்ட  மதிப்புகளில்  `batch_size`  எண்ணிக்கையிலான  சீரற்ற  எண்கள்  உருவாக்கப்படுகின்றன.  இந்த  எண்கள்,  data-வில்  batch-ன்  தொடக்க  நிலையைக்  குறிக்கும்.

3. **Input (x)  மற்றும்  Target (y)  உருவாக்குதல்:**

   Python

   ```python
   x = torch.stack([data[i:i+block_size] for i in ix])
   y = torch.stack([data[i+1:i+block_size+1] for i in ix])
   ```

   - `data[i:i+block_size]`:  `data`-வில்  `i`  முதல்  `i+block_size`  வரையிலான  உள்ளடக்கத்தை  (ஒரு  பாடலின்  ஒரு  பகுதி)  எடுக்கிறது.  `ix`-ல்  உள்ள  ஒவ்வொரு  `i`-க்கும்  இப்படியான  ஒரு  பகுதி  எடுக்கப்பட்டு,  `x`  என்ற  list-ல்  சேர்க்கப்படும்.  `x`  என்பது  input  sequence.
   - `data[i+1:i+block_size+1]`:  `data`-வில்  `i+1`  முதல்  `i+block_size+1`  வரையிலான  உள்ளடக்கத்தை  (அடுத்த  எழுத்துக்களைக்  கொண்ட  பகுதி)  எடுக்கிறது.  இது  target sequence  ஆகும்.  `y`  என்பது  x-க்கான  அடுத்த  எழுத்துக்களைக்  கொண்டது.
   - `torch.stack(...)`:  `x`  மற்றும்  `y`-ல்  உள்ள  tensorகளை  ஒன்றாக  stack  செய்து  ஒரு  batch  tensor-ஆக  உருவாக்குகிறது.

4. **Device-க்கு  மாற்றுதல் (GPU  அல்லது  CPU):**

   Python

   ```python
   x, y = x.to(device), y.to(device)
   ```

   `x`  மற்றும்  `y`  tensorகளை  device-க்கு  (GPU  அல்லது  CPU)  நகர்த்துகிறது.  GPU  இருந்தால்  GPU-விலும்,  இல்லையென்றால்  CPU-விலும்  training  நடக்கும்.  GPU-வில்  training  வேகமாக  இருக்கும்.

5. **Batch-ஐ  திரும்ப  அளித்தல்:**

   Python

   ```python
   return x, y
   ```

   உருவாக்கப்பட்ட  batch  tensorகள்  `x`  (input)  மற்றும்  `y`  (target)  திரும்ப  அளிக்கப்படுகின்றன.

இந்த  function-ஐப்   பயன்படுத்தி,  training  loop-ல்  batch-களை  உருவாக்கி,  மாடலுக்குப்  பயிற்சி  அளிக்கலாம்.  அடுத்த  பகுதியில்,  மாடல்  உருவாக்கம்  பற்றி  விரிவாகப்  பார்ப்போம்.

###### 7.4. Loss Estimation

Loss என்பது, மாடலின் predictions எவ்வளவு தவறாக இருக்கிறது என்பதன் அளவீடு. Loss குறைவாக இருந்தால், மாடல் நன்றாகக் கற்றுக்கொள்கிறது என்று அர்த்தம்.

```python
# Loss-ஐ கணக்கிடுதல்
@torch.no_grad()
def estimate_loss():
    out = {}
    model.eval()
    for split in ['train', 'val']:
        losses = torch.zeros(eval_iters)
        for k in range(eval_iters):
            X, Y = get_batch(split)
            logits, loss = model(X, Y)
            losses[k] = loss.item()
        out[split] = losses.mean()
    model.train()
    return out
```

**விளக்கம்:**

`estimate_loss()` என்ற function, train மற்றும் validation data-வில் மாடலின் performance-ஐ அளவிட loss-ஐ கணக்கிடுகிறது.

1. **`@torch.no_grad()`:**

   இந்த decorator, gradient calculations-ஐ disable செய்கிறது.  Evaluation-ன் போது gradients தேவையில்லை.  gradients கணக்கிடாமல் இருந்தால், computation speed அதிகரிக்கும்.

2. **`model.eval()`:**

   மாடலை evaluation mode-க்கு மாற்றுகிறது.  சில layers (Dropout, BatchNorm) training மற்றும் evaluation mode-களில் வெவ்வேறாக செயல்படும்.

3. **Loss சேமிக்க dictionary:**

   Python

   ```python
   out = {}
   ```

   `train` மற்றும் `validation` data-வின் loss-களை சேமிக்க ஒரு dictionary உருவாக்கப்படுகிறது.

4. **Train மற்றும் Validation data-வில் loss கணக்கிடுதல்:**

   Python

   ```python
   for split in ['train', 'val']:
       losses = torch.zeros(eval_iters)
       for k in range(eval_iters):
           X, Y = get_batch(split)
           logits, loss = model(X, Y)
           losses[k] = loss.item()
       out[split] = losses.mean()
   ```

   - `for split in ['train', 'val']`: train மற்றும் validation data இரண்டிலும் loss கணக்கிடப்படுகிறது.
   - `losses = torch.zeros(eval_iters)`: ஒவ்வொரு iteration-க்கான loss-ஐ சேமிக்க ஒரு tensor உருவாக்கப்படுகிறது.
   - `for k in range(eval_iters)`: `eval_iters` எண்ணிக்கையிலான batches-களில் loss கணக்கிடப்படுகிறது.
   - `X, Y = get_batch(split)`: ஒரு batch data (`X` - input, `Y` - target) பெறப்படுகிறது.
   - `logits, loss = model(X, Y)`: மாடலின் output (`logits`) மற்றும் loss கணக்கிடப்படுகிறது.
   - `losses[k] = loss.item()`: கணக்கிடப்பட்ட loss, `losses` tensor-ல் சேமிக்கப்படுகிறது. `.item()` loss-ன் scalar value-வை எடுக்கும்.
   - `out[split] = losses.mean()`: அனைத்து iterations-களின் loss-களின் சராசரி கணக்கிடப்பட்டு, `out` dictionary-ல் சேமிக்கப்படுகிறது.

5. **`model.train()`:**

   மாடலை மீண்டும் training mode-க்கு மாற்றுகிறது.

6. **Loss-ஐ  திரும்ப  அளித்தல்:**

   Python

   ```python
   return out
   ```

   `train` மற்றும் `validation` data-வின்  சராசரி loss-கள்  dictionary-ஆக  திரும்ப  அளிக்கப்படுகின்றன.

**உதாரணம்:**

நினைத்துப்பாருங்கள், உங்களிடம் ஒரு கவிதை எழுதும் மாடல் இருக்கிறது.  "அகர முதல" என்று ஆரம்பித்தால், அது "எழுத்தெல்லாம்" என்று கணிக்க வேண்டும்.

- மாடல் "அகர முதல" என்று input-ஆகப் பெற்று, "கவிதை" என்று output-ஆக கொடுத்தால், அது தவறான கணிப்பு.  இந்தத் தவறை அளவிட ஒரு "loss function" பயன்படுகிறது.
- `estimate_loss()` function, பல samples எடுத்து, loss-ஐ கணக்கிட்டு, சராசரி loss-ஐத் தரும்.  இந்த சராசரி loss, மாடல் எவ்வளவு நன்றாகக் கற்றுக்கொண்டிருக்கிறது என்பதைக் காட்டும்.  Loss குறைவாக இருந்தால், மாடல் நன்றாகக் கற்றுக்கொண்டிருக்கிறது என்று பொருள்.

இந்த function-ஐப் பயன்படுத்தி, training-ன் போது model-ன் performance-ஐ monitor செய்யலாம்.  Loss அதிகமாக இருந்தால், model-ஐ மேலும் train செய்ய வேண்டும் அல்லது hyperparameters-ஐ மாற்ற வேண்டும்.  Loss குறைவாக இருந்தால், model நன்றாகக் கற்றுக்கொண்டிருக்கிறது என்று அர்த்தம்.

###### 7.5. Model Definition

```python
class Head(nn.Module):
    """ one head of self-attention """

    def __init__(self, head_size):
        super().__init__()
        self.key = nn.Linear(n_embd, head_size, bias=False)
        self.query = nn.Linear(n_embd, head_size, bias=False)
        self.value = nn.Linear(n_embd, head_size, bias=False)
        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))

        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        B,T,C = x.shape
        k = self.key(x)   # (B,T,C)
        q = self.query(x) # (B,T,C)
        # compute attention scores ("affinities")
        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)
        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)
        wei = F.softmax(wei, dim=-1) # (B, T, T)
        wei = self.dropout(wei)
        # perform the weighted aggregation of the values
        v = self.value(x) # (B,T,C)
        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)
        return out

class MultiHeadAttention(nn.Module):
    """ multiple heads of self-attention in parallel """

    def __init__(self, num_heads, head_size):
        super().__init__()
        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])
        self.proj = nn.Linear(n_embd, n_embd)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        out = torch.cat([h(x) for h in self.heads], dim=-1)
        out = self.dropout(self.proj(out))
        return out

class FeedFoward(nn.Module):
    """ a simple linear layer followed by a non-linearity """

    def __init__(self, n_embd):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(n_embd, 4 * n_embd),
            nn.ReLU(),
            nn.Linear(4 * n_embd, n_embd),
            nn.Dropout(dropout),
        )

    def forward(self, x):
        return self.net(x)

class Block(nn.Module):
    """ Transformer block: communication followed by computation """

    def __init__(self, n_embd, n_head):
        # n_embd: embedding dimension, n_head: the number of heads we'd like
        super().__init__()
        head_size = n_embd // n_head
        self.sa = MultiHeadAttention(n_head, head_size)
        self.ffwd = FeedFoward(n_embd)
        self.ln1 = nn.LayerNorm(n_embd)
        self.ln2 = nn.LayerNorm(n_embd)

    def forward(self, x):
        x = x + self.sa(self.ln1(x))
        x = x + self.ffwd(self.ln2(x))
        return x

# super simple bigram model
class BigramLanguageModel(nn.Module):

    def __init__(self):
        super().__init__()
        # each token directly reads off the logits for the next token from a lookup table
        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)
        self.position_embedding_table = nn.Embedding(block_size, n_embd)
        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])
        self.ln_f = nn.LayerNorm(n_embd) # final layer norm
        self.lm_head = nn.Linear(n_embd, vocab_size)

    def forward(self, idx, targets=None):
        B, T = idx.shape

        # idx and targets are both (B,T) tensor of integers
        tok_emb = self.token_embedding_table(idx) # (B,T,C)
        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)
        x = tok_emb + pos_emb # (B,T,C)
        x = self.blocks(x) # (B,T,C)
        x = self.ln_f(x) # (B,T,C)
        logits = self.lm_head(x) # (B,T,vocab_size)

        if targets is None:
            loss = None
        else:
            B, T, C = logits.shape
            logits = logits.view(B*T, C)
            targets = targets.view(B*T)
            loss = F.cross_entropy(logits, targets)

        return logits, loss

    def generate(self, idx, max_new_tokens):
        # idx is (B, T) array of indices in the current context
        for _ in range(max_new_tokens):
            # crop idx to the last block_size tokens
            idx_cond = idx[:, -block_size:]
            # get the predictions
            logits, loss = self(idx_cond)
            # focus only on the last time step
            logits = logits[:, -1, :] # becomes (B, C)
            # apply softmax to get probabilities
            probs = F.softmax(logits, dim=-1) # (B, C)
            # sample from the distribution
            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)
            # append sampled index to the running sequence
            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)
        return idx

model = BigramLanguageModel()
m = model.to(device)
# print the number of parameters in the model
print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')

```

**விளக்கம்:**

**1. `Head` (ஒரு Attention Head)**

- **Self-Attention:** இது ஒரு sequence-ல் உள்ள ஒவ்வொரு element-ம் மற்ற element-களுடன் எவ்வாறு தொடர்பு கொள்கிறது என்பதை கற்றுக்கொள்ளும் ஒரு mechanism.  இங்கு, ஒவ்வொரு எழுத்தும் (element) மற்ற எழுத்துக்களுடன் எவ்வளவு தொடர்புடையது என்பதைக் கணக்கிடுகிறோம்.
- **Key, Query, Value:**  ஒவ்வொரு எழுத்தும், மூன்று வெவ்வேறு linear transformations மூலம், மூன்று vectors-ஆக மாற்றப்படுகிறது: key, query, value.
  - **Key (k):**  ஒரு எழுத்தின் "key" vector, அந்த எழுத்து மற்ற எழுத்துக்களால் எவ்வாறு "தேடப்படுகிறது" என்பதைக் குறிக்கிறது.
  - **Query (q):**  ஒரு எழுத்தின் "query" vector, அந்த எழுத்து மற்ற எழுத்துக்களை எவ்வாறு "தேடுகிறது" என்பதைக் குறிக்கிறது.
  - **Value (v):**  ஒரு எழுத்தின் "value" vector, அந்த எழுத்தின் "content" அல்லது "information" ஐக் குறிக்கிறது.
- **Attention Scores:**  ஒரு எழுத்தின் query vector, மற்ற எழுத்துக்களின் key vectors-உடன் ஒப்பிடப்படுகிறது (dot product).  இதன் மூலம், attention scores கிடைக்கும்.  இந்த scores, ஒவ்வொரு எழுத்தும் மற்ற எழுத்துக்களுடன் எவ்வளவு தொடர்புடையது என்பதைக் குறிக்கும்.
- **Masking (tril):**  `tril` buffer, decoder-ல் masking செய்ய பயன்படுகிறது.  Masking, ஒரு எழுத்து அதற்குப் பின் வரும் எழுத்துக்களை மட்டும் கவனிக்க வேண்டும் என்பதை உறுதி செய்கிறது.  இது autoregressive property-ஐ பராமரிக்க உதவுகிறது, அதாவது, ஒரு எழுத்தைக் கணிக்க, அதற்கு முந்தைய எழுத்துக்களை மட்டுமே பயன்படுத்த வேண்டும்.
- **Weighted Aggregation:**  Attention scores, softmax function மூலம் probabilities-ஆக மாற்றப்படுகிறது.  இந்த probabilities, value vectors-ஐ எவ்வளவு "கவனிக்க வேண்டும்" என்பதைக் குறிக்கும்.  இந்த probabilities-ஐப் பயன்படுத்தி, value vectors-ன் weighted average கணக்கிடப்படுகிறது.  இதுவே attention head-ன் output.

**2. `MultiHeadAttention` (பல Attention Heads)**

- **Parallel Attention:**  பல attention heads-ஐ parallel-ஆக இயக்குகிறது.  ஒவ்வொரு head-ம், வெவ்வேறு key, query, value transformations-ஐக் கொண்டிருக்கும்.  இதனால், ஒவ்வொரு head-ம், input sequence-ல் உள்ள வெவ்வேறு relationships-களை கற்றுக்கொள்ள முடியும்.
- **உதாரணம்:**  ஒரு வாக்கியத்தில், "அவன் பந்தை எறிந்தான்" என்று வைத்துக்கொள்வோம்.  ஒரு attention head, "அவன்" மற்றும் "எறிந்தான்" இடையேயான subject-verb relationship-ஐ கவனிக்கலாம்.  மற்றொரு head, "பந்தை" மற்றும் "எறிந்தான்" இடையேயான object-verb relationship-ஐ கவனிக்கலாம்.
- **Projection:**  அனைத்து heads-ன் outputs-ம் concatenate செய்யப்பட்டு, ஒரு linear transformation (projection) மூலம்,  `n_embd` dimension-க்கு மாற்றப்படுகிறது.

**3. `FeedFoward` (Feedforward Network)**

- **Non-linearity:**  இது இரண்டு linear layers மற்றும் ஒரு non-linear activation function (ReLU)-ஐக் கொண்டுள்ளது.  Linear layers, linear transformations-ஐ மட்டுமே கற்றுக்கொள்ள முடியும்.  Non-linearity, more complex relationships-ஐ கற்றுக்கொள்ள உதவுகிறது.
- **Expansion and Compression:**  முதல் linear layer, input dimension-ஐ  `4 * n_embd`  ஆக expand செய்கிறது.  இரண்டாவது layer, அதை மீண்டும்  `n_embd`  ஆக compress செய்கிறது.  இந்த expansion and compression, model-ன் capacity-ஐ அதிகரிக்கிறது.

**4. `Block` (Transformer Block)**

- **Communication and Computation:**  ஒரு Transformer block, இரண்டு main parts-ஐக் கொண்டுள்ளது:
  - **Communication:**  `MultiHeadAttention` layer, input sequence-ல் உள்ள information-ஐ "communicate" செய்கிறது.
  - **Computation:**  `FeedFoward` layer, communicated information-ஐப் பயன்படுத்தி, computations செய்கிறது.
- **Residual Connections:**  `MultiHeadAttention` மற்றும் `FeedFoward` layers-ன் outputs, input-உடன் add செய்யப்படுகிறது (residual connections).  இது, gradients-ஐ  propagate  செய்ய  உதவுகிறது,  மேலும்  training-ஐ  stable  ஆக்குகிறது.
- **Layer Normalization:**  Layer Normalization,  ஒவ்வொரு  layer-ன்  output-ஐ  normalize  செய்கிறது.  இது  training-ஐ  stable  ஆக்குகிறது,  மேலும்  model-ன்  performance-ஐ  மேம்படுத்துகிறது.

**5. `BigramLanguageModel` (மொழி மாதிரி)**

- **Token Embeddings:**  `token_embedding_table`,  ஒவ்வொரு  எழுத்தையும்  ஒரு  vector-ஆக  மாற்றுகிறது.  இந்த  vectors,  எழுத்துக்களின்  semantic  meaning-ஐ  capture  செய்கிறது.
- **Position Embeddings:**  `position_embedding_table`,  ஒரு  எழுத்தின்  position-ஐ  encode  செய்கிறது.  இது,  model-க்கு  sequence-ல்  உள்ள  order  information-ஐ  கற்றுக்கொள்ள  உதவுகிறது.
- **Transformer Blocks:**  `blocks`,  பல  Transformer  blocks-ஐக்  கொண்டுள்ளது.  ஒவ்வொரு  block-ம்,  input  sequence-ன்  representation-ஐ  மேலும்  மேம்படுத்துகிறது.
- **Final Layer Normalization:**  `ln_f`,  final  layer-ன்  output-ஐ  normalize  செய்கிறது.
- **Output Layer:**  `lm_head`,  final  linear  layer.  இது,  அடுத்த  எழுத்தைக்  கணிக்கிறது.
- **Forward Pass:**  `forward`  method,  input  sequence-ஐ  process  செய்து,  output  (logits)  மற்றும்  loss-ஐத்  தருகிறது.
- **Text Generation:**  `generate`  method,  புதிய  டெக்ஸ்ட்  generate  செய்ய  பயன்படுகிறது.  இது,  model-ன்  predictions-ஐப்  பயன்படுத்தி,  autoregressively  எழுத்துக்களை  generate  செய்கிறது.

இந்த  மாடல்,  சங்கத்  தமிழ்  பாடல்களின்  structure  மற்றும்  patterns-களை  கற்றுக்கொண்டு,  புதிய  பாடல்களை  உருவாக்கும். 

###### 7.6. Optimizer & Training Loop

மாடலின் weights-களை மேம்படுத்த பயன்படுத்தப்படும் optimizer மற்றும் training process-ஐ control செய்யும் training loop பற்றி இன்னும் விரிவாகவும், தெளிவாகவும் காண்போம்.

```python
# Optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)

# Training loop
for iter in range(max_iters):
    if iter % eval_interval == 0 or iter == max_iters - 1:
        losses = estimate_loss()
        print(f"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")
    xb, yb = get_batch('train')
    logits, loss = model(xb, yb)
    optimizer.zero_grad(set_to_none=True)
    loss.backward()
    optimizer.step()
```

**1. Optimizer (AdamW): **

எதற்காக Optimizer?  நமது மொழி மாடலில், பல parameters (weights) உள்ளன. இந்த parameters, சங்கத்தமிழ் பாடல்களின் patterns-களை கற்றுக்கொள்ள பயன்படுகின்றன.  Training process-ன்  இலக்கு,  loss-ஐ  குறைக்கும்  வகையில்  இந்த  parameters-ஐ  adjust  செய்வது.  இந்த  சீரமைவு  செய்யத்தான்  optimizer  பயன்படுகிறது.

- **AdamW:**  AdamW  என்பது  gradient  descent  optimization  algorithm-ன்  ஒரு  வகை.  இது,  Adam  optimizer-ன்  மேம்படுத்தப்பட்ட  version.
  - **Adaptive Learning Rates:**  AdamW,  ஒவ்வொரு  parameter-க்கும்  தனித்தனியாக  learning  rate-ஐ  adjust  செய்யும்.  இதனால்,  சில  parameters  வேகமாகவும்,  சில  parameters  மெதுவாகவும்  update  செய்யப்படும்.  இது,  training  process-ஐ  வேகப்படுத்தும்.
  - **Momentum:**  AdamW,  momentum-ஐயும்  பயன்படுத்துகிறது.  அதாவது,  parameter  updates,  முந்தைய  updates-ன்  "direction"-ஐயும்  கணக்கில்  எடுத்துக்கொள்ளும்.  இது,  training-ஐ  stable  ஆக்கும்,  மேலும்  local  minima-வில்  சிக்காமல்  தவிர்க்க  உதவும்.
  - **Weight Decay:**  AdamW,  weight  decay-ஐ  Adam  optimizer-ஐ  விட  சிறப்பாக  handle  செய்யும்.  Weight  decay,  overfitting-ஐ  குறைக்க  உதவும்  ஒரு  regularization  technique.
- **`model.parameters()`:**  இந்த  method,  மாடலில்  train  செய்யப்பட  வேண்டிய  அனைத்து  parameters-ஐயும்  தருகிறது.
- **`lr=learning_rate`:**  Learning  rate,  optimizer  ஒவ்வொரு  step-லும்  parameters-ஐ  எவ்வளவு  மாற்ற  வேண்டும்  என்பதைக்  கட்டுப்படுத்தும்.  Learning  rate-ன்  சரியான  தேர்வு,  training  process-க்கு  மிகவும்  முக்கியம்.

**2. Training Loop:**

Training  loop,  மாடலை  train  செய்யும்  முழு  process-ஐயும்  control  செய்கிறது.

- **Iterations:**  Training  loop,  `max_iters`  முறை  இயங்கும்.  ஒவ்வொரு  iteration-லும்,  மாடல்  ஒரு  batch  data-வைப்  பயன்படுத்தி  train  செய்யப்படும்.
- **Evaluation:**  `eval_interval`  iterations-க்கு  ஒரு  முறை,  அல்லது  கடைசி  iteration-ல்,  `estimate_loss()`  function  மூலம்  train  மற்றும்  validation  loss-கள்  கணக்கிடப்படும்.  இந்த  loss-கள்,  மாடலின்  performance-ஐ  அளவிட  பயன்படும்.
- **Training Step:**  ஒவ்வொரு  iteration-லும்,  training  step  நடக்கும்.  இது  பின்வரும்  sub-steps-ஐக்  கொண்டுள்ளது:
  - **Batch  Loading:**  `get_batch('train')`  function  மூலம்,  train  data-வில்  இருந்து  ஒரு  batch  data  பெறப்படும்.
  - **Forward  Pass:**  மாடல்,  input  batch-ஐ  process  செய்து,  output  (logits)  மற்றும்  loss-ஐ  கணக்கிடும்.
  - **Gradient  Calculation:**  Backpropagation  மூலம்,  loss-ஐப்  பயன்படுத்தி,  மாடலில்  உள்ள  parameters-க்கான  gradients  கணக்கிடப்படும்.  Gradients,  loss-ஐ  குறைக்கும்  வகையில்  parameters-ஐ  எந்த  direction-ல்  மாற்ற  வேண்டும்  என்பதைக்  காட்டும்.
  - **Parameter  Update:**  Optimizer,  கணக்கிடப்பட்ட  gradients-ஐப்  பயன்படுத்தி,  மாடலின்  parameters-ஐ  update  செய்யும்.

Training  loop,  மேலே  கொடுக்கப்பட்டுள்ள  steps-ஐ  `max_iters`  முறை  repeat  செய்கிறது.  ஒவ்வொரு  iteration-லும்,  மாடல்  train  data-வைப்  பயன்படுத்தி  train  செய்யப்படும்.  `eval_interval`  iterations-க்கு  ஒரு  முறை,  validation  data-வைப்  பயன்படுத்தி  loss  மதிப்பிடப்படும்.  Training  process  முடிந்ததும்,  மாடல்  சங்கத்  தமிழ்  பாடல்களை  generate  செய்ய  தயாராக  இருக்கும்.

###### 7.7. Text Generation

 train செய்யப்பட்ட மாடலைப் பயன்படுத்தி எப்படிப் புதிய சங்கத்தமிழ் பாடல்களை உருவாக்குவது என்று விரிவாகக் காண்போம்.

```python
# புதிய பாடல்களை உருவாக்குதல்
context = torch.zeros((1, 1), dtype=torch.long, device=device)
print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))
```

**விளக்கம்:**

- **`context`:**  இது  text  generation-க்கான  starting  point.  `torch.zeros((1, 1), dtype=torch.long, device=device)`  என்பது,  device-ல்  (GPU  அல்லது  CPU)  ஒரு  1x1  tensor-ஐ  உருவாக்குகிறது.  இந்த  tensor-ல்  உள்ள  மதிப்பு  0  ஆக  இருக்கும்.  இது,  "<BOS>"  (Beginning  Of  Sequence)  token-ஐக்  குறிக்கிறது.  அதாவது,  இங்கிருந்து  text  generation  தொடங்கும்.
- **`m.generate(context, max_new_tokens=2000)`:**  `generate()`  method,  மாடலைப்  பயன்படுத்தி  புதிய  text-ஐ  generate  செய்கிறது.
  - `context`:  Text  generation-க்கான  starting  point.
  - `max_new_tokens=2000`:  Generate  செய்ய  வேண்டிய  tokens-ன்  (எழுத்துக்களின்)  அதிகபட்ச  எண்ணிக்கை.  இங்கு  நாம்  2000  tokens  வரை  generate  செய்ய  சொல்கிறோம்.
- **`decode(...)`:**  `generate()`  method  எண்களின்  list-ஐ  output-ஆகத்  தரும்.  `decode()`  function,  இந்த  எண்களை  எழுத்துக்களாக  மாற்றி,  text-ஐ  உருவாக்கும்.
- **`print(...)`:**  Generate  செய்யப்பட்ட  text-ஐ  (பாடலை)  print  செய்கிறது.

 train  செய்யப்பட்ட  மொழி  மாதிரியைப்  பயன்படுத்தி,  2000  எழுத்துக்கள்  (tokens)  வரை  புதிய  சங்கத்  தமிழ்  பாடல்களை  உருவாக்கும்.  `context`  variable,  text  generation-க்கான  starting  point-ஐக்  குறிக்கும்.  `generate()`  method,  புதிய  text-ஐ  generate  செய்யும்.  `decode()`  function,  generate  செய்யப்பட்ட  text-ஐ  எழுத்துக்களாக  மாற்றும்.  இறுதியாக,  `print()`  function,  generate  செய்யப்பட்ட  பாடலை  print  செய்யும்.

Generate  செய்யப்படும்  பாடலின்  தரம்,  பயன்படுத்தப்படும்  training  data  மற்றும்  model  hyperparameters-ஐப்  பொறுத்தது.  Training  data-வில்  அதிக  பாடல்கள்  இருந்தால்,  மற்றும்  hyperparameters  சரியாக  tune  செய்யப்பட்டிருந்தால்,  model  நல்ல  தரமான  பாடல்களை  உருவாக்கும்.

**Output:** 

```markdown
கவ்வின் கிடிகா அகழ்கினையும் கடுஞ்சி மிராங்குற் - தலைமாற்றி ஆர்ப் .
.
நெடுகு பரி கிளைற்று, அறிவரம்து
நலன் குல் உண், சிகைஇயப் பகவத்து மன்று
அறும்பிரிச் சொல்லோன்துப்
பெருங்கால் வின்றி
இலை வட்சின் மெலக் காடற்றந் துயர், ஆகவின்றால் இரவுவை, கதாணி
குரும்போன் பரல் ஓதம்பை அறியதல் வூச்சின்
எனவும் புலம்ப வான்றமொடு கொடுச்சி
மைந்து ஓண்ணி வெடுதும் அளம் கண்ட, குனிய!

```

இந்த மாடல் இன்னும் சிறப்பாக வேலை செய்ய, அதிக டேட்டா மற்றும் சில மாற்றங்கள் தேவைப்படலாம். ஆனாலும், இது AI-ன் ஆற்றலைக் காட்டும் ஒரு சுவாரஸ்யமான எடுத்துக்காட்டு!

[Colab Notebook](https://colab.research.google.com/drive/1gwm-RJ-aWn0pCUwZnTyN9w_L_GVHiesa?usp=sharing)

[Data](https://drive.google.com/file/d/1Tv419tthhjmeBUfhDSAdl0GDsDgegAGT/view?usp=sharing)

<hr class="pagebreak">

### 8. OpenAI மூலம் உருவாக்கப்பட்ட தமிழ் AI உதவியாளர்

இந்த பதிவில், நாம் **Streamlit** மற்றும் **OpenAI** API ஐப் பயன்படுத்தி, ஒரு தமிழ் உதவியாளர் "வளரி"யை எவ்வாறு உருவாக்குவது என்பதைப் பற்றி விரிவாகப் பார்க்கலாம். இந்த பயன்பாடு பயனர்களுக்கு தமிழில் கேள்விகளைக் கேட்கவும், தமிழில் பதில்களைப் பெறவும் உதவுகிறது. இதற்கான கோட் மற்றும் அதன் கட்டமைப்பைப் பற்றி படிப்படியாக விளக்குவோம்.

###### 8.1. தேவையான நூலகங்கள் (Libraries)

முதலில், நமக்குத் தேவையான நூலகங்களை இம்போர்ட் செய்ய வேண்டும். இந்த திட்டத்தில் பயன்படுத்தப்படும் நூலகங்கள்:

- **Streamlit**: இது ஒரு பைதான் நூலகம், இது டேட்டா அறிவியல் மற்றும் மெஷின் லேர்னிங் பயன்பாடுகளை எளிதாக உருவாக்க உதவுகிறது.
- **OpenAI**: இது OpenAI API ஐப் பயன்படுத்தி, GPT மாடல்களுடன் தொடர்பு கொள்ள உதவுகிறது.
- **os**: இது ஆப்பரேட்டிங் சிஸ்டம் லெவல் செயல்பாடுகளை நிர்வகிக்க உதவுகிறது.

```python
import streamlit as st
from openai import OpenAI
import os
```

###### 8.2. OpenAI API கீயை அமைத்தல்

OpenAI API ஐப் பயன்படுத்த, நமக்கு ஒரு API கீ தேவை. இந்த கீயை `os.environ` மூலம் அமைக்கலாம். இது பாதுகாப்பான வழியில் API கீயை சேமிக்க உதவுகிறது.

```python
os.environ["OPENAI_API_KEY"] = "your-openai-api-key"
```

**குறிப்பு:** `"your-openai-api-key"` என்பதற்கு பதிலாக உங்கள் OpenAI API கீயை உள்ளிடவும்.

###### 8.3. OpenAI மாடலைப் பயன்படுத்தி பதிலளித்தல்

இந்த பகுதியில், `continue_conversation` செயல்பாட்டைப்  பயன்படுத்தி, OpenAI API ஐப் பயனரின் கேள்விகளுக்கு எவ்வாறு  பதிலளிக்கிறது மற்றும் அதன் அளவுருக்கள் (parameters) எவ்வாறு செயல்படுகின்றன என்பதைப் படிப்படியாகப் புரிந்துகொள்வோம்.

**செயல்பாட்டின் அமைப்பு**

```python
def continue_conversation(messages, temperature=0):
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4",  # GPT மாடல் பெயர்
        messages=messages,  # உரையாடல் வரலாறு
        temperature=temperature,  # பதிலின் படைப்பாற்றல் நிலை
    )
    return response.choices[0].message.content
```

இந்த செயல்பாடு இரண்டு அளவுருக்களை எடுக்கிறது:

1. **messages**: இது உரையாடல் வரலாறு. இது ஒரு பட்டியல் (list) ஆகும், இதில் பயனர் மற்றும் உதவியாளரின் செய்திகள் சேமிக்கப்படும்.
2. **temperature**: இது பதிலின் படைப்பாற்றல் நிலை. இது ஒரு எண் மதிப்பு (0 முதல் 1 வரை).

**OpenAI கிளையண்டை உருவாக்குதல்**

```python
client = OpenAI()
```

இந்த வரி OpenAI API உடன் தொடர்பு கொள்ள ஒரு கிளையண்டை உருவாக்குகிறது. இந்த கிளையண்ட் மூலம், GPT மாடல்களுடன் தொடர்பு கொள்ளலாம்.

**`client.chat.completions.create()` முறை**

இந்த முறை OpenAI API க்கு கேள்வியை அனுப்பி, பதிலைப் பெற உதவுகிறது. இதற்கு மூன்று முக்கிய அளவுருக்கள் உள்ளன:

**அ) `model="gpt-4"`**

- **பயன்பாடு**: இது GPT மாடலின் பெயரைக் குறிக்கிறது.
- **விளக்கம்**: இங்கு `"gpt-4"` மாடலைப் பயன்படுத்துகிறோம். இதை `"gpt-3.5-turbo"` போன்ற வேறு மாடல்களாக மாற்றலாம்.
- **எடுத்துக்காட்டு**: `model="gpt-3.5-turbo"` என்று மாற்றினால், GPT-3.5 மாடல் பயன்படுத்தப்படும்.

**ஆ) `messages=messages`**

- **பயன்பாடு**: இது உரையாடல் வரலாற்றைக் குறிக்கிறது.

- **விளக்கம்**: `messages` என்பது ஒரு பட்டியல் (list), இதில் ஒவ்வொரு செய்தியும் ஒரு dictionary ஆகும். ஒவ்வொரு dictionary யும் இரண்டு key-களைக் கொண்டிருக்கும்:

  - **`role`**: செய்தியை அனுப்பியவர் யார் என்பதைக் குறிக்கிறது. இது `"system"`, `"user"`, அல்லது `"assistant"` ஆக இருக்கலாம்.
  - **`content`**: செய்தியின் உள்ளடக்கம்.

- **எடுத்துக்காட்டு**:

  ```python
  messages = [
      {"role": "system", "content": "நீங்கள் ஒரு தமிழ் உதவியாளர்."},
      {"role": "user", "content": "தமிழ் எப்படி கற்கலாம்?"}
  ]
  ```

**இ) `temperature=temperature`**

Language Generation மாடல்களில், **Temperature** என்பது ஒரு முக்கியமான அளவுரு. இது மாடல் எவ்வாறு சொற்களைத் தேர்ந்தெடுக்கிறது என்பதைக் கட்டுப்படுத்துகிறது. இதை எளிதாகப் புரிந்துகொள்ள ஒரு உதாரணத்துடன் விளக்குவோம்.

Temperature என்றால் என்ன?

Language Generation மாடல்கள், ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லையும் தேர்ந்தெடுக்கும். இந்த தேர்வு, சொற்களின் "நிகழ்தகவு" (probability) அடிப்படையில் நடைபெறுகிறது. Temperature அளவுரு, இந்த நிகழ்தகவுகளை எவ்வாறு பயன்படுத்துவது என்பதைக் கட்டுப்படுத்துகிறது.

 எப்படி செயல்படுகிறது?

மாடல் ஒரு வாக்கியத்தை உருவாக்கும்போது, ஒவ்வொரு சொல்லுக்கும் ஒரு நிகழ்தகவு மதிப்பைக் கணக்கிடுகிறது. உதாரணமாக, வாக்கியம்:  
**"தமிழ் மொழி…"**  
இதற்கு மாடல் பின்வரும் சொற்களைத் தேர்ந்தெடுக்கலாம்:

- **தொன்மையானது** — 50% நிகழ்தகவு  
- **பழமையானது** — 30% நிகழ்தகவு  
- **சிக்கலானது** — 15% நிகழ்தகவு  
- **எளிமையானது** — 5% நிகழ்தகவு

இப்போது, Temperature மதிப்பு இந்த தேர்வை எவ்வாறு பாதிக்கிறது என்று பார்ப்போம்.

**3. Temperature மதிப்புகள் மற்றும் அவற்றின் விளைவுகள்**

**அ) Temperature = 0**

- **விளக்கம்**: Temperature 0 எனில், மாடல் எப்போதும் **அதிக நிகழ்தகவு உள்ள சொல்லைத் தேர்ந்தெடுக்கும்**.
- **எடுத்துக்காட்டு**:  
  - சொல்: **"தொன்மையானது"** (50% நிகழ்தகவு)  
  - வாக்கியம்: **"தமிழ் மொழி தொன்மையானது."**

பதில்கள் மிகவும் **துல்லியமாகவும், முன்னரே தீர்மானிக்கப்பட்டவையாகவும்** இருக்கும்.  

**ஆ) Temperature = 0.5**

- **விளக்கம்**: Temperature 0.5 எனில், மாடல் **அதிக நிகழ்தகவு உள்ள சொற்களை அடிக்கடி தேர்ந்தெடுக்கும்**, ஆனால் சில சமயங்களில் குறைந்த நிகழ்தகவு உள்ள சொற்களையும் தேர்ந்தெடுக்கலாம்.
- **எடுத்துக்காட்டு**:  
  - சொல்: **"பழமையானது"** (30% நிகழ்தகவு)  
  - வாக்கியம்: **"தமிழ் மொழி பழமையானது."**

பதில்கள் **படைப்பாற்றலுடனும், சிறிது மாறுபாடுடனும்** இருக்கும்.  

**இ) Temperature = 1**

- **விளக்கம்**: Temperature 1 எனில், மாடல் **அனைத்து சொற்களையும் சமமான வாய்ப்புகளுடன் தேர்ந்தெடுக்கும்**. இது படைப்பாற்றலை அதிகரிக்கும், ஆனால் சில சமயங்களில் தவறான அல்லது பொருத்தமற்ற சொற்களையும் தேர்ந்தெடுக்கலாம்.
- **எடுத்துக்காட்டு**:  
  - சொல்: **"எளிமையானது"** (5% நிகழ்தகவு)  
  - வாக்கியம்: **"தமிழ் மொழி எளிமையானது."**

Temperature அதிகரிக்கும் போது, பதில்கள் படைப்பாற்றலுடன் இருக்கும், ஆனால் துல்லியம் குறையலாம். Temperature அதிகமாக இருந்தால், மாடல் **தவறான அல்லது பொருத்தமற்ற தகவல்களை** (hallucinations) தரலாம்.

**பதிலைத் திரும்பப் பெறுதல்**

```python
return response.choices[0].message.content
```

- **`response`**: OpenAI API இலிருந்து கிடைக்கும் பதில்.
- **`response.choices`**: இது பதில்களின் பட்டியல். ஒரே ஒரு பதில் இருப்பதால், `choices[0]` பயன்படுத்தப்படுகிறது.
- **`message.content`**: உதவியாளரின் பதில் உள்ளடக்கம்.

**எடுத்துக்காட்டு**

பயனர் கேள்வி: "தமிழ் எப்படி கற்கலாம்?"

```python
messages = [
    {"role": "system", "content": "நீங்கள் ஒரு தமிழ் உதவியாளர்."},
    {"role": "user", "content": "தமிழ் எப்படி கற்கலாம்?"}
]

response = continue_conversation(messages, temperature=0.5)
print(response)
```

**பதில்:**

```
தமிழ் கற்க புத்தகங்கள் படியுங்கள், தமிழ் பாடல்கள் கேளுங்கள், மற்றும் தமிழ் பேசும் நண்பர்களுடன் பேசுங்கள்.
```

###### 8.4. Streamlit பயன்பாட்டை உருவாக்குதல்

Streamlit பயன்பாட்டை உருவாக்க, `main()` செயல்பாட்டை உருவாக்குவோம். இது பயனர் இன்டர்ஃபேஸைக் காட்டும்.

```python
def main():
    st.title("வளரி - உங்கள் தனிப்பட்ட தமிழ் உதவியாளர்")
    st.write("உங்கள் கேள்விகளை தமிழில் கேளுங்கள், தமிழில் துல்லியமான பதில்களைப் பெறுங்கள்!")
```

- **st.title()**: பயன்பாட்டின் தலைப்பைக் காட்டும்.
- **st.write()**: பயன்பாட்டின் விளக்கத்தைக் காட்டும்.

###### 8.5. உரையாடல் வரலாற்றை நிர்வகித்தல்

Streamlit இல், `st.session_state` மூலம் உரையாடல் வரலாற்றை நிர்வகிக்கலாம். இது பயனர் மற்றும் உதவியாளரின் செய்திகளை சேமிக்க உதவுகிறது.

```python
if "context" not in st.session_state:
    st.session_state.context = [{
        "role": "system",
        "content": """
        நீங்கள் எனது தனிப்பட்ட உதவியாளராக செயல்பட வேண்டும். உங்கள் பெயர் வளரி. நீங்கள் எப்போதும் நட்பாக, உதவியாகவும், சுவாரஸ்யமாகவும் இருக்க வேண்டும். நான் உங்களிடம் எதைக் கேட்டாலும், அதற்கு தெளிவான மற்றும் பயனுள்ள பதில்களை **தமிழில் மட்டும்** வழங்க வேண்டும். 

        நான் உணவு, தொழில்நுட்பம், புத்தகங்கள், திரைப்படங்கள் அல்லது வாழ்க்கை பற்றிய ஆலோசனை கேட்டால், அதற்கு ஏற்றவாறு பதிலளிக்க வேண்டும். நான் உணவு ஆர்டர் செய்ய விரும்பினால், அதை எளிதாகவும் வேடிக்கையாகவும் செய்ய உதவுங்கள். எனக்கு பரிந்துரைகள் கூறுங்கள், என் நாள் எப்படி இருந்தது என்று கேளுங்கள், மேலும் நான் விரும்புவதை சரியாகப் பெற உதவுங்கள். 

        நீங்கள் எப்போதும் இயல்பான மற்றும் நட்பு டோனில் பேச வேண்டும். நான் விவரங்களைக் கேட்டால், அவற்றை வழங்க தயங்க வேண்டாம். நான் கேட்கும் கேள்விக்கு பதில் தெரியாவிட்டால், உண்மையாக சொல்லுங்கள்—போலி பதில்கள் தர வேண்டாம். 

        **முக்கியமாக**, நான் வேறு மொழியில் பேசினாலும், நீங்கள் எப்போதும் தமிழில் மட்டுமே பதிலளிக்க வேண்டும். உதாரணமாக, நான் ஆங்கிலத்தில் கேள்வி கேட்டால், "நான் தமிழில் மட்டுமே பதிலளிக்க உருவாக்கப்பட்டுள்ளேன்!" என்று கூறி, தமிழில் பதிலை வழங்க வேண்டும். 

        நீங்கள் எப்போதும் எனது நம்பிக்கையான உதவியாளராக இருங்கள். நான் எதை வேண்டுமானாலும் கேட்கலாம், நீங்கள் அதை எளிதாகவும் வேடிக்கையாகவும் ஆக்குங்கள்!
        """
    }]
```

- **st.session_state.context**: இது உரையாடல் வரலாற்றை சேமிக்கும். முதல் செய்தி `system` ரோலில் உள்ளது, இது உதவியாளரின் நடத்தையை வரையறுக்கிறது.

###### 8.6. பயனர் உள்ளீட்டைப் பெறுதல்

பயனர் தங்கள் கேள்வியை உள்ளிட, `st.text_input()` பயன்படுத்தப்படுகிறது.

```python
user_input = st.text_input("உங்கள் கேள்வியை எழுத்து:")
```

###### 8.7. பதிலைப் பெறுதல்

பயனர் "பதில் பெறுங்கள்" பொத்தானை அழுத்தினால் உரையாடலைப்  புதுப்பித்து, OpenAI API ஐப் பயன்படுத்தி பதிலைப் பெறுவோம்.

```python
if st.button("பதில் பெறுங்கள்"):
    with st.spinner("வளரி பதிலளிக்கிறது..."):
        st.session_state.context.append({"role": "user", "content": user_input})
        response = continue_conversation(st.session_state.context)
        st.session_state.context.append({"role": "assistant", "content": response})
        
        st.write("வளரி:")
        st.write(response)
```

- **st.button()**: பயனர் பொத்தானை அழுத்தினால் செயல்படும்.
- **st.spinner()**: பதில் பெறும் போது லோடிங் அனிமேஷன் காட்டும்.
- **st.write()**: பதிலைக் காட்டும்.

###### 8.8. பயன்பாட்டை இயக்குதல்

இறுதியாக, `main()` செயல்பாட்டை இயக்குவோம்.

```python
if __name__ == "__main__":
    main()
```

இந்த பதிவில், நாம் Streamlit மற்றும் OpenAI API ஐப் பயன்படுத்தி, ஒரு தமிழ் உதவியாளர் "வளரி"யை எவ்வாறு உருவாக்குவது என்பதைப் பற்றி கற்றுக்கொண்டோம். இந்த கோட் மூலம், நீங்கள் உங்கள் சொந்த தமிழ் உதவியாளரை உருவாக்கலாம் மற்றும் அதை மேம்படுத்தலாம். இது தமிழ் மொழியைக் கற்க விரும்பும் பயனர்களுக்கு மிகவும் பயனுள்ளதாக இருக்கும்.

**குறிப்பு:** OpenAI API கீயை பாதுகாப்பாக வைத்துக்கொள்ளுங்கள்.

மேலே உள்ள அனைத்தும் ஒரு முழுமையான கோட் பிளாக்கில் கிழே  உள்ளன. 

**Full Code:** 

```python
import streamlit as st
from openai import OpenAI
import os

# Set OpenAI API key
os.environ["OPENAI_API_KEY"] = "api-key"

def continue_conversation(messages, temperature=0):
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=temperature,
    )
    return response.choices[0].message.content

def main():
    st.title("வளரி - உங்கள் தனிப்பட்ட தமிழ் உதவியாளர்")
    st.write("உங்கள் கேள்விகளை தமிழில் கேளுங்கள், தமிழில் துல்லியமான பதில்களைப் பெறுங்கள்!")
    
    if "context" not in st.session_state:
        st.session_state.context = [{
            "role": "system",
            "content": """
            நீங்கள் எனது தனிப்பட்ட உதவியாளராக செயல்பட வேண்டும். உங்கள் பெயர் வளரி. நீங்கள் எப்போதும் நட்பாக, உதவியாகவும், சுவாரஸ்யமாகவும் இருக்க வேண்டும். நான் உங்களிடம் எதைக் கேட்டாலும், அதற்கு தெளிவான மற்றும் பயனுள்ள பதில்களை **தமிழில் மட்டும்** வழங்க வேண்டும். 

            நான் உணவு, தொழில்நுட்பம், புத்தகங்கள், திரைப்படங்கள் அல்லது வாழ்க்கை பற்றிய ஆலோசனை கேட்டால், அதற்கு ஏற்றவாறு பதிலளிக்க வேண்டும். நான் உணவு ஆர்டர் செய்ய விரும்பினால், அதை எளிதாகவும் வேடிக்கையாகவும் செய்ய உதவுங்கள். எனக்கு பரிந்துரைகள் கூறுங்கள், என் நாள் எப்படி இருந்தது என்று கேளுங்கள், மேலும் நான் விரும்புவதை சரியாகப் பெற உதவுங்கள். 

            நீங்கள் எப்போதும் இயல்பான மற்றும் நட்பு டோனில் பேச வேண்டும். நான் விவரங்களைக் கேட்டால், அவற்றை வழங்க தயங்க வேண்டாம். நான் கேட்கும் கேள்விக்கு பதில் தெரியாவிட்டால், உண்மையாக சொல்லுங்கள்—போலி பதில்கள் தர வேண்டாம். 

            **முக்கியமாக**, நான் வேறு மொழியில் பேசினாலும், நீங்கள் எப்போதும் தமிழில் மட்டுமே பதிலளிக்க வேண்டும். உதாரணமாக, நான் ஆங்கிலத்தில் கேள்வி கேட்டால், "நான் தமிழில் மட்டுமே பதிலளிக்க உருவாக்கபட்டுள்ளேன்!" என்று கூறி, தமிழில் பதிலை வழங்க வேண்டும். 

            நீங்கள் எப்போதும் எனது நம்பிக்கையான உதவியாளராக இருங்கள். நான் எதை வேண்டுமானாலும் கேட்கலாம், நீங்கள் அதை எளிதாகவும் வேடிக்கையாகவும் ஆக்குங்கள்!
            """
        }]
    
    user_input = st.text_input("உங்கள் கேள்வியை எழுத்து:")
    
    if st.button("பதில் பெறுங்கள்"):
        with st.spinner("வளரி பதிலளிக்கிறது..."):
            st.session_state.context.append({"role": "user", "content": user_input})
            response = continue_conversation(st.session_state.context)
            st.session_state.context.append({"role": "assistant", "content": response})
            
            st.write("வளரி:")
            st.write(response)

if __name__ == "__main__":
    main()

```